
\clearpage

\section{Preface}
\label{sec:orgcfa10a1}
The text of this chapter originally served as a memorandum, for internal documentation and knowledge transfer, distributed on October 16th, 2021 under the original title ``A Tiny Textbook About a Fraction of Statistical Methodology'' .
It applies probabilistic, predictive modeling to a previously analyzed data set, which was kindly provided by Fran√ßois Druelle \citep[][]{Druelle2021}.
The prior analysis, which focused on the comparison of spatiotemporal variables, is herein extended to questions of \emph{posture} and \emph{coordination}.
To tackle these additional research questions, a sophisticated statistical modeling procedure is required.
In preparation of a potential manuscript (which did not materialize after all), I realized that a significant amount of knowledge transfer is required to get all co-authors and interested readers up to level with the technical details and design decisions encountered on the way.


In a nutshell:
\begin{itemize}
\item I analyze bipedal locomotion in olive baboons, \emph{Papio anubis}.
\item Kinematics are processed with a previously established technique (``Fourier Coefficient Affine Superimposition'', Ch. \ref{cpt:fcas}).
\item \textbf{Probabilistic Models} are used to infer major interrelations of subject-, spatiotemporal-, and kinematic parameters.
\item Model design is validated by model comparison.
\item One purpose of these models is in-sample- and out-of-sample prediction.
\item For reference, all analysis code, including the \texttt{org mode} document compiling this text are available here: \url{https://git.sr.ht/\~falk/papio\_fcas}.
\end{itemize}

In accordance with the originally internal target audience, this chapter takes a more colloquial tone than actual publications.
As a compensation, I provide practical tipps and trial-and-error-based experiences for readers interested in implementing their own models.

The document also lacks a conventional introduction.
If the relevance and importance of statistical modeling is not immediately obvious to the reader, I kindly refer them to the applied chapter to follow (Ch. \ref{cpt:piglets}), which contains extensive elaboration on the topic.


\FloatBarrier
\clearpage
\section{Introduction: Probabilistic Modeling}
\label{sec:org2074548}
\subsection{Probabilistic Modeling and Other Statistics}
\label{sec:org0cc6a35}
To approach probabilistic modeling, it is important to understand its relation to other areas of statistics, such as hypothesis testing.
Many researchers have been primed on statistical hypothesis testing early during their education.
Its goal usually is to make an informed choice of whether a hypothesis about the data is true or not.
For example, one might ask: ``does the speed at which an animal moves change with age?''
The expected answer is often a simple ``yes/no''.
But the example question is not well formulated for statistics.
It defines a quantitative measure (speed), which is good.
However, it should rigorously be wrapped in: ``does our data set provide evidence that a rejection of the hypothesis \ldots{}''.
Furthermore, it should refer to testable subsets of the sample: ``\ldots{} that movement speed of young animals is different from that of adults.''
Finally, one must set an \emph{a priori} threshold above which the rejection of the null hypothesis would most likely be false \citep[called ``p-value'', too commonly desired to be below \(p=0.05\),][]{Dallal2003}.
A proper hypothesis to test must relate to the data, contain rejectable predictions and (ideally exclusive) alternatives, and finally must be linked to a confidence threshold \citep{Chamberlin1890,Platt1964,Popper2002}.

Yet there is a caveat: the metrics generated from conventional hypothesis testing do not yield a quantitative assessment of effect size.
In other words: a low \emph{p-value} does not indicate a large speed change with age, it just indicates that the change (i.e. rejection of the null hypothesis ``speed does not depend on ageclass'') is more likely to be true.
Also, there must be an assumption of \emph{how} speed changes with age: is it increasing linearly or is it low for young, high for middle, and low again for high-aged individuals?
The reason is that all tests explicitly require a set of mathematical assumptions to be met (e.g. ``Normal distribution'' of the data, one- or two-sided comparison).
And because of this, there exists a whole zoo of different test for different assumption situations, the choice of which is a science by itself.
Familiar examples are the ``t-Test'' or ``ANOVA'' in all their variants.
To summarize, this branch of statistics is called \textbf{hypothesis testing}; it is a complex field and valuable when it comes to falsifying hypotheses.


\begin{table}[p!]
\caption{\label{tab:statistics}Statistics: An Overview. Probabilistic models are the focus of this chapter.}
\centering
\begin{tabular}{|l|l|l|}
\hline
 & \textbf{Frequentist} & \textbf{Probabilistic}\\[0pt]
\hline
\textbf{Hypotheses} & decision trees & ``Bayesian'' hyp. tests\\[0pt]
\hline
\textbf{Modeling} & (least squares) regression & MCMC Sampling\\[0pt]
\hline
\end{tabular}
\end{table}



\FloatBarrier
The term ``hypothesis testing'' might be understood to be synonymous with ``Frequentist statistics'', or ``non-Bayesian statistics''.
This conception would be inexact, because there are also Bayesian hypothesis tests, which rely on a concept called ``Bayes factor'' but are not discussed herein \citep[cf.][]{Shikano2019}.
Hence, we need to disentangle two categories of distinction (Tab. \ref{tab:statistics}).

Not all researchers are after hypotheses.
What we usually desire in obtaining experimental data is a quantitative assessment of different effects which exist in the data and influence the outcome of a quantitative measurement.
There are two main frameworks to tackle these questions, both of which are captured by the term \textbf{modeling}: ``Frequentist'' models (usually least squares optimization), and ``Bayesian'' / probabilistic models (enabled by a technical trick called \emph{MCMC} = ``Markov Chain Monte Carlo'' sampling).
Hence, we should distinguish the type of question (hypothesis / quantitative estimate) and the methodological school (Frequentist or Bayesian, see Tab. \ref{tab:statistics}).



All these ``strains'' of statistics have historically developed different terminologies, sometimes even different meaning to the same terminologies, which can be confusing and even misleading (e.g. try to find out about the term ``likelihood'', cf. ``Bayesian Statistics without Frequentist Language'' by Richard McElreath, 2017, \url{https://www.youtube.com/watch?v=yakg94HyWdE}).
In particular, there is a lot of confusion and ongoing discussion about the distinction and proper presentation of \emph{confidence intervals} and \emph{credible intervals}.
Please excuse that for the purpose of this chapter, I calculated, but will not always report, credible intervals\footnote{I herein take the $\left[3\ \%,97\ \%\right]\ HDI$, i.e. Highest Density Interval, which is the smallest value range that covers $94\ \%$ of the posterior probability distribution.}.
I will occasionally explain conventions on the way, but leave it up to the interested reader to dig deeper or ask back.
You might notice that my way of tackling statistics with inclusive models were heavily primed by the book \href{https://xcelab.net/rm/statistical-rethinking/}{``Statistical Rethinking'' by Richard McElreath} \citep{McElreath2018}, and there is an infrequently updated, highly recommendable lecture series by that author available on youtube.


The main approach presented in this document is \textbf{probabilistic modeling}.
For simplicity, models will all be \emph{linear models}, which means that all outcome variables are modeled as a combination of linear predictors (i.e. just linear slopes / no multiplications, exponents etc.).
This subclass of models is often summarized as ``Generalized Linear (Mixed) Models'', or GLMs.
It is a special subset of thinkable models, nevertheless the most frequently used one.
Despite this practical restriction, most concepts introduced below should equally apply to non-linear models.
In fact, good modeling frameworks are sufficiently flexible to enable any model design, not only linear equations.
\bigskip


Hypothesis testing and modeling are non-exclusive, as one can ask both questions of effect significance and effect magnitude at the same time \chng{(though in the case of probabilistic models, we do not speak of significance, but of ``credible intervals'')}.
If a given data model turns out to match the data well, this affects the hypotheses which can be hypothesized (e.g. Normality assumption can be confirmed or rejected by measuring the goodness of fit of a ``Student's T'' model).
On the other hand, because most models also contain a residual variance, it is tempting (but not always legitimate for rigorous reviewers) to use the credible intervals and residual variance to reject hypotheses without additional test.
I would like to emphasize: all four major segments of statistics are intimately related, best executed in parallel, and should ideally yield consistent results.

Hence, one might validly ask why I focus on probabilistic modeling.
Firstly, most people are already familiar with the Frequentist side, since academic education on statistics is heavily biased towards these methods.
Readers probably know these methods already, and chances are they are more of an expert than I am.
Secondly, one perspective of the particular data set at hand is prediction, which is challenging for processes which are intrinsically variable (such as locomotion).
Probabilistic models are ideal for this purpose, as will become clear below.

But before getting to the actual data, I attempt to give an abstract overview of the involved methodological steps.

\clearpage
\subsection{Modeling Workflow}
\label{intro:workflow}
When cooking my soup of statistics, I tend to pragmatically stick to the ``ingredients'' outlined in the paragraphs to follow.
A prerequisite material is ``well-cleaned'' data, usually stored in database format (as ``csv'' for compatibility), containing as much information about the experiments as possible.
``Pragmatically'' here does not imply that these steps must be executed in sequential order for practical work.
In fact, they are often repeated iteratively.


\subsubsection{Data Simulation}
\label{sec:org2c774e4}
Before going to the actual data, I prepare a simulated data set which roughly incorporates parameters and parameter relations.
These realations are comparable to those I intend to model later.
For example, imagine I hope to find an age-dependent bodymass slope, i.e. I expect that one of my variables (``\texttt{obs1}'') depends on bodymass (\texttt{bm}), but the strength of this dependence is different for each ageclass.
Then I will generate a fake data set which follows exactly this desired relation: starting with a white noise data column for \texttt{obs1}, I add a known \texttt{intercept}.
I randomly assign an age group to each of the data rows.
Then, for each of the entries, I add \texttt{bm*slope(age)}, i.e. an age-group dependent component which represents the \texttt{obs1} / \texttt{bm} relation.
I tend to use values which are approximately in the range I would expect for the actual data, or I even work with averages from the data.

With that simulated data in place, I run a model which resembles the actual one applied later.
For example, one could use:
\begin{equation} obs_{1} \sim intercept + slope_{bm\mid age} \cdot bm_{centered} \label{eq:exampleformula} \end{equation}

This is our first model equation, and we will encounter and explain more below.
Model equations are an abstract formulation of the model, which helps communicating the content and keeping track of model alterations.
Centering the bodymass could happen per group, i.e. for each subset of the data which has a certain age group, I would substract the group mean bodymass from the actual bodymass values.
Or one could center for the whole data set.
I can ``simulate'' all of these structures by simple numeric calculation: a slope based on absolute bodymass, one based on centered bodymass, and finally one based on groupwise centered data.
And then I cross compare and see how the wrong model captures the simulated data and whether I can distinguish.
With the shere amount of parameter combinations, this can be time consuming.
Is simulation worth it? Or, in another word:

\textbf{Why?!} You might feel the urge to ask: why this extra step of using fake data to apply a fake model?
The reason is simply that, by this tautologous simulation procedure, I ensure that the model structure I apply is in fact \emph{capable of} finding the effects I suspect in the real data.
I thereby make sure that my model roughly works as I intend.
This is first and foremost important for setting up and getting used to a modeling framework.
But I can also apply simplified models and observe how they fail, which helps to explore the limitations of a given model design.
This might seem trivial for simple, linear models.
However, when going to multi-level, multivariate models\footnote{If you are unfamiliar with the terms ``multi-level'' or ``multivariate'', I would like to ask some patience: they will get clearer below, and in fact you might already have encountered them under alternative names.}, things get complex, and model structures are neither straight forward, nor intuitive.
Recovering the artificial parameters which I put into the data gives me some confidence that the model structure is as intended (which is not to say that the model is a good one for my real data set).
Critically, some models are inherently ambiguous (e.g. think of a toy model as the one above which instead has age as an explicit parameter \emph{and} as a level for bodymass).
By playing around with the parameters which generate the simulated data set, and then checking how the model changes, one can learn which effects end up where and how unique, and how sensitive, the model components are.
Likewise, it is possible to simulate varying sample- and effect sizes, to see how much data is needed to reliably recover a given effect.

Ideally, this informative procedure should happen in the process of experimental design, prior to a grant application or ethics proposal.
Yet even if the data happens to be on your hard drive already, better simulate late than never.


\subsubsection{Data Inspection}
\label{sec:orga128476}
Before throwing complex models at the data, one might want to get a feeling of the parameters recorded with the data set.
\begin{itemize}
\item How many data points are there in different groups?
\item Which categorical, which continuous parameters were recorded?
\item What are the empirical distributions of outcome values, and which theoretical distributions could potentially resemble them?
\item Is the distribution similar in different groups?
\item Are there notable correlations between parameters, on the predictor or outcome side?
\end{itemize}

This step is a rather flexible and personal one, and usually not documented (except for some high quality, polished figures in publication).
Data can be explored by looking at spreadsheets, using pivot tables and pivot charts, or better: by writing scripts in a scientific scripting language (Python, R, Matlab).

This is the ``data playground''.
Just learn what might be going on in the data, and \textbf{build hypotheses} for the subsequent analysis.


\subsubsection{Technical Framework}
\label{workflow:framework}
Although I happen to be an advocate of probabilistic modeling frameworks, I tend to test some basic models with ``conventional'', frequentist statistics toolboxes.
These are, for example, \texttt{statsmodels} in Python or \texttt{lmer} in R.
The most general models are easily formulated in formula notation.
Per default, such frameworks are (i) Frequentist and have (ii) ``high-level'' APIs (Application Programming Interface).

The ``Frequentist'' aspect was mentioned above, compared to ``probabilistic''.
Probabilistic sampling usually takes more time than a least squares procedure.
Ideally, models from both worlds should match.
A ``quick and (more or less) dirty'' model generation can facilitate \textbf{hypothesis refinement or model structure sharpening}.

In principle, there is nothing wrong about publishing these ``quick'' model outcomes directly (but there are some advantages to probabilistic procedures, which are covered herein).
However, the ``high-level'' aspect comes with some limitations.
By ``high-level'', I mean that the syntax is close to human intuition, and less demanding in terms of programming skills.
``Low-level'', in contrast, refers to high control and detailed initialization, closer to ``machine language'', which can be challenging for inexperienced users.
This should not be confused with unnecessary complexity and cumbersome syntax, which is abundant in both approaches (maybe more often found in high level APIs).
In my experience, the model construction procedure on high level modeling toolboxes tends to be intransparent and limited.
In consequence, my personal skill with them stayed limited over the years.
In my idealistic strive for reproducibility, I prefer to publish models of which I controlled and can explain every single design aspect on demand.

One example to illustrate the ``high/low-level'' dichotomy is formula notation.
Many available model programming libraries strive to give an ``easy to use'' interface for novice statisticians to produce models.
These users want to enter things like ``\texttt{speed \textasciitilde{} 1 + sex + age + (bm*age)}'', and get the result in convenient table format.
This notation is called ``formula notation'' (e.g. the Python library \texttt{patsy} is used for it).
Convenient as this may be, I tended to encounter problems with this approach: most real models are not ``easy to use''.
\begin{itemize}
\item Formula notation is limited: the explorative steps mentioned earlier ideally yielded many creative hypotheses that the eager statistician desires to forge into a model.
\item Model internals are intransparent: parameter interactions, ``random and fixed'' effects (i.e. multi-level parameters), multivariate parameter blocks\ldots{} abstracting these abundant model components to formula notation might obfuscate the actual inner working of the model (because formulas introduce an extra level of abstraction).
\item Formula syntax: although not being an expert, I experienced that formula notation is not universal; or if so, it involves syntactical details which I am unable to remember or intuitively disentangle (e.g., what is the difference between \texttt{bm*age} and \texttt{bm|age}?).
\end{itemize}
The alternative is a low-level toolbox in which one has to initialize intercept, slopes and outcome separately, and use operators to produce the ``formula'' (here: the mathematical formulation) in code.

Which to choose has a lot to do with prior experience, and I acknowledge that the major reason for my preference for low level interfaces lies at least partly in my personal inexperience with formula notation and the like, and in my attraction to code tinkering.


Here is my approach: object-oriented programming.
This is not strictly an alternative to formula notation and ``high level'' toolboxes, but an addition.
You can wrap formula generators in an object as well as ``low level'' component generators.
My strategy is to define a ``model'' object in code, which can be initialized with certain settings, and then assembles a model.
The advantage is that I get many convenience functions which I can easily \textbf{adjust to the specific requirements of my project} (for example, saving and loading, see \hyperref[workflow:deserialization]{Ch. \ref{workflow:deserialization}}, or model hygiene, see \hyperref[workflow:hygiene]{Ch. \ref{workflow:hygiene}}).
At the same time, I retain precise control of the mathematical model internals.
This strategy could be labelled \textbf{``building a high level API from low level ground''}.
Of course, the ``low level ground'' requires some tensor juggling and programming insights, which is certainly a show stopper for inexperienced programmers.

But for me, the benefits of ``full control'' over the models outweigh the disadvantage of short term inconvenience.
Furthermore, the system really ``flies'' with the highly iterative quest of finding the right model for a data set.


\subsubsection{Modeling Design Choices}
\label{workflow:design:philosophy}
When it comes to the actual components of a model, there are always multiple options of how to include a parameter.
This refers to questions of inclusion/exclusion, mathematical choices, and the hierarchical and covariable structure of individual model components (i.e. how parameters are interrelated):
\begin{itemize}
\item ``inclusiveness'': whether or not to include nuisance parameters (e.g. the effect of moon phase on animal locomotion)
\item whether to include it explicitly, or in a random intercept (e.g. ``sex'' male/female can be a model component, or shedded by a subject-level intercept)
\item the hierarchical structure of components (e.g. whether bodymass slope is universal, or different for each ageclass; most familiar are ``random slope'' and ``random intercept'')
\item whether/how to include the covariance of outcome variables (e.g. speed, stride frequency and stride length are interrelated)
\item whether/how to include the covariance of slopes
\item mathematical detail which can affect the sampling (e.g. the so-called ``parametrization'': multi-level components can be modeled by ``sampling'' from a hyper-prior or as ``offset'' from a population slope)
\end{itemize}

More on all this below.
Generally, the possibilities tend to be more numerous than one would like.

\textbf{How to choose?} Two things guide model design choices: (i) logical arguments and (ii) model comparison.
Model comparison is covered in detail below \chng{(Ch. \ref{workflow:comparison})}.
It is a ``hard'', numerical guide to which model succeeds best in representing the data.
Models are compared \emph{ex post}, i.e. sampling (model fitting) is a prerequisite.
Logical arguments, on the other hand, are soft criteria which exclude some implausible/unfeasible model structures \emph{ex ante}.
There is no general advice on those, yet oftentimes, the inability to MCMC-sample a particular probabilistic model can hint at overlooked logical errors.
An advantage is that logical exclusion criteria restrict the model search space \emph{a priori} and save us from sampling all too many design choice combinations.


\subsubsection{MCMC Sampling}
\label{workflow:sampling}
The fundamental magic which enables probabilistic models is a set of algorithms called ``MCMC Sampling'' (``Markov Chain Monte Carlo'').
There are excellent explanations about this on the web, and I'll restrict the explanation here to what I think is the necessary essence.

MCMC sampling is the procedure which adjusts model parameters to match the data.
It is notoriously time-consuming.

Sampling in probabilistics is analogous to the least squares regression in Frequentist models.
However, in probabilistics, this step is a random exploration of the model parameter space.
This exploration is initiated at a random ``point'' (read: distribution), and the hope is that after a certain ``tuning'' period, this ``non-random walk'' will get stuck in a local optimum.
To make sure the optimum is stable, the repetitive exploration step is run for a sufficiently large number of iterations.
Also, such an optimum should be characterized by the best match of the model values (``posterior distribution'') and the data.
There are technical tricks to increase the chance that the most attractive local optimum is the global one (e.g. run several independent ``chains'' with random starting points; using an adaptive algorithm).
There are many different update rules and algorithms (``Metropolis'', ``NUTS'', ``Hamiltonian Monte Carlo'', \ldots{}) all well explained on Wikipedia.

A defining difference to conventional regression is that the matter and outcome of parameter optimization are distributions of model parameter values (as opposed to point estimates).
I tend to think of the sampling as a procedure that attempts to ``deform'' the shape of the initially set distribution (e.g. a Normal \(\mathcal{{N}}\left(\mu = 0.0,\ \sigma = 1.0\right)\)) to reach optimal agreement with the data distribution (e.g. a slightly narrower, shifted Normal \(\mathcal{{N}}\left(0.6,\ 0.1\right)\) for a hypothetical set of dutyfactors) by adjusting the model parameters.
A bit like pressing a blob of pudding into an animal-shaped form.
Note that what I write above (except maybe the pudding metaphor) is not an exact description, e.g. a starting point should more exactly be called an initial distribution shape, or ``prior''.

The purpose of sampling is clear: explore the parameter space and find model parameters which lead to a best resemblance of model and data.


\subsubsection{Deserialization and Data Flow}
\label{workflow:deserialization}
While ``coming of age'' with statistics, one usually goes through several phases of data organization skills.
Note that I am not judging on beginners here for their work on data, but rather attempt to analyze and generalize my own experience.

Many people (including me) are primed on Excel-like spreadsheet programs, which I in retrospective would call a non-scientific data processing tool.
Non-scientific because it is not easy, maybe even impossible, to establish reproducible work flows in spreadsheets.
Formula links are hidden and prone to break, data types are a mess, cell references are limited, variable definition is impractical, and version control is hindered by the proprietary file format.
However, when taught well, spreadsheets can prime people on good database structure (for example, it is good practice to use the functions \texttt{vlookup}, \texttt{offset}, \texttt{match} and \texttt{indirect} + \texttt{address} frequently).
And, acknowledged, well-made spreadsheet files are often designed to accomplish one given task a time (e.g. they can make a handy ``dashboard'' when connected to external data sources).
Let's call this one-task-one-spreadsheet strategy \emph{``task-boxing''} (``boxing'' as in ``unboxing'', not like the sports), because steps of a larger procedure are solved by individual black box spreadsheets.

When advancing to scripting languages like Python, Matlab, or R, one learns to process spreadsheets and other database-like data sources in programming.
Noteworthy in this regard are ``data frames'' (\emph{cf.} R: \texttt{dplyr}, Python: \texttt{pandas}, Matlab: \texttt{table}), as the programming analogon to a single spreadsheet.
For experienced readers: the multidimensional variant of those are worth exploring (e.g. Python \texttt{xarray}).
Scripting can handle many data tables at once, easily.
But then, one might be tempted to write long scripts which perform the whole analysis procedure in one go, in a \emph{serial} fashion.
This temptation is fostered by notebook-like programming interfaces, such as RStudio/RMarkdown, Jupyter, or the Matlab interface.
I call this extreme strategy \emph{``serialization''}.
The problem is that complex scripts are hard to generalize and maintain.
Complexity should be avoided; good documentation is indispensible.

\textbf{Is there an intermediate way?}
It would be good to break the complex scripts and spreadsheets down to meaningful unit tasks, but what is a good unit?
In my experience, one has to find a middle ground between the antagonist strategies outlined above.
Functional programming can help to split tasks, whereas object-oriented programming can help to define working units and how they are processed.
A good framework must be available for version control (git/mercurial/subversion).
General definitions should be separated from project-specific tasks.
And all steps should be well documented.
The outcome is neither a series of black boxes, nor an unmaintainable monster script: it is a \emph{deserialized sequence of monofunctional building blocks}.
The ultimate goal is to produce fully reproducible and transparent data processing pipelines.


One particularly relevant aspect of deserialization is the storage of intermediate results or whole models.
``Whole models'' refers to the input data, the model structure and the model sampling outcome (``trace'', i.e. the model outcome after fitting it to the data).
The process of MCMC sampling can take a long time (and it usually does).
Model comparison requires many models to be sampled.
Hence, one must be able to write models to hard disk and recall them when necessary.
This may seem trivial, but it is a critical skill.
In particular, when it comes to \hyperref[workflow:prediction]{prediction (Ch. \ref{workflow:prediction})}, it must be ensured that model input data can be dynamically altered after storing and re-loading of the model.
Obviously, the association of model settings, structure, and outcome, must be maintained at all time, e.g. by ``settings'' log files.


I found all my personal requirements met in the library \texttt{pymc} for Pyhton \citep{Salvatier2016}.
% In fact, I started it shortly after I began learning to program in Python.
Compatible choices exist in the \texttt{R} programming language, or language-independent (\texttt{STAN}).
% I would love to learn those latter ones, but never found the time and urge, which is why I got stuck on Python.


\subsubsection{Model Comparison/Selection}
\label{workflow:comparison}
\textbf{``Which Model is the best for my data?''}
As mentioned above, the best of all the logically plausible model designs should not be determined by pure personal preference, but rather by hard, quantitative measures.
This is why this comparison step is also labeled ``model selection''.
The topic is exceptionally well covered in my favorite statistical literature \citep[][Ch. 11 therein]{McElreath2018}, which I will briefly summarize.

The framework of information theory provides tools for quantitative assessment, namely Information Criteria (e.g. WAIC, LOO).
The comparison problem has two balancing effects:
\begin{itemize}
\item complex models tend to fit a model better
\item \ldots{} but too complex models will be prone to ``overfitting''.
\end{itemize}

To illustrate this, try to mentally fit a fifth-order polynomial to a short segment of a quadratic curve: the match might be perfect in the observed area.
However, there are far too many degrees of freedom in the equation which might end up at values that produce weird wiggly curves outside of the data range.
To get around this, modern information criteria are designed to find the best tradeoff between model fit and complexity by quantifying and penalizing overfitting tendencies appropriately.

Model comparison is one of the most powerful aspects of the modeling procedure, because it enables statisticians to make an informed choice about what is going on in the data.
If, in direct comparison, a model including a certain parameter receives less ``support'' than the model lacking it, then it is valid to accept the null hypothesis that the parameter in question is of no relevance for the data.


\subsubsection{Posterior Prediction}
\label{workflow:prediction}
The other extraordinarily powerful tool in the modeling workflow is ``prediction'' \citep{Shmueli2010}.
This feature can serve two relevant purposes, which are technically almost identical.

\begin{enumerate}
\item \textbf{In-Sample Predicition.}
\label{sec:org369b808}
Or: \textbf{Did my model shot hit the data?}
After two weeks of exhaustive sampling (not uncommon in probabilistic statistics), one might get a ``trace'' of sampling values for a particular model.
And ideally, one has stored them to disk (see \hyperref[workflow:deserialization]{deserialization}).
Then, the best of many such models is identified in model comparison.
But how well does this model fit the data?

The common toolboxes for probabilistic inference all come with a feature of ``posterior predictive sampling''.
Quick vocabulary:
\begin{itemize}
\item ``posterior'' means that this happens after the model is tuned to the data.
\item ``predictive'' means that the data vectors fed to the model shall differ from the experimental values
\item ``sampling'' refers to the fact that not only a single mean output is generated, but rather a data distribution (i.e. hundreds, thousands or millions of posterior samples, if you like).
\end{itemize}

This is to be distinguished from the data sampling step (MCMC sampling), and from another trick called prior sampling.
All are called ``sampling'' because of the underlying technical procedure, and they actually mean that we work on data distributions.
However, the purpose of these sampling procedures is different.
MCMC sampling is the process of regression, i.e. of fitting the model parameters to the data.
Prior sampling is used to see if the model structure and the prior settings are plausible.
In contrast, posterior sampling yields values from an already fit model.

You could say that MCMC sampling is like tuning a guitar, prior sampling is analogous to playing on an untuned guitar, and posterior sampling is like playing proper chords and thereby new or old songs.


Why is posterior sampling useful?
I tend to explore the parameter space of my data set (e.g. Fig. \ref{fig:bodyproportions}).
For example, I choose one category of observations (e.g. ``infant female animals of the lower body weight quartile'') and set the probe data to according values.
Then, I can tell the model to generate a number of samples for this setting.
I compare the distribution of these posterior samples to the original data, filtered by the settings specified.
Repeat this for all categories.

Ideally, the predictive samples will match the observed data values.
If so, it is confirmed that the model converged to be a plausible representation (or: ``simplification'') of the real phenomenon that generated the data.
Even more: by sampling a high number of values, one can infer the \emph{distribution} of values of interest for a specific setting, which might otherwise be obscured by a limited sample size.


\item \textbf{Out-Of-Sample Prediction.}
\label{sec:org7e10c89}
Take this one step further: what if the settings I choose are not part of the original data set?
\textbf{Can the model make predictions beyond the data I provided?}
(Percussive playing skills in the guitar analogy\ldots{} or maybe time to admit that analogies can hardly be extrapolated beyond their scope.)
Prediction is the ultimate test to every model: when probing an unobserved or intentionally filtered category of observations, can the model produce outcomes which later stand the test of reality?
With this capability, the model is able to generate informed hypotheses which stimulate future research.
Even if a subsequent observation is impossible (thinking of inferring palaeontological data), the model can yield a distribution of values for a given phenomenon which is most plausible with the actual data.
Another use case is to test evolutionary hypotheses, for example by relating hypothetical traits (e.g. extreme morphology) to limited physical or ecological parameter spaces (e.g. contact forces).

I conclude that ``out of sample prediction'' is where the fun starts.
As I put it above, this feature is one of the biggest advantages of probabilistic models.
\end{enumerate}


\subsubsection{Model Hygiene}
\label{workflow:hygiene}
Having gone through the tideous procedures of acquiring a data set, designing a model, and getting a sampler to run, one might easily be tempted to jump for joy when finally retrieving the first MCMC trace (i.e. a fit model).
However, sampling does not always succeed.
It can fail bluntly (with an explicit error message), but with a trace you are already past that hurdle.
Worse, it can also fail in numerous non-obvious regards, and it is crucial to diagnose whether this happened.

Several diagnostic quantities are available:
\begin{itemize}
\item \texttt{divergent samples}: occur if the sampler occasionally leaves the local optimum, even after tuning
\item \texttt{energy}: quantifies whether the parameter space was well explored
\item \texttt{effective sample size}: check whether is enough sample coverage in the optimal region
\item \texttt{r hat}: (Gelman-Rubin statistic) measures if multiple, independent sampling ``chains'' converged, i.e. end up in the same local optimum
\item \texttt{auto correlation}: make sure the sampler did not get stuck in cyclical patterns
\end{itemize}

More such ``hygiene quantities'' exist.
I call them ``hygiene'' because they are like body hygiene: you might live without for a certain period, but rather sooner than later people around you will smell it.
Luckily, many diagnostics are readily delivered with the actual results by the modeling toolbox, so the hurdle to check them is minimal.
Model diagnostics make a great, long supplementary table.
I omit presentation of the diagnostics in this chapter, but you would probably smell if they were not calculated and positive for the main selected models.

\FloatBarrier
\clearpage
\section{Application: Baboon Kinematics}
\label{sec:orge39e02f}
After this long, conceptual introduction, let us finally get to ``the meat'' and apply the procedure to a real data set with Python and \texttt{PyMC}.
This requires me to gradually present the data which was acquired by \citet{Druelle2021}, and what I made of it.

\subsection{Data Preparation}
\label{sec:orgeaaa58c}
\subsubsection{Data Overview}
\label{intro:dataprep}
% Raw data is available upon request, and will be supplemented to future published manuscripts.
Data was processed via a sequence of python scripts which can already be found here: \begin{center}\href{https://git.sr.ht/\~falk/papio\_fcas}{\nolinkurl{https://git.sr.ht/~falk/papio_fcas}}\end{center}
These scripts complete the following tasks:
\begin{itemize}
\item import data per stride cycle to python
\item store master data (\textbf{subject info} e.g. age, and \textbf{spatiotemporal gait variables} e.g. relative speed)
\item calculate joint angle temporal profiles
\item remove end-start difference (make ``cyclical'')
\item transformation to the frequency domain via Fourier Series
\item temporal alignment to remove phase differences in whole-limb movement
\item \textbf{posture:} extraction of affine components (mean \chng{joint} angle, amplitude = effective range of motion/eROM)
\item \textbf{coordination:} Principal Component Analysis of non-affine remainder
\item perform statistical analysis
\end{itemize}


Highlighted above are the different categories of data (see Tab. \ref{tab:parameters} for a detailed overview).


\begin{table}[p]
\caption{\label{tab:parameters}Overview of data parameters.}
\centering
\begin{footnotesize}
\begin{tabular}{llll}
\hline
\textbf{category} & \textbf{parameter} & \textbf{units} & \textbf{description}\\[0pt]
\hline
\hline
subject & subject & - & names of the subjects\\[0pt]
(subject) & age & years & time since birth\\[0pt]
subject & ageclass & \{infant, adolescent, adult\} & three disjunct ageclasses\\[0pt]
subject & sex & \{female, male\} & sex of the animal\\[0pt]
(subject) & bodymass & kg & weight at recording\\[0pt]
(subject) & leg length & m & leg length\\[0pt]
(subject) & bmi & kg/m & bodymass divided by body length\\[0pt]
\hline
stride & dutyfactor & 1. & fraction of stride in ground contact\\[0pt]
stride & distance & relative & distance covered by stride (m),\\[0pt]
 &  &  & normalized by reference segment length (m)\\[0pt]
stride & frequency & \(Hz = s^{-1}\) & reciprocal stride duration\\[0pt]
stride & speed & rel. (\(s^{-1}\)) & (rel.) stride distance divided by duration\\[0pt]
stride & clearance & 1. & how much \((\%)\) the limb is\\[0pt]
 &  &  & shortened during the stride\\[0pt]
stride & trunk angle & radians & mean trunk segment angle (rel. to upright)\\[0pt]
stride & stride \(PC_{i}\) & arb. units & PCA of distance, frequency, speed\\[0pt]
\hline
posture & mean angle & \(\pi\) & zero'th Fourier Coefficient of joint angles\\[0pt]
posture & amplitude & \(\pi\) & Fourier Amplitude (related to\\[0pt]
 &  &  & effective joint range of motion)\\[0pt]
\hline
coordination & \(PC_{i}\) & 1. & PCA of non-affine components of\\[0pt]
 &  &  & the Fourier coefficients of all joints\\[0pt]
\hline
\end{tabular}
\end{footnotesize}
\end{table}


In total, \(40\) stride cycles from \(17\) subject individuals entered the analysis.
The goal of the subsequent analysis is to quantify the interrelation within and between these categories of parameters.
This has to regard their implicit hierarchical structure (\emph{subject} \(\rightarrow\) \emph{stride} \(\rightarrow\) \(\lbrace\) \emph{posture}, \emph{coordination} \(\rbrace\) ).


\subsubsection{Segment- and Joint Angles}
\label{sec:orgd5b5698}
In the parameter overview table, several angles are listed.
Firstly, there is the trunk angle, which is a \textbf{segment angle}.
A segment is a more or less rigid subunit of a body which lies between two joints, normally it is associated with a bone or skeletal unit.
Segment angles (here: in two spatial dimensions) are calculated as the angle of a segment relative to the global reference frame.
For example, the trunk angle is herein defined as the angle between the head-hip vector and the vector parallel, but opposite in direction to the gravitational acceleration vector (i.e. pointing upwards; approximated from the video y-direction).
By this definition, if you sit straight on a chair right now, your trunk angle would be zero; if you lean back, it becomes negative, and if you lean forward to tie your lace it gets positive.

Segment angles of coupled series of segments (``limbs'') are highly correlated, which can be problematic for statistical analysis.
To illustrate this, imagine a limb in which the knee joint is fixed, i.e. held at a constant angle throughout the stride cycle.
The thigh and the shank segments will both have temporally varying segment angle profiles, but the correlation of these profiles is perfect.
Further, imagine that there is an effect changing the hip angle (a joint angle) temporal profile under certain circumstances; that effect will be visible in the shank \textit{segment angle} as well, although the knee does not move.
The reason is the ``fixed knee'' constraint introduced here for illustration; the correlation is hardly less with mobile joints (the distal segments just hang on a chain downstream of a given joint, and never fully cancel out the proximal movements).


\textbf{Joint angles} measure the difference of two segment angles, which is equal to the angle between two segments.
Joint angles are also interdependent through musculoskeletal coupling and the influence of gravity.
Imagine an animal holds its trunk always perfectly vertical for some reason.
As in the scenario above, a change of the hip angle profile will be visible as compensation in the more distal joints and segments.
The reason is the ``fixed trunk'' constraint, and that the limb as a whole has to compensate for the change.

I want to submit either of these sets of angles to the FCAS procedure \citep[previous chapters, \textit{cf.}][]{Mielke2019}, to achieve temporal alignment and the separation of posture and coordination measures.
However, which angles of those mentioned above are more appropriate?
In other words: which of the constraint scenarios is more realistic?
Joints are always mobile, as are segments, and neither of the extreme constrains above are realistic for freely moving animals.
Nevertheless, some observations tip the balance towards using joint angles, in my opinion.
Muscles (the ``motors'' in animal locomotion) are usually changing joint angles.
According to my observations, there is a tendency to reduce joint angle change, or limit it to short temporal intervals (probably due to energetic optimization).
In contrast, the change of segment angles is of larger magnitude, and probably optimized to exploit gravity in pendulum-like mechanics.
Another observation comes from \emph{in silico} tests.
When using a simulated two-segment system with realistic segment lengths, computing random joint angle profiles in a reasonable range of motion, I observe that correlation is high (\(O(0.8)\)) despite the random input values.
I conclude that the underlying mechanism of movement and the spatial arrangement of the segments increase the correlation issue with segment angles.
I think of joint angles as being a kind of spatial differential/derivative of segment angles, which is why they are insensitive to issues of the absolute position.
This can be advantageous for tackling kinematic research questions, but disadvantageous for kinetic research (in which the direction of gravity matters).


For the present analysis, I chose joint angle profiles as the measures which enter the FCAS procedure.
The trunk angle, which appears to be variable among different strides in the data set (and might hold predictive value), is included in some of the calculations below as a spatiotemporal gait variable.


\subsubsection{Dimensionless Spatiotemporal Gait Variables}
\label{prep:dimensionless}
Except for the trunk angle (in units of \(\pi\), where \(\pi\equiv 3\)), all spatiotemporal gait variables are normalized, i.e. made dimensionless \citep[according to][]{Hof1996}.
The reference \(l_0\) for spatial parameters is the leg length (hip-knee-ankle).
Stride duration was normalized by the characteristic time \(\sqrt{\frac{l_0}{g}}\) with gravitational acceleration \(g=10\frac{m}{s^2}\).
Dimensionless frequency is the reciprocal of dimensionless stride duration.
Speed was divided by \(\sqrt{l_0 g}\) to get dimensionless speed.

The rationale behind using dimensionless parameters is the intention to compare the animal's performance at points where their locomotion is equally costly (in terms of energy).
This is intuitive in the case of stride length: a stride of a given distance (e.g. \(1\ m\)) might be a small step for an adult animal, but a huge leap for an infant.
When normalized with a meaningful morphological reference, comparison of the observations is at least a bit more fair (with regard to the animal's energy investment).

Note that there is no pressing reason to perform this normalization, and it is by no means clear whether models improve with it.
The dimensionless parameters are most likely correlated to their unnormalized counterparts.
And repeating the actual calculation with the raw spatiotemporal parameters showed that the outcomes are not all too different from those presented below.
On the other hand, interpretation of the outcome is facilitated by the normalization, because all effects due to morphological differences are supposedly summarized on the body proportion predictor(s).


\subsubsection{PCA of Gait Variables}
\label{prep:stridepca}
It turned out that some of the models (namely the more complex ones involving posture and coordination) did not sample well when all the spatiotemporal gait variables listed above were included as predictors.
However, a strong correlation between some of them is expected and confirmed by calculation.
Therefore, a useful trick to enable sampling for the complex models is a dimensionality reduction via principal component analysis (PCA).

A PCA of stride distance, stride frequency, and speed (all dimensionless) was performed (``stride PCA'', Tab. \ref{tab:stridepca}).
The three input parameters were standardized so that they equally contribute to the components.
The first two principal components capture \(99.8 \%\) of the variance, justifying an optional reduction to two parameters via PCA transformation.
PCA space is orthogonal, i.e. there is no correlation between the principal components (thus we do not have to model a multivariate predictor block).
This means that PCA can be favorable for sampling even if dimensionality is retained.
The inverse transformation allows to convert predicted PC values back to the original parameters.
\bigskip

\begin{table}[p]
\caption{\label{tab:stridepca}Stride PCA: variance covered (\%) and eigenvector loadings.}
\centering
\begin{tabular}{l|rrr}
 & d.s. distance & d.s. frequency & d.s. speed\\[0pt]
\hline
PC1 (\(69.1 \%\)) & -0.39 & -0.61 & -0.69\\[0pt]
PC2 (\(30.7 \%\)) & -0.86 & +0.50 & +0.04\\[0pt]
PC3 (\(0.2 \%\)) & -0.32 & -0.62 & +0.72\\[0pt]
\end{tabular}
\end{table}

\clearpage
\subsection{Subject Parameters}
\label{sec:orgb7153d3}
The first order model parameters are the subject parameters, because they are characteristic and more or less constant for each of the animal subjects under research.
The purpose of this section is to find out how they interrelate.

Within this group of parameters, \emph{sex} stays constant for a given subject.
Of the \(17\) subjects included, \(5\) were male.
By study design, \emph{ageclass} was also constant over recordings for all subjects in the data set (subjects might be measured at slightly different ages, however recording periods were narrow, and no subjects of transitional ages were considered).
A total of
\(4\) adults (\(4/0\) females and males, respectively),
\(6\) (\(4/2\)) adolescent
and \(7\) (\(4/3\)) infant
\emph{Papio anubis} entered the final data set.
Subjects were intentionally selected so that the ages of the classes do not overlap, i.e. to have disjunct ageclasses.
Note that, in principle, ageclass and sex can be interrelated, e.g. if there is a bias in the experimentally selected sex ratios per age group.
This is indeed the case in our data set: in the ``adult'' class, only females were measured.
However, this bias is neither coincidental nor intentional, but owes to the group structure and social habits of baboons.
It forces us to assume that locomotion of adult \emph{Papio anubis} is indifferent to sex, or that the sex difference in adults can be inferred from the observed difference in subadults.
More on this case below.


The \emph{bodymass} of the animals was determined for each recording (averages for infant/adolescent/adult individuals: \(3.0/10.2/13.1\ kg\)).
This means that different strides of the same subject would associate with slightly different bodymasses if bodymass changed within the narrow time period of recording.
Furthermore, bodymass can be associated with the other subject parameters (e.g. trivially with age, because individuals grow).
For the subsequent analyses, this interrelation of subject characteristics needs to be taken into account.

The two leg long bone segments (hip-knee-ankle) were chosen as a size reference for normalization of distance values. They measured \(0.27/0.41/0.43\ m\) (inft./adol./adult) per ageclass on average.
Adding the length of the torso segment (head-hip), we retrieved a total body length proxy, which was used to calculate a ``body mass index'' (BMI, averages \(5.0/11.4/14.1\ kg/m\) for the respective ageclasses).
This is no proper scientific BMI, but one solely for demonstration purposes in this document.
\medskip

To prepare the decision on how to include bodymass, leg length and BMI in the subsequent models, behold the first \textbf{probabilistic model}.
It is a rather simple one, modeling bodymass as a function of ageclass and sex.
I will use it to settle some fundamentals about how I apply the modeling procedure herein.

\subsubsection{The Bodymass Model}
\label{sec:orge4d1e9b}
Take the following linear model for bodymass, with bodymass \(\theta\), intercept \(\alpha\), data vectors \(v\), slopes \(\beta\) and residuals \(\epsilon\):

\begin{equation} \theta \sim v_{1}\cdot\alpha + v_{male}\cdot\beta_{male} + v_{adol}\cdot\beta_{adol} + v_{inft}\cdot\beta_{inft} + \epsilon \label{eq:proportions} \end{equation}

Note that all vectors \(v\) in eqn. \eqref{eq:proportions} are boolean column vectors, containing ones for data rows of a given category and zeros on all other rows (\(v_{1}\) is an all-true boolean specially used for the intercept).
This way, the decisive slopes are only added to the data rows which match a given category: for example, only the entries where \(v_{male}\) is \texttt{True} get the value of \(\beta_{male}\) added.

A brief recap to homogenize vocabulary:
\begin{itemize}
\item The ``left handside'', ``independent'', or ``outcome'' variables (often called \(\theta_{i}\)) are termed \emph{observables} in this text. Acknowledged, all parameters are ``observed'' (or ``dependent'', or ``outcome''\ldots{}), but observables are the ones in focus of a given chapter.
\item The ``right handside'', ``dependent'', or ``input'' variables are usually described as \emph{predictors}. Again, this label is my arbitrarily changing choice.
\item Model components which do not stem from the data table are called \emph{(model) parameters}; in the case of linear models these are intercepts, slopes and the residual.
\end{itemize}

I will explain all components in detail in the following paragraphs.

\begin{enumerate}
\item \textbf{Intercept \(\alpha\):}
\label{sec:org034f04c}
Each model ``starts'' with an intercept (though it wouldn't need to, or the intercept could be implicit).
For continuous variables, the intercept is intuitive to understand: it is the observable value when the predictor is zero.
With categorical variables, the intercept value is the value observed for a given ``reference'' set/selection of parameter values.
For example, in the bodymass model below, the intercept is approximately corresponding to the average bodymass of adult, female animals.
The choice of reference is done by the statistician, it is an arbitrary one, and sometimes only visible by the category changes associated with slopes.

\item \textbf{Slopes \(\beta\):}
\label{sec:org2c291e4}
Slopes quantify the change in the value of the modeled observable (e.g. bodymass) when changing along a parameter axis (e.g. sex from female to male).
Some mathematical explanation:
\begin{itemize}
\item For binary categorical values, such as sex, this is simple: set the corresponding value for ``female'' to \(0.0\) and that for male to \(1.0\) and the slope (``female \(\rightarrow\) male'', or just ``male'') will be their modeled difference in bodymass.
\item For multi-categorical values (e.g. ageclass, three possible categories), one reference category is chosen (e.g. adults), and separate slopes are modeled for each of the other groups (i.e. ``adlt \(\rightarrow\) adol'' and ``adlt \(\rightarrow\) inft''). Because for each slope, only the target category is associated with \(1.\) and all others with \(0.\), the slopes determine the pairwise distance of the target categories and the reference (the category associated with the intercept). No animal is infant and adolescent for a single observation (categories are mutually exclusive), hence no observation will get associated with both slopes.
\item For continuous values (e.g. age), the slope is related to the numerical values in that parameter. Parameter ranges must be considered when evaluating effect size. It usually makes sense to center or even normalize the parameter to make slopes comparable.
\end{itemize}

\item \textbf{Residual \(\epsilon\):}
\label{sec:orgbf53734}
Even with all measured parameters, some unexplained variation remains in models of partly random processes.
This can be measurement ``noise'', or simply unexplained variation.
Its order of magnitude is estimated in the sampling procedure as the ``residual''.
The terms ``residual'', ``epsilon'', and ``standard deviation'' (in model context) can be considered approximately synonymous (\emph{:statistician-smiley:}).

\item \textbf{Prior Choice and Sampling:}
\label{sec:orgf31f4ce}
Because I use a probabilistic modeling framework (the python library \texttt{pymc}), the actual values of the model parameters are determined in MCMC sampling (see Ch. \ref{workflow:sampling}).
This procedure requires start values (``priors''), for which I usually take the mean and standard deviation of the observed values (because the sampled model values should certainly fall in that range).
Also, there is a whole lot of voodoo about setting the correct distribution type for a given parameter.
Usually (with the sample size encountered in this data set), it is hard to falsify the assumption that model values, logarithmized in obvious cases, are approximately normally distributed \citep{Downey2013}.

Finally, the MCMC sampling itself asks for some choices by the researcher.
I chose something close to industry standard (No U-Turn Sampler ``NUTS''; sufficient tuning and sampling steps; twenty chains; Student's T distribution for the posterior) and verified \emph{ex post} that sampling went well (``hygiene'').

\item \textbf{Model Comparison:}
\label{sec:orgd46c837}
I skip this here for clarity.
Usually, one would have to argue why the chosen model is the most appropriate one (though of course limited by availability of parameters).
More on it when we get to spatiotemporal gait variables.
For bodymass, the model choice is rather trivial, there is not many options but to use the other subject parameters as predictors.
I do not use leg length and BMI as predictors for bodymass, because they share a hierarchy level, are correlated, and thus the idea of one predicting the other might falsely imply causality.

\item \textbf{Data:}
\label{sec:org71ae22a}
Because there is usually only one bodymass per subject animal in our data set, the data set onto which I apply the bodymass model is reduced (\(17\) observations).
For one animal which was measured at two bodymasses, the average value was used.

\item \textbf{Transformations:}
\label{sec:org1dc49e0}
As an additional technical complication, bodymass (and the other body proportions) have to be transformed.
For most body measures, negative values are implausible, e.g. a negative bodymass does not exist.
Also, one can usually observe that the Normality assumption, or in our case a Normal prior distribution, is better met when log-transforming the values.
In consequence, predictions become more accurate for models of logarithmized measures.
This was also the case for the current data set.
Therefore, the body parameters presented here were transformed with the natural logarithm for modeling, and all values untransformed with the Euler exponential for presentation.
\end{enumerate}


\FloatBarrier
\subsubsection{Bodymass is Age-Dependent (Surprise!)}
\label{bodymass:results}
\begin{table}[p]
\caption{\label{tab:bodyproportions}Results of the Bodymass Model.}
\centering
\begin{tabular}{|l|r|c|c|}
\hline
\textbf{parameter} & \textbf{value} & \textbf{interval} & \textbf{\chng{cred.}}\\[0pt]
\hline
\(\alpha\) & \(+12.3\) & \(\left(+10.2, +14.8\right)\) & \\[0pt]
\(\beta_{male}\) & \(+0.6\) & \(\left(-1.9, +3.7\right)\) & \\[0pt]
\(\beta_{adol}\) & \(-2.4\) & \(\left(-4.6, +0.4\right)\) & \\[0pt]
\(\beta_{inft}\) & \(-9.4\) & \(\left(-10.1, -8.6\right)\) & *\\[0pt]
\(\epsilon\) & \(+2.6\) & \(\left(+1.7, +3.8\right)\) & \\[0pt]
\(\nu\) & \(+52.1\) & \(\left(+15.1, +94.0\right)\) & \\[0pt]
\hline
\end{tabular}
\textit{\chng{Asterisk in the ``cred.'' column indicates model parameters for which the credible interval does not include zero.}}
\end{table}


As expected, bodymass and ageclass are associated (Tab. \ref{tab:bodyproportions}).
But how much?
On average, adolescents are \(2.4\ kg\) and infants are \(9.4\ kg\) lighter than adult individuals.
The effect of an animal being infant is deemed relevant because the credible interval does not include zero.
The credible interval is the smallest possible value range to contain \(94\ \%\) of the values, i.e. from \(3\ \%\) to \(97\ \%\) quantile of the samples; termed ``highest (probability) density interval'' or HDI.
That interval is comparable to the ``standard error of the mean'' of a given slope, and has to be seen in relation to the intercept and model residual to judge if an effect is large or small, i.e. relevant or not.
The difference for the adolescent group exemplifies this: it is in the order of the \(\epsilon\), and the HDI contains zero.
Although we know that adolescents weigh less than adults, the data set is insufficient and effect size too low to give waterproof statistics.

In contrast to age, sex seems to have no effect on bodymass (keeping in mind that there are generally few and no adult males in the sample; slope: \(+0.6\ [-1.9, +3.7]\ kg\) ).

Finally, the parameter \(\nu\) (``nu'') deserves some explanation, to demonstrate another neat modeling trick \citep{Wiecki2013}.
An often disputed, but indispensible assumption in conventional statistics is the Normality assumption (i.e. that values of a variable are normally distributed).
Likewise, in probabilistic modeling, one can choose the distribution \emph{type} (e.g. Normal) of a model parameter, which together with the distribution \emph{properties} (e.g. \(\mu = 0\), \(\sigma = 1\)) is the \textbf{prior} for that parameter.
Distribution properties are adjusted in MCMC sampling, and the prior only influences the result when sample size is very small.
In contrast, the distribution type stays fixed and has major influence on the outcome.
Hence, choosing a Normal here might need some justification.
Part of that justification comes from model comparison (see Ch. \ref{workflow:comparison}).
But in case of the Normal distribution, we can use a more general distribution (Student's T) to actually measure how ``Normal'' our data is.
Student's T has an extra parameter, which is \(\nu\) or the ``degree of freedom''.
The larger \(\nu\), the higher the resemblance to a Normal distribution.
In contrast, on lower \(\nu\) values, Student's T has more ``weight in the tails'', accounting for ``outliers'' which are unnormally far from the mean.
For our bodymass model, the sampler converged at \(\nu = 52.1\).
This is a relatively high value, confirming that bodymass is approximately normally distributed.
Usually, model comparison favors the use of a Normal posterior in such cases.


\FloatBarrier
\subsubsection{Multi-Level Modeling}
\label{sec:org25b6e1a}
For all following models, there is the option to include the bodymass parameter as a hierarchical (better: multi-level) parameter.
This means that, when we have a model which includes a slope for (centered) bodymass, we actually make it three slopes (one for each ageclass). I will note this as \(\beta_{bm\mid age}\).

As mentioned above, groupwise centering bodymass (\(cbm_a = bm_a - mean(bm_a)\quad \forall a = {ageclasses}\)) can be useful to facilitate interpretation of the model outcome.
If data values are centered, the slopes are relative to a mean, and the intercept will give a value at the average of all continuous parameters (in this case: at average body weight).
And because age has such a high impact on body weight, it makes sense to center the groups individually, to get relatively lighter or heavier individuals per ageclass separated.

The complexity of this matter is not to be underestimated.
Just to review our options to model bodymass:
\begin{itemize}
\item inclusion or exclusion
\item log-transform or not
\item not centering or centering to population mean or to ageclass mean
\item multi-level: one slope for the whole population or slope for each of the ageclasses
\end{itemize}

All of these choices in combination affect the model, and need to be compared.
Even worse: they affect how to best model other parameters (if \texttt{bm|age} is used, \texttt{leglength|age} might be a worse choice than \texttt{leglength} alone, but if \texttt{bm} is a population slope, \texttt{leglength|age} might become the model of choice).
Multi-level modeling gives a lot of options for model comparison.
These will be handled below.


\subsubsection{Multivariate Posterior Structures: Mor(e)phometrics}
\label{sec:orgf2c37c2}
Together with bodymass, I modeled leg length (ankle-knee-hip distance, cumulated) and body mass index (BMI, bodymass divided by ankle-knee-hip-head distance).
The model formula from above remains unchanged, except for the left side.
But that, namely ``multiple parameters on the left side'', is a concept on its own.
The solution is a \textbf{Multivariate Posterior}.
I imagine this as multiple models, sampled in parallel, but cross-connected through the data and the correlations (like a ladder with steps of chewing gum, floating in free space\ldots{} yes, I'm running out of metaphors).
In an unconnected model, the MCMC sampler would explore the parameter space randomly, and might be ``at different ends'' for two variables at a given time.
In contrast, when they are connected by a multivariate posterior, the sampler path is also connected, and therefore a positive correlation of two parameters reflects in the values the sampler sees simultaneously.
The connection can be either fixed (empirical correlation, based on the data) or inferred.
The correlation is crucial for predictive sampling to avoid unplausible parameter combinations.


Let us rehearse this concept on the body proportions, where it is rather intuitive.
Body proportions (including bodymass) are highly correlated.
For BMI, this is trivial: it is defined as the quotient of two other measures.

We can simply calculate the correlation of the three present observables from the raw data.
This would be the \emph{empirical} correlation.
However, according to our statistical theory, the data we acquied is just a sample from the true, underlying distributions of the observables.
So the correlation might be incomplete or inexact.
Probabilistic statistics is the attempt to infer that true underlying distribution, and when it is known, one can calculate a potentially more exact correlation (\emph{inferred} correlation).
The inferred correlation is not \emph{per se} more exact; imagine a situation where correaltion is close to \(\pm 1\) and the sampler might have problem with parameter bounds.
It depends on the data which one works best (yay, more model comparison!).


In my toolbox of choice, \texttt{PyMC}, a multivariate posterior can be initialized with either (i) the empirical or (ii) the inferred correlation structure; a third choice is to use (iii) no correlation.
For cases (i) and (ii), I introduce the observables as a multivariate Student's T distribution.
The empirical correlation (i) enters the model in form of the Cholesky matrix calculated from the data\footnote{Subtle technical complication: this variant does not allow the inclusion of an explicit model residual; in such cases I report the standard deviation of the observables as model residuals.}.
To get inferred correlation (ii), I instead initialize the \texttt{MvStudentT} with a so-called LKJ Prior \citep{LKJ2009}, which allows me to quantify the posterior correlation.
Finally, uncorrelated posterior (iii) do not need an \texttt{MvStudentT}, but go with independent \texttt{StudentT}'s; the system can sample multiple observables at once.

Note that multivariate blocks will also be relevant on the predictor side.
The only difference between observables and predictors in modeling is the somewhat arbitrary choice of which variables we define as ``dependent'', and which as ``independent''.
After all, they are all just distributions, as probabilistic modeling is about juggling distributions.
Tricky detail: a multivariate predictor block must be initialized with inferred correlation (LKJ), because this block contains inferred slopes and no observed data, and thus the correlation is that of the slopes, and not of the data.


\begin{table}[p]
\caption{\label{tab:proportions_empiricalcorrelation}Body proportions: empirical cross correlation. Asterisk indicates parameter pairs in which the Pearson Correlation \(p\)-value is less than \(0.05\).}
\centering
\begin{tabular}{l|lll}
 & log( body mass (kg)) & log( leg length (m)) & log (bmi (kg/m))\\[0pt]
\hline
\chng{log (body mass (kg))} & \(1\) & \(+0.97\) * & \(+1.00\) *\\[0pt]
log (leg length (m)) & \(+0.97\) * & \(1\) & \(+0.94\) *\\[0pt]
log (bmi (kg/m)) & \(+1.00\) * & \(+0.94\) * & \(1\)\\[0pt]
\end{tabular}
\end{table}

\begin{table}[p]
\caption{\label{tab:proportions_correlation}Body proportions: inferred cross correlation. Asterisk indicates values for which the HDI does not include zero.}
\centering
\begin{tabular}{l|lll}
 & log (body mass (kg)) & log (leg length (m)) & log (bmi (kg/m))\\[0pt]
\hline
\chng{log (body mass (kg))} & \(1\) & \(+0.49\) * & \(+0.92\) *\\[0pt]
log (leg length (m)) & \(+0.49\) * & \(1\) & \(+0.18\)\\[0pt]
log (bmi (kg/m)) & \(+0.92\) * & \(+0.18\) & \(1\)\\[0pt]
\end{tabular}
\end{table}

\begin{table}[p]
\caption{\label{tab:proportions_predictors}Body proportions: model results. Note that these values refer to log-transformed body proportions. }
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
 & intercept & female  & adult  & adult  & \(\epsilon\)\\[0pt]
 & & \(\rightarrow\) male & \(\rightarrow\) adolescent & \(\rightarrow\) infant & \\[0pt]
\hline
\chng{log (body mass (kg))} & \(+2.51\) & \(+0.05\) & \(-0.21\) & \(-1.44\) * & \(\pm 0.19\)\\[0pt]
log (leg length (m)) & \(-0.87\) & \(+0.03\) & \(-0.03\) & \(-0.46\) * & \(\pm 0.08\)\\[0pt]
log (bmi (kg/m)) & \(+2.60\) & \(+0.02\) & \(-0.18\) & \(-1.01\) * & \(\pm 0.16\)\\[0pt]
\hline
\end{tabular}
\end{table}


In the case of our group of body proportions, the empirical correlation is close to unity (Tab. \ref{tab:proportions_empiricalcorrelation}).
It is less strong with the inferred posterior correlation (Tab. \ref{tab:proportions_correlation}): bodymass is highly correlated with both leg length and BMI, but the latter are not correlated to each other.


The multivariate model also infers the relation to the primary subject parameters (sex and ageclass, \emph{cf.} Tab. \ref{tab:proportions_predictors}).
The values for bodymass are identical to those reported above (Tab. \ref{tab:bodyproportions}), but here the outcome is shown for the log-transformed observables.
The results for the additional quantities are consistent with those from bodymass, except that we see that leg length of adolescents is almost identical to that of adults (whereas in bodymass, the difference is more pronounced).

And there are many more body size measures (broad category: morphometrics) which could be measured and included.
(There is \emph{always} another parameter which one could include in the model.)
BMI was intentionally introduced as a redundant parameter and will not be included in subsequent models.
Bodymass and leg length are highly correlated, and if both are part of another model (e.g. a model on coordination), it might be hard to distinguish which of them is causally responsible for an observed effect.
On the other hand, I demonstrated that bodymass and leg length are slightly different with regard to the adolescent individuals.
Hence, the question whether or not to include either, both, or none of these two parameters in the more complex models to come remains to be evaluated.

\subsubsection{Posterior Predictive Sampling}
\label{sec:org805e0cf}

\begin{figure}[p]
\centering
\includegraphics[width=.9\linewidth]{figures/bodyproportions_predictions.pdf}
\caption{\label{fig:bodyproportions}Subject parameters: raw data (white circles) and model predictions (distributions).}
\end{figure}

Because the body proportion problem involves still relatively few parameters, a rather complete visualization is possible (Fig. \ref{fig:bodyproportions}).
Some observations:
\begin{itemize}
\item Comparing the raw data to the predicted values confirms plausibility of the predictions.
\item The effect of modeling in log space is visible in the narrower distribution of groups with lower values.
\item Groups with fewer observations (e.g. adults) tend to be wider, reflecting the influence of relatively wide priors and a high uncertainty in these classes.
\item Out-of-sample prediction is possible: adult males were not observed, but their model values get tuned by the observations of partly similar subsets of data (i.e. other sex/age combinations).
\end{itemize}

The visual comparison captures all relevant info in this simple example case.
For subsequent models, such plots are equally valuable, yet the occurrence of continuous predictors and the increase in complexity require a lot more filtering and adjustment.


\subsubsection{Summary: Subject Parameters}
\label{sec:orge0c65f9}
The example of a bodymass model has already taken us deep into the modeling world.
We explored simple relations (bodymass as a function of ageclass and sex, and the body proportion cross correlations).
This involved a linear model with rather few components.
It is a trivial finding that bodymass depends on the ageclass of our subject, and we will see how that can be incorporated in subsequent models.
With regard to the interrelations of our body proportion quantities, we encountered multivariate posteriors and saw how they can serve to infer correlations among the observables.
Visual comparison of raw data and model predictions confirmed that the model converged to plausible results.

All this was more a playground to rehearse and apply some basic modeling concepts, establish vocabulary and visuals, and to prepare some upcoming design decisions when moving on to other quantities of relevance.

\FloatBarrier\clearpage
\subsection{Spatiotemporal Gait Variables}
\label{sec:org69bec74}
With this knowledge about the subject parameteres, I will proceed to the next parameter category: the spatiotemporal gait variables, also called gait variables, spatiotemporals, or stride cycle parameters \chng{(Tab. \ref{tab:spatiotemporals})}. Those are:
\begin{itemize}
\item dutyfactor
\item diml. stride distance (relative to lower leg length)
\item diml. stride frequency
\item diml. speed
\item clearance
\item trunk angle
\end{itemize}


\begin{table}[p]
\begin{change}
\caption{\label{tab:spatiotemporals}Observed spatiotemporal gait parameter value ranges.}
\centering
\begin{footnotesize}
\begin{tabular}{l|llllll}
\textbf{gait variable} & \textbf{units}  & \textbf{mean} & \textbf{standard deviation} \\[0pt]
\hline
clearance              & \(\%\)          & \(0.35\) & \(0.05\) \\[0pt]
stride distance        & \(m\)           & \(0.57\) & \(0.16\) \\[0pt]
stride duration        & \(s\)           & \(0.56\) & \(0.14\) \\[0pt]
dutyfactor             & \(1\)           & \(0.63\) & \(0.07\) \\[0pt]
stride frequency       & \(Hz\)          & \(1.92\) & \(0.55\) \\[0pt]
speed                  & \(\frac{m}{s}\) & \(1.10\) & \(0.41\) \\[0pt]
trunk angle            & \(rad\)         & \(0.57\) & \(0.18\) \\[0pt]
\end{tabular}
\end{footnotesize}
\end{change}
\end{table}


The ``diml.'' indication refers to ``dimensionless'', which means that the spatiotemporal parameter \chng{can be normalized, according to the concept of dynamic similarity} \citep[see Ch. \ref{prep:dimensionless};][]{Hof1996,Alexander1983}.
Just as bodymass and its relation to the other subject parameters was the focus of the previous chapter, we now move spatiotemporal gait variables to the ``left handside'' of the equation, i.e. they are observables, and we guess that they will be in part predicted by subject parameters.



\subsubsection{Model Design}
\label{sec:org554cfcf}
As before, some design decisions should be justified.

\begin{enumerate}
\item \textbf{Parameter Correlation:}
\label{sec:orgccc0e5d}
The spatiotemporal gait variables are intrinsically correlated.
This can have trivial reasons, such as their definition (e.g. speed is the product of distance and frequency).
In other cases, it is at least physically and physiologically plausible (e.g. lower dutyfactor at higher speeds).
These correlations must be quantified, which can be part of the sampling procedure.
As with moving from bodymass to a set of body proportions, we will have a connected set of observables.
This can also be incorporated in the mathematical descriptions.


The favored model in this case was one which got programmed on the \emph{empirical} correlation of spatiotemporal gait variables (Tab. \ref{tab:stridecorrelation}).
The speed parameter correlation can elucidate how animals reach higher speeds: they walk at increased stride frequency and cover a larger distance, whereby the dutyfactor tends to reduce.
This, however, implies no consistent change in clearance, nor does it depend on mean trunk angle.

\begin{table}[p]
\caption{\label{tab:stridecorrelation}Empirical Cross Correlation of Spatiotemporal Gait Variables. Significant correlations (as per Pearson's correlation coefficient and test for non-correlation) are marked by asterisks. \emph{d./d.s.}: ``dimensionless (stride)'' parameter.}
\centering
\begin{footnotesize}
\begin{tabular}{l|llllll}
 & clearance & d.s. distance & dutyfactor & d.s. frequency & d. speed & trunk angle\\[0pt]
\hline
clearance & \(1\) & \(+0.32\) * & \(-0.42\) * & \(-0.01\) & \(+0.15\) & \(+0.38\) *\\[0pt]
d.s. distance & \(+0.32\) * & \(1\) & \(-0.57\) * & \(+0.09\) & \(+0.52\) * & \(-0.12\)\\[0pt]
dutyfactor & \(-0.42\) * & \(-0.57\) * & \(1\) & \(-0.52\) * & \(-0.72\) * & \(-0.27\)\\[0pt]
d.s. frequency & \(-0.01\) & \(+0.09\) & \(-0.52\) * & \(1\) & \(+0.89\) * & \(+0.12\)\\[0pt]
d. speed & \(+0.15\) & \(+0.52\) * & \(-0.72\) * & \(+0.89\) * & \(1\) & \(+0.07\)\\[0pt]
trunk angle & \(+0.38\) * & \(-0.12\) & \(-0.27\) & \(+0.12\) & \(+0.07\) & \(1\)\\[0pt]
\end{tabular}
\end{footnotesize}
\end{table}



\item \textbf{Reference Model:}
\label{sec:orge7f3220}
I will model the spatiotemporal gait variables as a function of sex, age and bodymass, i.e. all the relevant subject parameters.
The goal is to find out how strides of a given subject are characterized, e.g. whether certain aspects of the subject lead to difference in their gait characteristics.

There are two basic strategies to identify the final model.
As mentioned before, there are logical reasons for a model choice, and quantitative comparison.
Choosing an inclusive strategy (i), one might start off with an ``all in'' model.
From there, one can iteratively leave out parameters, perform model comparison, and see whether models with fewer parameters are favored by information criteria.
Alternatively, starting from a minimal model (ii), one can gradually increase complexity and find the point when adding parameters does not indicate improvement.
Either way, the procedure is iterative: sample all plausible, possible models, and perform model comparison (Ch. \ref{strides:comparison}).
Ideally, both strategies will converge on ``the best model''.
This model is simply the one which, of a broad range of models, had favorable model scores, and is logically consistent.
It is labeled \emph{ex post} as the reference model.


In the case of spatiotemporal gait variables, the reference looks as follows.
The equations below extend the \(\theta\) from \eqref{eq:proportions} to be a multivariate data ``block'' (i.e. matrix).
It has the number of observations in rows, and the number of observables in columns.
Similarly, data vectors \(v\), intercept \(\alpha\), slopes \(\beta\) and residual \(\epsilon\) receive an extra dimension and become matrices (which means incredibly fuzzy work for model programming, but can be considered bean counting given that we may turn to the actual outcome one variable at a time).

Here is thus the formula for one gait variable:
\begin{equation} \theta_{i} \sim v_{1}\cdot\alpha_{i} + v_{male}\cdot\beta_{male,i} + v_{adol}\cdot\beta_{adol,i} + v_{inft}\cdot\beta_{inft,i} + v_{cbm}\cdot\beta_{cbm,i} + \epsilon_{i} \label{eq:stride} \end{equation}

Therein, \(i\) is one of the spatiotemporal gait variables, which are all sampled in a multivariate model.
The intercept vector \(v_{1}\) is simply a column vector of ones.
The boolean \(v_{male}\) holds values one for every stride for a male subject, and zero for females.
Similarly for \(v_{adol}\) and \(v_{inft}\), which are mutually exclusive in the equation (i.e. animal is either adolescent, or infant, or neither, but never two of those options).
In contrast, \(v_{cbm}\) for centered log bodymass contains continuous values; the centering was done per ageclass, and after log transformation.
Groupwise centering affects the data vector, however the bodymass slope is not affected by ageclass (a model with \(\beta_{bm\mid ageclass}\) was also included in model comparison).


\item \textbf{Prior Choice:}
\label{sec:orgffbfe48}
A Normal distribution was used for all the slopes, a multivariate Student's T for the observables.
Informative priors (global mean and standard deviation) are used, which is a good heuristic to improve sampling without biasing the sampler.
The multivariate block of observables is initialized with the empirical correlation, which facilitates the work of the sampler (yet all three options of multivariate posterior were applied and compared).
\end{enumerate}


\subsubsection{Subject Parameters Affect Stride Characteristics}
\label{sec:orge85b957}
The model of spatiotemporal gait variables quantifies how stride (or gait) characteristics in bipedal baboon walking are affected by subject parameters (Tab. \ref{tab:strideresults}).

Clearance is highest in adult males of low bodymass (though we did not actually observe those; the effects are separately determined for age class, sex, and bodymass).
Females and subadults lift their feet less during the swing, as do animals of comparatively higher bodymass.
Dutyfactor is higher in infants: they are in ground contact for a longer portion of the stride.
All of the three speed-related parameters (i.e. distance, frequency, speed; all dimensionless) are affected by bodymass, though the effect is \chng{clearly different from zero} only for frequency.
Animals of higher bodymass tend to take shorter steps of higher frequency, which seems to overcompensate in terms of speed.
Infants cover lower relative distance at lower frequency, which adds up in terms of relative speed.
The results on trunk angle show that males hold their upper body less upright than females (i.e. at a higher trunk angle; though as with any sex effect this might be due to few, influential observations).
Although this inference can only stem from the subadult classes, it is separate from (and in opposing direction of) an age effect: adults seem to walk more crouched than infants (i.e. infants walk with a lower trunk angle, more upright).

A value which is sampled, but not shown, is the \(\nu\) parameter (or degrees of freedom, see Ch. \ref{bodymass:results}) of the Student's T posterior.
It is high (\(\nu = 54.2\)), indicating that the posterior distribution has hardly more ``weight in the tails'' than a Normal distribution would; the Normality assumption is a good approximation in this case.


\begin{table}[p]
\caption{\label{tab:strideresults}Effects of Subject Characteristics on Spatiotemporal Gait Variables. \chng{Values which do not contain zero in their HDI} are indicated by an asterisk.}
\centering
\begin{small}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
 & intercept & female  & adult  & adult  & c.log.bodymass & \(\epsilon\)\\[0pt]
 &  & \(\rightarrow\) male & \(\rightarrow\) adol. & \(\rightarrow\) infant &  & \\[0pt]
\hline
clearance & \(+0.39\) & \(+0.05\) * & \(-0.05\) * & \(-0.06\) * & \(-0.12\) * & \(\pm 0.05\)\\[0pt]
d.s. distance & \(+1.72\) & \(+0.16\) & \(-0.06\) & \(-0.13\) & \(-0.38\) & \(\pm 0.25\)\\[0pt]
dutyfactor & \(+0.58\) & \(-0.05\) & \(+0.01\) & \(+0.10\) * & \(-0.03\) & \(\pm 0.07\)\\[0pt]
d.s. frequency & \(+0.39\) & \(-0.02\) & \(-0.02\) & \(-0.06\) & \(+0.21\) * & \(\pm 0.10\)\\[0pt]
d.s. speed & \(+0.68\) & \(+0.04\) & \(-0.06\) & \(-0.16\) * & \(+0.21\) & \(\pm 0.20\)\\[0pt]
trunk angle & \(+0.67\) & \(+0.14\) * & \(-0.12\) & \(-0.20\) * & \(+0.10\) & \(\pm 0.18\)\\[0pt]
\hline
\end{tabular}
\end{small}
\end{table}


\subsubsection{Gait Variable Two Step Predicton}
\label{sec:org3879560}
The posterior prediction of spatiotemporal gait variables holds an additional complication: as shown in the body proportion model, we now have interdependent predictors (i.e. bodymass might depend on age and sex, though note that it is groupwise centered).
Therefore, two consecutive steps of posterior prediction are necessary: first predict a number (e.g. \texttt{n = 1000}) of bodymasses, then based on those samples predict spatiotemporal gait variables.
For a given setting for sex and ageclass, the workflow is as follows.
\begin{enumerate}
\item draw posterior predictive samples from the body proportion model, to get \texttt{n} bodymass samples
\item convert these samples (i.e. log transform, ageclass-wise centering with the means from actual data)
\item replace the data in the spatiotemporal gait variable model with these samples
\item then draw (i.e. predict) \texttt{n} spatiotemporal gait variable samples.
\end{enumerate}

Step 3 in this workflow might seem odd, but it is exactly the same procedure we get when choosing a setting for age and sex.
The only difference is that we do not set \texttt{n} boolean values, but \texttt{n} values which are drawn from a continuous distribution.
Although one should in theory sample multiple spatiotemporal gait variable values for each sample of bodymass, it is sufficient (and technically convenient) to keep the \texttt{n} constant throughout the procedure and compansate by a large number of samples.


As with the subject parameters, we can compare the observed values with the predictions of the model (Figs. \ref{fig:stride1} and \ref{fig:stride2}).
The data and predictions are overall consistent with the effects identified by the model (Tab. \ref{tab:strideresults}), and it is good sport to reason how the prediction for male adults came about.


\begin{figure}[p]
\centering
\includegraphics[width=.9\linewidth]{figures/stride_pt1_predictions.pdf}
\caption{\label{fig:stride1}Spatiotemporal gait variables: raw data and model predictions. Part 1.}
\end{figure}

\begin{figure}[p]
\centering
\includegraphics[width=.9\linewidth]{figures/stride_pt2_predictions.pdf}
\caption{\label{fig:stride2}Spatiotemporal gait variables: raw data and model predictions. Part 2.}
\end{figure}



\subsubsection{Stride PCA in Posterior Prediction}
\label{sec:org82b0840}
Due to the intrinsic correlation of stride distance, stride frequency, and speed, it is an option to submit them to a PCA for optional dimensionality reduction.
In posterior predictive sampling, the same PCA must be used to transform the samples to PCA space.

\begin{figure}[p]
\centering
\includegraphics[width=.9\linewidth]{figures/stride_pca_predictions.pdf}
\caption{\label{fig:stridepca}Spatiotemporal gait variables: raw data and model predictions. PCA conversion.}
\end{figure}



\subsubsection{Model Comparison}
\label{strides:comparison}
One of the great features of quantitative models is the ability to perform model comparison.
An arsenal of ``information criteria'' is available to compare models and choose which one succeeds best in capturing the effects present in the data, without being over-complex.

In addition to the reference model above, many other models were sampled for comparison.
Those are similar to the reference, but individual parameters are removed in turn, or their hierarchical structure is altered (in the case of bodymass).
In other test models, parameters were added (e.g. leg length).
The centering of bodymass was optionally omitted.
Additionally, the correlation structure of the observables (``empirical'' per default) can be changed to ``inferred''.

\begin{table}[p]
\caption{\label{tab:stridemodelcomparison}Model Comparison. LOO is the model goodness indicator. For convenience, delta (LOO difference from highest ranking model) and standard error (range of the LOO estimate) are displayed.}
\centering
\begin{tabular}{rrrrl}
\textbf{rank} & \textbf{loo} & \textbf{delta} & \textbf{std err} & \textbf{description}\\[0pt]
\hline
0 & 286.5 & 0.0 & 9.7 & additional predictor- leg length\\[0pt]
1 & 286.4 & 0.0 & 9.8 & additional predictor- BMI\\[0pt]
2 & 285.9 & 0.6 & 10.1 & Normal distribution in posterior\\[0pt]
3 & 285.7 & 0.7 & 9.6 & bodymass/ageclass level\\[0pt]
4 & 285.6 & 0.9 & 10.1 & \textbf{reference model}\\[0pt]
5 & 284.9 & 1.5 & 9.8 & non-centered bodymass\\[0pt]
6 & 284.6 & 1.9 & 9.8 & no sex slope modeled\\[0pt]
7 & 280.3 & 6.2 & 10.1 & bodymass excluded entirely\\[0pt]
8 & 280.1 & 6.4 & 10.4 & age class slopes excluded\\[0pt]
9 & 276.9 & 9.6 & 16.8 & sampled observable covariance\\[0pt]
10 & 208.4 & 78.1 & 11.8 & spatiotemporals in SI units\\[0pt]
\end{tabular}
\end{table}


The outcome of this particular comparison method (Tab. \ref{tab:stridemodelcomparison}) are ``LOO'' values (``Leave One Out'') as a quantification for the model performance/complexity tradeoff.
As mentioned, there are alternative quantifiers (e.g. WAIC), but experience shows that rankings from different information criteria are often similar.
Given relatively little difference and wide standard error ranges in the LOO estimate, we can conclude that almost all of the tested models yield some plausible descriptions of the data (in other words: most models do not perform \chng{clearly} better or worse than the reference).
In fact, the reference model is not the highest on the list: for example, choosing a Normal distribution instead of a Student's T for the observables would be better, which is consistent with the inferred high value for \(\nu\).
This switch in this case would be little more than cosmetics, since that extra parameter does not affect the results presented above.

Among the models ranking lower than the reference are models leaving out either of the current predictors.
Most of them are still within the range of the reference LOO, so it would be justifiable by logical arguments to choose either of them as reference.
The only outlier is the model with ``spatiotemporals in SI units'', i.e. where distance, frequency, and speed are measured in absolute values.
Those values are less well explained by a linear model with the given priors and structure.
This does not mean that model is wrong: most likely, they are just less normally distributed.
Yet for the sake of constructing a cascade of models (from subject-, via stride-, to coordination parameters), it seems better to choose the dimensionless parameter set.


On the other hand, comparison would favor an ageclass dependend (hierarchical) bodymass, or the inclusion of another body proportion proxy (leg length or BMI).
However, this ranking appeared only after I made a final, last-minute (and presumably minor) adjustment to the data.
Any extra data could tip the balance back towards the current structure - or not.
This exemplifies the finite sharpness of model comparison.
It guides model design, and some designs can be clearly excluded (falsification!).
Yet it should by no means be interpreted as carved in stone ultimate wisdom.
A problematic corollary of this is the need to re-sample a high number of models after even the tinyest change in the data.
Combined with the long duration of MCMC sampling, this can be prohibitive, but partially alleviated with an efficient sampling toolbox (see Ch. \ref{workflow:framework}).


\subsubsection{Hierarchical Components (``Random'' Effects)}
\label{sec:org86c8327}
Above, I have touched on the concept of a hierarchical parameter (\(bm\mid ageclass\)), and in fact it might be chosen here over the current reference.
Other hierarchical structures are possible and should be included if that is indicated by model comparison.

A particularly popular one is a ``random intercept'', where ``random'' means that each subject has its own, specific value for and intercept.
In the case of spatiotemporal gait variables, such a construct would be possible if we had longitudinal sampling (e.g. individuals recorded at different ages, or different body weights).
However, given that the set of subjects is partitioned (e.g. into male and female), a model structure with a subject-level intercept might shift variance to that ``random'' intercept which would otherwise be captured on the sex slope.
Such ambiguities in effect distribution sometimes manifest in sampling failure (because the sampler can freely move values between the overlapping categories, and thereby fails to converge).
Other times ambiguous models get disfavored in model comparison due to the extra complexity.
And yet on other examples in-sample prediction produces weird results (e.g. unlikely parameter combinations).

In conclusion, due to the data structure, I would argue that a subject level intercept is not useful in the case of spatiotemporal gait variable model.
An attempt to include such a model for model comparison failed accordingly during MCMC sampling, which is why it is not even in the model comparison list.
Note that this sampling problem would not become apparent in least squares modeling.


\subsubsection{Summary: Spatiotemporal Gait Variables}
\label{sec:org0d94e4f}
The presented findings on spatiotemporal gait variables are substantial insights into the way in which spatiotemporal characteristics of gait in \emph{Papio anubis} are affected by sex, ageclass and bodymass.
These findings are interesting by themselves and were part of the prior research on the data set \citep[][]{Druelle2021}.
They are re-iterated here with a different modeling framework and serve to exemplify important statistical concepts, most importantly (two-step) posterior predictive sampling and model comparison.

\FloatBarrier\clearpage
\subsection{Posture and Coordination}
\label{sec:orgc82aa48}
The remaining classes of model parameters (Tab. \ref{tab:parameters}, Ch. \ref{intro:dataprep}) are posture and coordination.
In this chapter, I will briefly describe how they are acquired, before even briefer presenting the results of probabilistic models which quantify their dependence on subject and spatiotemporal gait variables.


This chapter does not introduce any new concepts of statistics, but instead has some nice graphs and figures.
Its purpose is to round off the baboon story and provide the basis for further discussion.


\subsubsection{Quantifying Posture and Coordination}
\label{sec:orgb18a99b}
Among the most relevant outcomes of \chng{video-derived data} and kinematics are joint angles.
Their temporal profiles, i.e. the \chng{joint} angle over time, and how they change for different settings or subjects, can yield insights on coordination and motor control.
In cases were we have steady state locomotion, one can exploit the fact that joint angle profiles are cyclic and submit them to a Fourier Series Decomposition \citep[\emph{cf.}][]{Mielke2019}.
This operation is simply a reversible transformation, and no information is lost in the process.
Temporal profiles can thereby be investigated in the frequency domain, which involves a complex (math.) quantification of a given number of harmonics (this is often called the ``spectrum'' of a signal).
This is perfectly analogous to harmonics on a guitar string, and because one can tune models of Fourier Coefficients with MCMC sampling (see above), guitars are now oficially my favorite metaphor in explaining statistics.

Some characteristics are particularly prominent in the frequency domain/spectrum:
\begin{itemize}
\item The temporal \emph{mean} value of a joint angle appears as the zero'th Fourier coefficient (i.e. where the string is ``hung up'').
\item The magnitude of the coefficient values corresponds to the \emph{amplitude} (i.e. loudness, per coefficient or cumulated).
\item Fourier coefficients rotate in the complex plane depending on their \emph{phase} (rarely perceived in music, except in directional hearing).
\end{itemize}


Mean, amplitude and phase are familiar from general theories and descriptions of oscillations.
They can be classified as \textbf{affine} components of a signal, which simply means that they can be altered by multiplication with a scalar.
(Maybe not) coincidentally, they also have a biological meaning.
The mean of all joint angles defines posture (\emph{sensu stricto}, it \emph{is} ``dynamic'' posture).
Think of school children walking in a duck walk (or try it yourself, best immediately, but with vocalization): their limbs will be far from straightened, and their joints set at high angles.
Amplitude corresponds to effective range of motion (eROM): when you try to walk over ice with some care to not slip, it will most likely decrease.
Herein, I chose to subsume mean and amplitude as ``posture'' (\emph{sensu lato}).
Phase quantifies the relative timing of oscillating parts with respect to each other, which is, if you like, a ``regular'' part of coordination.
Lastly, if mean, amplitude, and phase are subtracted or normalized, the (non-affine) remainder of the signal can be described as an ``irregular'' part of coordination.

This removal of affine signal components is achieved by the method of Fourier Coefficient Affine Superimposition (FCAS, Ch. \ref{cpt:fcas}).
More precisely, the purpose of FCAS is to separate mean, amplitude, phase and the non-affine remainder, and use them in reasonable ways.
In the present analysis, I used it to disassemble hip, knee, and ankle joint angle profiles and extract \textbf{posture} (mean joint angle and range of motion) and \textbf{coordination} (the remainder, including phase differences).
Phase was not isolated for the different joints; however, a ``global phase alignment'' was performed by temporally aligning all \chng{joint} angle profiles so that the phase difference of the \emph{whole limb} (head-hip-toe angle) is zero.
I find this mathematically more convenient than the conventional alignment to toe touch down, which in my opinion over-emphasizes a single time point and has problems with all-too-variable dutyfactors.

A minor practical complication is that there are immensely many parameters in the ``coordination'' category (number of harmonics retained times number of joints times two for real and imaginary part).
The often misused bread-and-butter method for dimensionality reduction is PCA.
Hence, I submit the coordination parameters to a PCA for modeling.
The first \(8\) components capture \(91.0 \%\) of the variance and were submitted to the modeling procedure.


To summarize: by neat mathematical tricks, we are able to extract direct quantitative representations of posture and coordination for each stride.


\subsubsection{Model Design}
\label{sec:orga2e576d}
Posture and coordination are technically similar for the model procedure.
However, they depend differently on the available predictors.
Furthermore, they differ in posterior design: because coordination observables were derived from a PCA (which is an orthogonal transformation), these parameters are non-correlated per definition - no multivariate posterior necessary.
In contrast, the posture parameters correlate in a characteristic way (Tab. \ref{tab:posturecorrelation}), and the model with a sampled covariance structure was favored by model selection.
Therefore, posture and coordination were handled by two separate models with similar general structure.

\begin{table}[p]
\caption{\label{tab:posturecorrelation}Sampled Cross Correlation of Posture Parameters. \chng{Values of which the HDI excludes zero} are marked by asterisks. \chng{``Mean''} refers to the temporal mean of the joint angle profile, whereas ``amplitude'' is related to range of motion at that joint.}
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
 & hip & hip & knee & knee & ankle & ankle \\[0pt]
 & \chng{mean} & amplitude & \chng{mean} & amplitude & \chng{mean} & amplitude\\[0pt]
\hline
hip \chng{mean angle} & \(1\) & \(+0.53\) * & \(-0.57\) * & \(-0.07\) & \(+0.07\) & \(-0.26\)\\[0pt]
hip amplitude & \(+0.53\) * & \(1\) & \(-0.12\) & \(-0.30\) & \(-0.08\) & \(-0.01\)\\[0pt]
knee \chng{mean angle} & \(-0.57\) * & \(-0.12\) & \(1\) & \(-0.11\) & \(-0.38\) * & \(+0.25\)\\[0pt]
knee amplitude & \(-0.07\) & \(-0.30\) & \(-0.11\) & \(1\) & \(+0.03\) & \(+0.05\)\\[0pt]
ankle \chng{mean angle} & \(+0.07\) & \(-0.08\) & \(-0.38\) * & \(+0.03\) & \(1\) & \(-0.31\) *\\[0pt]
ankle amplitude & \(-0.26\) & \(-0.01\) & \(+0.25\) & \(+0.05\) & \(-0.31\) * & \(1\)\\[0pt]
\hline
\end{tabular}
\end{table}


In addition to the predictors used to infer spatiotemporal gait variables, the models now include the gait variables themselves on the right handside.
Since the number of observations has not changed, but the number of predictors increases, modeling gets challenging.
As it turns out, a multivariate block of gait variables was too complex to be included, and consequently sampling was unsuccessful.
At the same time, interdependency of speed-related parameters should not be disregarded.
I solved both problems by using another PCA, in this case for the gait variables (see Ch. \ref{prep:stridepca}).
Although this reduces the number of predictors by just one, it enables successful sampling.

The reference model for posture and coordination is as follows:
\begin{equation}
\begin{split}
 \theta_{i}  \sim &\quad v_{1,i}\cdot\alpha_{i} +
\\ & + v_{male}\cdot\beta_{male,i} + v_{adol}\cdot\beta_{adol,i} + v_{inft}\cdot\beta_{inft,i} + v_{cbm}\cdot\beta_{cbm,i} +
\\ & + v_{clr}\cdot\beta_{clr,i} + v_{df}\cdot\beta_{df,i} + v_{trnk}\cdot\beta_{trnk,i} + v_{str1}\cdot\beta_{str1,i} + v_{str2}\cdot\beta_{str2,i} +
\\ & + \epsilon_{i}
\end{split}
 \label{eq:posturemodel} \end{equation}

In equation \eqref{eq:posturemodel}, the lines correspond to the four predictor parts (intercept, subject parameters, spatiotemporal gait variables, residual).
Abbreviations are as above, plus \texttt{clr}: clearance, \texttt{df}: dutyfactor, \texttt{trnk}: trunk angle, \texttt{str1} / \texttt{str2}: stride PCs.



Implications from model comparison are overall similar to those in the spatiotemporal gait variables.
Some exceptions are better-ranked models with left-out predictors, which however were not used because I prefer to keep parameter selection and basic structure consistent throughout the chain of models.
Interesting results are anticipated by the comparison: for example, the trunk angle, which per definition contributes ``half'' of the hip joint angle profiles (adjacent segment), is an integral part of the posture model but not relevant for coordination.

\begin{table}[p]
\caption{\label{tab:posturemodelcomparison}Model Comparison of Posture models.}
\centering
\begin{tabular}{rrrrl}
\textbf{rank} & \textbf{loo} & \textbf{delta} & \textbf{std err} & \textbf{description}\\[0pt]
\hline
0 & 235.0 & 0.0 & 14.4 & age class slopes excluded\\[0pt]
1 & 231.8 & 3.3 & 13.8 & no sex slope modeled\\[0pt]
2 & 231.3 & 3.8 & 14.0 & additional predictor- leg length\\[0pt]
3 & 229.9 & 5.1 & 14.8 & \textbf{reference model}\\[0pt]
4 & 229.9 & 5.1 & 14.4 & Normal distribution in posterior\\[0pt]
5 & 229.4 & 5.6 & 13.3 & bodymass excluded entirely\\[0pt]
6 & 229.3 & 5.7 & 14.8 & bodymass/ageclass level\\[0pt]
7 & 229.1 & 5.9 & 14.9 & additional predictor- BMI\\[0pt]
8 & 228.2 & 6.8 & 15.0 & duty factor slope excluded\\[0pt]
9 & 226.7 & 8.3 & 14.8 & non-centered bodymass\\[0pt]
10 & 224.8 & 10.2 & 14.3 & stride PC1 slope excluded\\[0pt]
11 & 222.7 & 12.3 & 15.2 & clearance slope excluded\\[0pt]
12 & 212.5 & 22.5 & 15.1 & stride PC2 slope excluded\\[0pt]
13 & 196.3 & 38.8 & 8.6 & fixed observable covariance\\[0pt]
14 & 187.8 & 47.2 & 14.9 & trunk angle slope excluded\\[0pt]
\end{tabular}
\end{table}

\begin{table}[p]
\caption{\label{tab:coordinationmodelcomparison}Model Comparison of Coordination models.}
\centering
\begin{tabular}{rrrrl}
\textbf{rank} & \textbf{loo} & \textbf{delta} & \textbf{std err} & \textbf{description}\\[0pt]
\hline
0 & 337.3 & 0.0 & 15.3 & age class slopes excluded\\[0pt]
1 & 332.8 & 4.5 & 14.3 & bodymass excluded entirely\\[0pt]
2 & 332.0 & 5.3 & 14.8 & additional predictor- leg length\\[0pt]
3 & 330.7 & 6.6 & 14.7 & additional predictor- BMI\\[0pt]
4 & 330.6 & 6.7 & 14.8 & \textbf{reference model}\\[0pt]
5 & 330.6 & 6.7 & 14.7 & Normal distribution in posterior\\[0pt]
6 & 330.2 & 7.1 & 15.2 & no sex slope modeled\\[0pt]
7 & 329.7 & 7.7 & 14.8 & trunk angle slope excluded\\[0pt]
8 & 329.4 & 7.9 & 14.2 & stride PC2 slope excluded\\[0pt]
9 & 329.2 & 8.1 & 14.5 & non-centered bodymass\\[0pt]
10 & 328.5 & 8.8 & 15.2 & stride PC1 slope excluded\\[0pt]
11 & 327.3 & 10.0 & 14.6 & bodymass/ageclass level\\[0pt]
12 & 327.3 & 10.0 & 14.8 & clearance slope excluded\\[0pt]
13 & 326.6 & 10.8 & 14.9 & duty factor slope excluded\\[0pt]
\end{tabular}
\end{table}


\clearpage
\subsubsection{Lots of Figures}
\label{sec:org00d6433}
The ``statistics tutorial'' part of this journey ends here, where the biological discussion begins.
Following below is a series of figures and tables which I will leave uncommented, to open a discussion on baboon kinematics, if you like.

Whereas posture parameters have an intuitive meaning (mean joint angles and eROM), it seems futile to interpret the outcome of the coordination model (Tab. \ref{tab:coordinationresults}, Figs. \ref{fig:coordination1} and \ref{fig:coordination2}) directly.
The observables are principal components of Fourier coefficient nonaffine residuals -- even Fourier himself could not make sense of such numbers.
However, it should be pointed out that PCs are ordered by the variance they cover, hence the first ones capture the larger effects.
Furthermore, the edges of the cordination space can be sampled and re-transformed to joint angle profiles, which I demonstrated elsewhere (e.g. Fig. \ref{fig:pca} in Ch. \ref{cpt:fcas}).


The role of dutyfactor deserves special attention to illustrate what level of detail is contained in these figures.
Although \chng{zero difference is not excluded by the HDI} (probably I should have log transformed it, or given it a Beta distribution), some dutyfactor slopes are higher than others (Tab. \ref{tab:postureresults}).
We can learn from this that hip and knee angle are affected (hip: more flexed, knee: more extended on average) and that the knee range of motion increases with dutyfactor.
Dutyfactor also has the biggest effect on coordination, being the highest slope value on PC1 (Tab. \ref{tab:coordinationresults}).


In combination, posture and coordination values can be translated back into joint angle profiles.
This is especially interesting for prediction (e.g. Figs. \ref{fig:posture1} - \ref{fig:coordination2}).
The final cherry on this cake (Fig. \ref{fig:japprediction}) is thus a promising attempt to predict joint angular profiles for the given classes.

\begin{landscape}\clearpage
\begin{table}[t!]
\caption{\label{tab:postureresults}Results of the Posture Model. \chng{Values different from zero (per HDI)} are indicated by an asterisk.}
\centering
\scriptsize
\begin{tabular}{llllllllllll}
 & intercept & female \(\rightarrow\) male & adlt \(\rightarrow\) adol & adlt \(\rightarrow\) inft & c.log.bodymass & clearance & dutyfactor & trunk angle & stride PC1 & stride PC2 & \(\epsilon\)\\[0pt]
\hline
hip angle \chng{mean} & \(+2.48\) & \(-0.06\) & \(+0.02\) & \(+0.06\) & \(+0.18\) & \(-0.87\) * & \(+0.26\) & \(-1.33\) * & \(-0.04\) * & \(-0.04\) & \(\pm 0.11\)\\[0pt]
hip amplitude & \(+0.40\) & \(-0.04\) & \(+0.02\) & \(+0.11\) * & \(-0.09\) & \(-0.03\) & \(+0.03\) & \(-0.02\) & \(-0.01\) & \(-0.04\) * & \(\pm 0.07\)\\[0pt]
knee angle \chng{mean} & \(-1.55\) & \(+0.12\) * & \(-0.07\) & \(-0.07\) & \(-0.34\) * & \(+0.35\) & \(-0.31\) & \(+0.18\) & \(+0.04\) * & \(+0.06\) * & \(\pm 0.12\)\\[0pt]
knee amplitude & \(+0.94\) & \(-0.05\) & \(-0.02\) & \(-0.09\) * & \(-0.03\) & \(+0.26\) & \(-0.21\) & \(+0.05\) & \(+0.00\) & \(-0.05\) * & \(\pm 0.07\)\\[0pt]
ankle angle \chng{mean} & \(+1.45\) & \(-0.03\) & \(+0.04\) & \(+0.01\) & \(+0.09\) & \(+0.08\) & \(+0.03\) & \(+0.01\) & \(-0.04\) * & \(-0.06\) * & \(\pm 0.09\)\\[0pt]
ankle amplitude & \(+0.68\) & \(-0.07\) & \(-0.04\) & \(+0.05\) & \(+0.10\) & \(+0.24\) & \(+0.07\) & \(-0.14\) & \(-0.03\) & \(-0.08\) * & \(\pm 0.11\)\\[0pt]
\end{tabular}
\end{table}

\begin{table}[b!]
\caption{\label{tab:coordinationresults}Results of the Coordination Model. \chng{Values which do not contain zero in their HDI} are indicated by an asterisk.}
\centering
\scriptsize
\begin{tabular}{llllllllllll}
 & intercept & female \(\rightarrow\) male & adlt \(\rightarrow\) adol & adlt \(\rightarrow\) inft & c.log.bodymass & clearance & dutyfactor & trunk angle & stride PC1 & stride PC2 & \(\epsilon\)\\[0pt]
\hline
PC1 & \(+0.34\) & \(+0.09\) & \(-0.11\) & \(-0.23\) * & \(-0.01\) & \(+0.35\) & \(-0.52\) & \(-0.01\) & \(-0.01\) & \(-0.03\) & \(\pm 0.18\)\\[0pt]
PC2 & \(-0.06\) & \(+0.07\) & \(-0.06\) & \(-0.05\) & \(-0.12\) & \(+0.07\) & \(+0.00\) & \(+0.10\) & \(+0.04\) * & \(+0.05\) & \(\pm 0.14\)\\[0pt]
PC3 & \(-0.04\) & \(+0.11\) * & \(-0.04\) & \(-0.07\) & \(-0.15\) & \(-0.13\) & \(+0.16\) & \(-0.00\) & \(-0.02\) & \(+0.05\) * & \(\pm 0.11\)\\[0pt]
PC4 & \(-0.11\) & \(-0.01\) & \(+0.01\) & \(+0.01\) & \(-0.03\) & \(+0.05\) & \(-0.05\) & \(+0.20\) * & \(-0.01\) & \(-0.00\) & \(\pm 0.09\)\\[0pt]
PC5 & \(-0.04\) & \(-0.03\) & \(+0.04\) & \(+0.04\) & \(-0.08\) & \(-0.15\) & \(+0.07\) & \(+0.04\) & \(-0.02\) * & \(-0.02\) & \(\pm 0.07\)\\[0pt]
PC6 & \(+0.02\) & \(+0.03\) & \(-0.03\) & \(-0.02\) & \(+0.02\) & \(+0.11\) & \(+0.02\) & \(-0.10\) & \(+0.00\) & \(-0.00\) & \(\pm 0.06\)\\[0pt]
PC7 & \(-0.04\) & \(-0.01\) & \(+0.03\) & \(+0.02\) & \(-0.03\) & \(+0.01\) & \(-0.02\) & \(+0.05\) & \(-0.01\) & \(+0.03\) * & \(\pm 0.06\)\\[0pt]
PC8 & \(-0.01\) & \(+0.03\) & \(+0.01\) & \(+0.01\) & \(-0.06\) & \(+0.01\) & \(-0.01\) & \(-0.01\) & \(-0.01\) & \(+0.00\) & \(\pm 0.05\)\\[0pt]
\end{tabular}
\end{table}
\end{landscape}
\clearpage

\begin{figure}[h!]
\centering
\includegraphics[width=.9\linewidth]{figures/posture_means_predictions.pdf}
\caption{\label{fig:posture1}Posture model predictions. Part 1: mean \chng{joint} angles.}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=.9\linewidth]{figures/posture_amps_predictions.pdf}
\caption{\label{fig:posture2}Posture model predictions. Part 2: amplitudes (range of motion).}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=.9\linewidth]{figures/coordination_pt1_predictions.pdf}
\caption{\label{fig:coordination1}Coordination model predictions, part 1.}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=.9\linewidth]{figures/coordination_pt2_predictions.pdf}
\caption{\label{fig:coordination2}Coordination model predictions, part 2.}
\end{figure}


\begin{figure}[h!]
\centering
\includegraphics[width=.9\linewidth]{figures/trace_predictions.png}
\caption{\label{fig:japprediction}Joint Angle Profile predictions from combined results of coordination and posture models. Thick lines are actual observations; thin lines in the background are posterior predictive samples. Identical to Fig. \ref{fig:modelprediction} in Ch. \ref{cpt:fourier_review}, yet this time it should be clear how the prediction was performed.}
\end{figure}


\FloatBarrier\clearpage
\subsubsection{Lots of (New) Questions}
\label{sec:orgc1e641b}
The results of in-sample prediction of joint angle profiles in the presented form (Fig. \ref{fig:japprediction}) mainly serve to confirm whether a model was correctly tuned to the data or not.
But this capability also opens up a whole set of questions for which the original data set might have been too fragmented or complex.
Here is one example.


I touched above on the influence of dutyfactor.
One might want to ask:
\textbf{How do joint angle profiles in bipedally walking baboons change with dutyfactor?}
This parameter changes with ageclass and potentially also with sex (Tab. \ref{tab:strideresults}).
Hence, plotting all joint angle profiles of low dutyfactor strides (LDS) and comparing them to high dutyfactor strides (HDS) will probably be confounded with a comparison of juveniles and adults and unbalanced sex ratios in these groups.
Sample sizes are low due to data fragmentation, thus filtering for adult females (8 strides) does not retain enough data to derive statistically relevant conclusions.
In fact, to answer the dutyfactor question above, one would like to use information from within-ageclass comparisons and from both sexes, because each of these classes contribute their own bit to our knowledge of dutyfactor-related changes in kinematics.
This is what the probabilistic model did: it separated effects of the subject and spatiotemporal gait variables.
Ideally, the model has learned the concerted influence of these parameters on the outcome parameters.


\begin{figure}[p]
\centering
\includegraphics[width=.9\linewidth]{figures/trace_quantiles_dutyfactor_0.png}
\caption{\label{fig:dutyquantileprediction}Joint angle profile predictions for dutyfactor quantiles, for adult females. Thick lines: averages; thin lines: individual predictive samples. Caution: to emphasize differences, the range of y-values varies on the three panels.}
\end{figure}

So let us ask the model what the effect of dutyfactor is, specifically for adult females!
The prediction (Fig. \ref{fig:dutyquantileprediction}) depicts the exact temporal coordination of joint angles within the specified group.
Changing from LDS to HDS, the hip mean angle increases (more flexed), which indicates that a prerequisite for quicker strides is a somewhat extended posture.
The knee is affected in terms of amplitude.
Curiously, the ankle joint profile is hardly altered during the swing phase (phases not indicated in figure, but it is the latter part of the cycle progress and can be guessed from the ankle) except that obviously the ``second trough'' in the trace starts later; the stance phase again is altered in terms of mean \chng{joint} angle.
As a bonus, we can see the variance in the strides (as shaded traces in the background), though that variance might be an over-estimation due to low data sample size (partially influenced by wide priors).
Remember that dutyfactor cross-influences other spatiotemporal gait variables (Tab. \ref{tab:stridecorrelation}).
Luckily, it is easily possible and might be worth comparing the speed etc. of the selected, predicted strides.


The capacity to fix some parameters and ``playing'' with others is immensely useful for all kinds of research questions, beyond the context of kinematic analysis.
As shown above, the prerequisite is a well-fit probabilistic model of the phenomenon you want to analyze, and a sufficiently high number of observations.



\FloatBarrier
\clearpage
\section{Summary}
\label{sec:org527d8db}
With this chapter, I attempted to plant the seed which will grow into your love for the beauty of probabilistic modeling.
Alternative (and less ambitious) claim: you could call this my illustrative/colloquial/desperate attempt to explain what I think when I hear or talk ``statistics''.

Still, I hope I kindled some good ideas.
\medskip

This rough overview is the basis of the subsequent chapter, in which I will take the modeling procedure one more step further to predictively model subject parameters as a function of gait, posture, and coordination (Ch. \ref{cpt:piglets}).
The intention of this chapter was also to facilitate orientation for those who would like to look at the scripts that generated all the models, figures, and tables above (available at \url{https://git.sr.ht/~falk/papio_fcas}).


\FloatBarrier
\clearpage

\nocite{Gelman2013}

% \bibliographystyle{apalike}
% \bibliography{library.bib}
