@article{Bernstein1927b,
    author   = {Bernstein, Nikolai A.},
    year     = {1927},
    title    = {Kymozyklographion, ein neuer {A}pparat f{\"u}r {B}ewegungsstudium},
    doi      = {10.1007/BF01723725},
    journal  = {{Pfl{\"u}ger's Archiv f{\"u}r die gesamte Physiologie des Menschen und der Tiere}},
    volume   = {217},
    number   = {1},
    pages    = {782--792},
    month    = {Dec},
    issn     = {1432-2013},
    abstract = {Der vom Verf. zu besonders exakten Untersuchungen im Bereiche normaler und pathologischer Bewegungen konstruierte Apparat, Kymozyklographion (K.-Z.) benannt, basiert auf dem Prinzip des Chronophotographierens einer Reihe von Leuchtpunkten, die an den Gelenken des Versuchsorgans angebracht sind, (Chronozyklographie), auf einem gleichm{\"a}{\ss}ig beweglichen Film. Dieses Verfahren vereinigt die Vorz{\"u}ge der chronozyklographischen Methode der Bewegungsregistration mit einer M{\"o}glichkeit beliebig lange dauernde und komplizierte Bewegungsfolgerungen aufzuzeichnen und zu analysieren. Die Methode ist zum Studium verschiedenster normaler und pathologischer Bewegungen anwendbar, wobei die Dechiffrierung der Aufzeichnungen der K.-Z.-Kamera mittels der zyklogrammetrischen Methodik des Verfassers besonders bequem und exakt erscheint.},
    day      = {01},
}

@article{Hedrick2008,
    author = {Hedrick, Tyson L. },
    year = {2008},
    title = {Software techniques for two- and three-dimensional kinematic measurements of biological and biomimetic systems},
    doi = {10.1088/1748-3182/3/3/034001},
    journal = {Bioinspiration & Biomimetics},
    month = {jul},
    publisher = {},
    volume = {3},
    number = {3},
    pages = {034001},
    abstract = {Researchers studying aspects of locomotion or movement in biological and biomimetic systems commonly use video or stereo video recordings to quantify the behaviour of the system in question, often with an emphasis on measures of position, velocity and acceleration. However, despite the apparent simplicity of video analysis, it can require substantial investment of time and effort, even when performed with adequate software tools. This paper reviews the underlying principles of video and stereo video analysis as well as its automation and is accompanied by fully functional and freely available software implementation.},
}

@article{MMielke2020,
    author = {Mielke, Maja and Aerts, Peter and Van Ginneken, Chris and Van Wassenbergh, Sam and Mielke, Falk},
    year = {2020},
    title = {{Progressive tracking: a novel procedure to facilitate manual digitization of videos}},
    doi = {10.1242/bio.055962},
    journal = {Biology Open},
    volume = {9},
    number = {11},
    month = {11},
    issn = {2046-6390},
    comment = {bio055962},
    abstract = {Digitization of video recordings often requires the laborious procedure of manually clicking points of interest on individual video frames. Here, we present progressive tracking, a procedure that facilitates manual digitization of markerless videos. In contrast to existing software, it allows the user to follow points of interest with a cursor in the progressing video, without the need to click. To compare the performance of progressive tracking with the conventional frame-wise tracking, we quantified speed and accuracy of both methods, testing two different input devices (mouse and stylus pen). We show that progressive tracking can be twice as fast as frame-wise tracking while maintaining accuracy, given that playback speed is controlled. Using a stylus pen can increase frame-wise tracking speed. The complementary application of the progressive and frame-wise mode is exemplified on a realistic video recording. This study reveals that progressive tracking can vastly facilitate video analysis in experimental research.},
}

@article{Karashchuk2021,
    author = {Karashchuk, Pierre and Rupp, Katie L. and Dickinson, Evyn S. and Walling-Bell, Sarah and Sanders, Elischa and Azim, Eiman and Brunton, Bingni W. and Tuthill, John C.},
    year = {2021},
    title = {{Anipose: A toolkit for robust markerless 3D pose estimation}},
    journal = {Cell Reports},
    volume = {36},
    number = {13},
    pages = {109730},
    issn = {2211-1247},
    doi = {10.1016/j.celrep.2021.109730},
    url = {https://www.sciencedirect.com/science/article/pii/S2211124721011797},
    keywords = {pose estimation, robust tracking, markerless tracking, behavior, 3D, deep learning, camera calibration, visualization, Drosophila joint rotation, neuroscience},
    abstract = {Quantifying movement is critical for understanding animal behavior. Advances in computer vision now enable markerless tracking from 2D video, but most animals move in 3D. Here, we introduce Anipose, an open-source toolkit for robust markerless 3D pose estimation. Anipose is built on the 2D tracking method DeepLabCut, so users can expand their existing experimental setups to obtain accurate 3D tracking. It consists of four components: (1) a 3D calibration module, (2) filters to resolve 2D tracking errors, (3) a triangulation module that integrates temporal and spatial regularization, and (4) a pipeline to structure processing of large numbers of videos. We evaluate Anipose on a calibration board as well as mice, flies, and humans. By analyzing 3D leg kinematics tracked with Anipose, we identify a key role for joint rotation in motor control of fly walking. To help users get started with 3D tracking, we provide tutorials and documentation at \nolinkurl{http://anipose.org}.},
}

@article{Mathis2020,
    author = {Mathis, Alexander and Schneider, Steffen and Lauer, Jessy and Mathis, Mackenzie Weygandt},
    year = {2020},
    title = {{A Primer on Motion Capture with Deep Learning: Principles, Pitfalls, and Perspectives}},
    journal = {Neuron},
    volume = {108},
    number = {1},
    pages = {44-65},
    issn = {0896-6273},
    doi = {10.1016/j.neuron.2020.09.017},
    url = {https://www.sciencedirect.com/science/article/pii/S0896627320307170},
    abstract = {Extracting behavioral measurements non-invasively from video is stymied by the fact that it is a hard computational problem. Recent advances in deep learning have tremendously advanced our ability to predict posture directly from videos, which has quickly impacted neuroscience and biology more broadly. In this primer, we review the budding field of motion capture with deep learning. In particular, we will discuss the principles of those novel algorithms, highlight their potential as well as pitfalls for experimentalists, and provide a glimpse into the future.},
}

@article{Mathis2018,
    author = {Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M and Abe, Taiga and Murthy, Venkatesh N and Mathis, Mackenzie Weygandt and Bethge, Matthias},
    year = {2018},
    title = {{DeepLabCut: markerless pose estimation of user-defined body parts with deep learning}},
    doi = {10.1038/s41593-018-0209-y},
    journal = {Nature Neuroscience},
    volume = {21},
    number = {9},
    pages = {1281--1289},
    publisher = {Nature Publishing Group},
}

@article{Cronin2021,
    author = { Cronin, Neil J.},
    year = {2021},
    title = {{Using deep neural networks for kinematic analysis: Challenges and opportunities}},
    doi = {10.1016/j.jbiomech.2021.110460},
    journal = {Journal of Biomechanics},
    volume = {123},
    pages = {110460},
    issn = {0021-9290},
    url = {https://www.sciencedirect.com/science/article/pii/S0021929021002402},
    keywords = {Motion analysis, Kinematics, Deep neural network, Markerless tracking, AI},
    abstract = {Kinematic analysis is often performed in a lab using optical cameras combined with reflective markers. With the advent of artificial intelligence techniques such as deep neural networks, it is now possible to perform such analyses without markers, making outdoor applications feasible. In this paper I summarise 2D markerless approaches for estimating joint angles, highlighting their strengths and limitations. In computer science, so-called “pose estimation” algorithms have existed for many years. These methods involve training a neural network to detect features (e.g. anatomical landmarks) using a process called supervised learning, which requires “training” images to be manually annotated. Manual labelling has several limitations, including labeller subjectivity, the requirement for anatomical knowledge, and issues related to training data quality and quantity. Neural networks typically require thousands of training examples before they can make accurate predictions, so training datasets are usually labelled by multiple people, each of whom has their own biases, which ultimately affects neural network performance. A recent approach, called transfer learning, involves modifying a model trained to perform a certain task so that it retains some learned features and is then re-trained to perform a new task. This can drastically reduce the required number of training images. Although development is ongoing, existing markerless systems may already be accurate enough for some applications, e.g. coaching or rehabilitation. Accuracy may be further improved by leveraging novel approaches and incorporating realistic physiological constraints, ultimately resulting in low-cost markerless systems that could be deployed both in and outside of the lab.},
}
