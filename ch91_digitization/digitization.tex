To perform any kinematic analysis, one has to extract kinematic data.
Therefore, one has to ``track'' the trajectory of points of interest on a digital video.

The standard way to do this has changed dramatically during the course of this PhD project:
whereas the gold standard used to be having a student assistent to click points frame-wise on the videos (``video tracking'' of points), there are now deep learning algorithms to replace those students (``pose estimation'' of whole animals).
Some relevant publications are listed here for the interested reader.
More details can be found in the articles marked as ``review''.
The author was involved in one of the studies \citep{MMielke2020}.

\begin{itemize}
\item (review) DLTv: \citet{Hedrick2008}
\item Argus: \citet{Jackson2016}
\item (review) Progressive Tracking: \citet{MMielke2020}
\item DeepLabCut: \citet{Mathis2018,Mathis2020}
\item ThruTracker: \citet{Corcoran2021}
\item AniPose: \citet{Karashchuk2021}
\item (review) overview of deep learning methods: \citet{Cronin2021}
\end{itemize}
