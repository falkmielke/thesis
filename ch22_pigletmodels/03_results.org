
#+BIBLIOGRAPHY: literature.bib apalike
#+BEGIN_SRC emacs-lisp :exports none :results silent
(setq org-babel-inline-result-wrap "\\(%s\\)")
(setq bibtex-completion-bibliography
      '("literature.bib"))
#+END_SRC

#+begin_comment
TODO: set "reloading" in the code block below!
TODO: uncomment Code04-05 execution below to re-load predictions! Make sure to remove pre-stored data upon changes!
#+end_comment


#+RESULTS:

# * Data Set
The present analysis is centered around a linear model which is designed to infer mass, size, and age (subject characteristics) from an extensive set of kinematic parameters from 2D videos.
The numbers provided by the model sampling are equally extensive, and will only be reported in brief.
The key purpose of the model is posterior predictive sampling of the LBW strides which were left out of the model, and which are analyzed in detail below.


@@latex:\bigskip@@
# * Differences in LBW and NBW kinematics are minimal

#+BEGIN_SRC sh :results none :exports none :tangle no
# python Code05_RawDataPlot.py
#+END_SRC


#+CAPTION: Joint angle profiles per joint, grouped by birth weight category. An angle of zero would be a fully extended (i.e. straight) joint. Thick lines represent the average profiles, dashed lines indicate the average of the opposite birth weight group for comparison. Colored, shaded lines show all raw profiles available for the present analysis. Temporal alignment was done based on total forelimb angle (see methods), yet for the shown hindlimb averages (but not for the raw profiles), a separate alignment of the hindlimb was performed.
#+ATTR_LATEX: :placement [b!]
#+LABEL: fig:raw_data
[[./figures/raw_profile_comparison.pdf]]

To assess whether there are qualitative differences between the birth weight categories, one can compare the joint angle profiles (i.e. raw, angular kinematics) on which the present analysis was performed (Fig. \ref{fig:raw_data}).
The intra-group variablility clearly exceeds the differences between groups, although it must be emphasized that groups are inhomogeneous (with regard to age, speed, etc.), which might lead to a bias if composition of LBW and NBW data differs.
LBW walk with a more flexed hindlimb posture, as indicated by the parallelly offset average hip, stifle, and tarsal profiles.
Additionally, NBW individuals on average seem to set the shoulder at a more extended angle.
No differences in coordination are apparent (which would manifest in altered temporal structure of the profiles).
These findings indicate that LBW kinematics are hardly distinguishable from NBW kinematics by qualitative, visual assessment, which is at least in part be due to high variability.



@@latex:\bigskip@@
# * Model Results
A quantitative comparison of variable kinematic measurements can be achieved with probabilistic linear models.
For the purpose of predictive sampling (see below), we train models to describe the interrelations of kinematic parameters and subject characteristics in NBW piglets.
The outcome of MCMC sampling of a linear model are value distributions for slopes, which in our case indicated how certain kinematic parameters are associated with a change in mass, size, and age (supplementary material \ref{supp:modelresults}).
Of the gait- or coordination parameters, only hindlimb clearance was correlated with differences in animal mass.
Mass was also associated with changes in the dynamic posture of the hip and tarsal.
For size, the model inferred associations with head angle, hindlimb duty factor and clearance, and one coordination component (CC3), as well as changes in the fore- and hindlimb posture and an effect of sex.
Finally, age was associated with an increase in forelimb clearance, potential changes at the stifle and carpal, and several coordination components (CC9, CC11).
Some eROM slope distributions for age were high in average magnitude, but variable (the "credible interval" contained zero).
These model results provide detailed insight into parameter interrelations in the present data set and indicate which of the parameters are the relevent ones to infer a given subject attribute in predictive sampling.



@@latex:\bigskip@@
# * Age Predictions are Bimodal

Performing in-sample and out-of-sample predictive inference with the models trained on NBW strides elucidated if and how left-out strides differed from NBW model expectation (Fig. \ref{fig:predictions}).
Note that, to capture variance (i.e. uncertainty in the prediction), each stride was sampled repeatedly.

#+BEGIN_SRC python :results output :session predictions :exports none :tangle yes
# update the figure
import os as OS
import numpy as NP
import pandas as PD
import matplotlib.pyplot as PLT

print (OS.getcwd(), OS.path.exists('Code03_Predictions.py'))

force_reloading = False
model_label = 'reference'
prefix = 'age'
n_samples = 16384 # 1024 # 16384

import Code03_Predictions as PRED

data = PRED.LoadYoungData()
all_diffs = PRED.StoreOrReload(data, force_reloading, prefix, n_samples)

fig, _ = PRED.PlotPredictions(data, all_diffs)

fig.savefig(f'figures{OS.sep}histograms_prediction_comparison.png', dpi = 300, transparent = False)
fig.savefig(f'figures{OS.sep}histograms_prediction_comparison.pdf', dpi = 300, transparent = False)
PLT.close()

# info for the text
mean_diffs = PD.DataFrame.from_dict({ \
               param: {grp: all_diffs[param][grp].mean() for grp in range(3)}
               for param in all_diffs.keys() \
              }).T

print (mean_diffs)
# print ('tic')
# print ('toc')
#+END_SRC

#+RESULTS:
: /data/01_kinematics/16_piglet_fcas/ms1_agemodel True
: loading pre-stored prediction diffs....
: ['weight', 'morpho1', 'age']
: [0, 1, 2]
: [ 3.    3.44  1.4  ... -8.22 -3.12 -6.3 ]
:             0     1     2
: weight  -0.00  0.02  0.44
: morpho1  0.00  0.02  1.71
: age     -0.03 -0.09 -1.23



#+CAPTION: Model inference. For all included subject characteristics, models which were trained on NBW strides correctly inferred the training data (gray) and values from the validation set (blue). In contrast, the same models wrongly inferred the characteristics of LBW subjects (orange). The \(x\)-axes show the difference (\(\Delta\)) between actual and predicted values per prediction. To facilitate comparison, histogram heights are again normalized per category.
#+ATTR_LATEX: :placement [t!]
#+LABEL: fig:predictions
[[./figures/histograms_prediction_comparison.pdf]]


Out-of-sample inferences for the /NBW validation set/ matched those of in-sample NBW inference in terms of average values and standard deviation for all modeled outcome variables, which confirms that inference of subject characteristics from kinematics is possible.
In contrast, inferences for /LBW strides/ did not match those of the NBW training set.
Low birth weight animals were inferred to be on average
src_python[:session predictions]{f"{mean_diffs.loc['weight', 2].round(2)}"} {{{results(\(0.44\))}}}
kg heavier than actual, and their size was overestimated (+
src_python[:session predictions]{mean_diffs.loc['morpho1', 2].round(2)} {{{results(\(1.71\))}}}
units).
Both faults matched the actual differences in magnitude (/cf./ methods, Fig. \ref{fig:observations}).
In contrast, the age inference for the low birth weight subjects were not normally distributed: most ages were correctly inferred from stride-wise kinematics, but ages for some strides were underestimated.
The underestimation of those strides quantified to just below five hours.

In summary, the NBW-trained model "guesses" the size and mass of the animals producing LBW strides to be "normal" (although they are not), which indicates that these defining features of LBW do not reflect in altered kinematics.
However, age inference \chng{of LBW differs from NBW}, i.e. some strides are classified as typical for animals of younger than actual age.


@@latex:\begin{change}@@
These findings are based on an analysis that uses the statistical model of one subset of the data for predictive inference on another subset, which is a strategy that demands justification.
+ Is the model actually /capable/ of finding differences?
+ Under which circumstances will group differences arise?
+ Is there a bias in the modeling procedure, for example to not find all differences?
Answering these questions requires a rather technical analysis of the model outcome.

One important constraint is that the model is linear, i.e. of the form
\[y = a + b_1 \cdot x_1 + b_2 \cdot x_2 + \ldots + b_m \cdot x_m + \epsilon = a + \sum\limits_k b_k \cdot x_k + \epsilon\]

Herein, \(y\) is one of the outcome variables (age, size, or mass), \(a\) is the intercept, \(b_i\) are the slopes, \(x_i\) are the different input parameters (observed; spatiotemporal gait variables, dynamic posture, and coordination measures), and finally \(\epsilon\) is the model residual (unexplained variation).
As I have demonstrated [[http://mielke-bio.info/falk/posts/33.linearmodels/][elsewhere]] citep:Mielke2024lm, there are some conditions which are necessary (but not sufficient by themselves) to find a difference.
If there is a....
1. significant difference between the study groups in the distributions of input variables
2. high enough slope magnitude (steepness)
3. small enough model complexity/size, i.e. number of (other) slopes
4. low residual variation or noise
5. sufficient sample size

... then we can find differences as in the example of age, above.
In case one of these conditions is not met, a difference between the study groups might be obscured (yet note that there is a continuum, and effects may cancel).
Note that, from theoretical considerations alone, this situation is biased.
Differences in out-of-sample prediction (e.g. in case of the age model) must have passed the criteria above, and are therefore robust.
On the other hand, /"the absence of evidence is not the evidence of absence"/: if for example the sample size is low, or the residual variation is high, the model's prediction might have missed an actual effect.
This situation is somewhat analogous to classical hypothesis testing.

#+CAPTION: Observed model parameter input distributions. Observations are indicated for each model parameter (rows) by tick marks for the two study groups (NBW: gray, LBW: orange). Values were standardized (mean-centered and scaled by standard deviation). Significance between the distributions (indicated by asterisk) was determined by a two-sample ranksum test.
#+ATTR_LATEX: :placement [p!]
#+LABEL: fig:input_distributions
[[./figures/input_distribution_differences.pdf]]


#+CAPTION: Effects of each input parameter on the model output. Effect size is calculated as the data range (difference between \(2.5\%\) and \(97.5\%\) data quantiles) multiplied by the slope distributions (from model sampling). Effect magnitude is visualized by red shading, effects which are different from zero (\(95\%\) HDI) are also indicated by an asterisk. Residual is determined as the difference of the actual parameter observation and the model result.
#+ATTR_LATEX: :placement [p!]
#+LABEL: fig:output_effects
[[./figures/output_effectsize.pdf]]


The available modeling framework enables some extra insights on why the prediction appeared as it did.
Firstly, we can compare the input distributions of the observational groups (Fig. \ref{fig:input_distributions}), to identify those model parameters which can acutally influence the predictions (in Fig. \ref{fig:predictions}, above).
Secondly, we can calculate the absolute effect of each parameter onto the predicted outcome (slope magnitude, point 2 above), by multiplying the parameter magnitude with the according slope (Fig. \ref{fig:output_effects}; this works because \(\Delta y \sim b_i \cdot \Delta x_i\)).
Thirdly, we can quantify the model residual (point 4; Fig. \ref{output_effects}).
The other points above (model complexity and sample size) are fixed in our application, and could have an influence.

For the *age model*, we observe a low residual variance, and two parameters which are significantly different between NBW and LBW /and/ have a high slope (those are hindlimb clearance and hip angle).
Notably, there is hardly any difference in the observed coordination parameters.
For the model of *body mass*, the same parameters seem to have relevant slopes, yet the model residual is much higher and will likely prohibit conclusive differences in the probabilistic prediction.
Other slopes seem to have significant effect in the NBW group (hip and tarsal eROM), yet the input distributions (i.e. NBW and LBW observations) do not differ, and so their effect is meaningless for mass prediction.
For the *size model*, we some slopes with a negative effect on the output (hindlimb clearance, head angle, hip angle), yet others with a positive effect (knee angle, tarsal eROM) likely cancel this out for the overall prediction.
Again, this model contains significant slopes with nonetheless no difference in the input distribution.
We can also compare the relative widths of effect size distributions, which shows that "dimensionless (relative) speed" is most variable among trials: all animals use a variety of speeds, and that can not be systematically associated with age, size, or mass.
It must be re-iterated that "significance" in these analyses merely provides a hint to guide the eye: the combination of a minor (non-significant) difference in an input parameter with a notable, but "almost-significant" effect size might still affect the probabilistic prediction.
Finally, comparing NBW and LBW, we observe most differences in spatiotemporals (predominantly hindlimb-related), as well as in measures of dynamic posture and range of motion.
There are few significant effects of coordination parameters, and the remaining ones are canceled out by a lack of difference in the observed coordination of LBW and NBW.


To summarize, we showed that a detailed inspection of the observed model input parameters, and of the effect "lever" of each parameter slope, warrants some caution about non-different predictions (as in the models of size and mass).
In those models, we cannot rule out that a larger sample size or an adjusted, potentially more fine-grained model structure might elucidate quantitative NBW/LBW differences.
On the other hand, inspection of the predictive age model confirms that finding differences by out-of-sample prediction is possible, and we could even relate those findings to specific model parameters.

@@end:\end{change}@@



@@latex:\bigskip@@
# * Inference Bimodality is Related to Individuals


#+BEGIN_SRC sh :results none :exports none :tangle no
# python Code04_FindIndividuals.py
#+END_SRC

#+BEGIN_SRC python :results output :session individuals :exports none :tangle yes
import numpy as NP
import pandas as PD
lbw_data = PD.read_csv('./results/lbw_strides.csv', sep = ';')

# per stride, calculate the share of predictions above actual age
strides = lbw_data.groupby(['piglet', 'age_actual', 'session_idx', 'recording_idx', 'cycle_idx']).agg({'age_diff': lambda arr: NP.sum(arr > 0.)/len(arr)})
# print (strides)

piglets = strides.groupby(['piglet']).agg({'age_diff': NP.mean})
print (piglets)
piglets['under'] = piglets['age_diff'].values < 0.2 # 80% strides consistent

over_rate = piglets.loc[NP.logical_not(piglets['under'].values), 'age_diff'].mean()
print (over_rate)

over_strides = strides.loc[piglets.loc[NP.logical_not(piglets['under'].values), :].index.values, :].values < 0.5
print (over_strides.sum())

#+END_SRC

#+RESULTS:
#+begin_example
        age_diff
piglet
1794_5  0.104532
b15     0.633101
b19v2   0.001348
b23     0.709336
b56     0.012975
b58     0.088475
b74     0.602111
b76     0.611527
0.6390187161309379
1
#+end_example

#+CAPTION: Age inference per LBW animal (compared to NBW average, last row). \(\Delta\): "inferred - actual" difference. Underestimation is defined as \(\Delta < 0\), "count": per stride, "rate": per predictive sample. \(h\): hours, \(std\): standard deviation.
#+LABEL: tab:prediction
#+ATTR_LATEX: :placement [b!]
#+ATTR_LATEX: :align |l|c|c|c|c|c|c|
#+INCLUDE: "./results/prediction_lbw.org"


To find out whether the offset age inference was related to certain individuals, or certain strides from different individuals, we grouped the inferences per stride or subject and calculated the chance of over- or underestimating age.
Of the
src_python[:session individuals]{piglets.shape[0]} {{{results(\(8\))}}}
low birth weight subjects who contributed
src_python[:session individuals]{strides.shape[0]} {{{results(\(39\))}}}
strides,
src_python[:session individuals]{piglets.loc[piglets['under'].values, :].shape[0]} {{{results(\(4\))}}}
individuals were consistently underestimated (Tab. \ref{tab:prediction}).
Consistently means that more than \(75 \%\) of all predictive samples were below actual age, and that the ages for a majority of strides were on average underestimated.
The magnitude of underestimation was between two and five hours.
Curiously, those were the individuals recorded at a slightly higher age (\( > 5\) hours).
Overestimation in the other four LBW individuals was also consistent, but less so (less extreme underestimation rate, mean \(\Delta < 2\ h\)).
Standard deviation of the estimates did not vary across individuals or birth weight categories.

We conclude that underestimation of age is consistent over multiple strides of the same individual, and thus individual-specific.
