#+TITLE: Extracting Inertial Properties from X-Ray Computed Tomography: A Failed Attempt
#+AUTHOR: Falk Mielke
#+DATE: <2023-07-05 Thu>

#+SETUPFILE: latex_header.org
#+EXPORT_FILE_NAME: pt3ch7_inertials

#+BIBLIOGRAPHY: literature.bib apalike
#+BEGIN_SRC elisp :results none :exports none :tangle no
(setq bibtex-completion-bibliography
      '("literature.bib"))
#+END_SRC

#+OPTIONS: toc:t

#+STARTUP: noinlineimges showeverything entitiespretty
@@latex:\clearpage@@
#+ODT: <text:p text:style-name="PageBreak"/>


* Abstract

* Introduction
** Computed Tomography and Density
Since the advent of x-ray imaging, people are intrigued by the ability to see the inner structure of objects and living creatures (such as the famous hand of Röntgen's wife, "Über eine neue Art von Strahlen", 1895).
This desire probably increased by the development of computed tomography citep:Beckmann2006,Hounsfield1973, a set of techniques which enable the reconstruction and visualization of three-dimensional structural images.
The transmission images obtained via high energy electromagnetic radiation often serve to answer qualitative questions (e.g. whether a bone is fractured, whether there are porosities in asphalt drill cores).
Quantitative questions are obvious with regard to the shape of a scanned structure (e.g. the size of porosities, the length of a fracture, the shape of a bone).
However, researchers have been struggling with the quantitative extraction of material properties from Computed Tomography (CT) data.
The material property of primary interest is physical density; from a given density distribution, the other relevant inertial properties can be calculated.


Reseachters have long suggested to relate the gray value of CT images to density citep:Mull1984,Phelps1975, yet it was immediately noted that the relation is nothing more than a correlation which only holds under specific circumstances.
Even these pioneer works acknowledge that there must be discrepancies between known and measured densities, which can be explained by (i) the polychromatic character (source spectrum) of the used radiation, (ii) chemical composition (absorption spectrum), and (iii) scan artifacts.
# scattering types,
These issues demand a detailed explanation, below.
Notwithstanding this list of known problems, people have repeatedly attempted to extract density and inertial propertes from CT scans @@latex: \citep[][, as well as the present study]{Phillips1997,DuPlessis2013,Durston2022}@@.
The purpose of this chapter is to explore whether or not (or under which circumstances) CT gray values can be used to estimate density distributions, and thereby mass and other derived inertial properties.
I will start by giving a brief intro to the CT scanning technology, reviewing similar attempts by others, then introducing a simple experimental setup to measure dynamics of an excised piglet femur, and with that re-attempting the extraction of inertial properties.


** Emission and Absorption
Visible light and x-ray radiation are, to a large degree, analogous.
The reason is that both are just electromagnetic radiation; they differ in wavelength.
To understand what is happening with x-ray light during a CT experiment, I will use the analogy of visible light.


On some military signal flashlights, one can set the light to be white (i.e. bulb spectrum, unfiltered) or filtered either red or green, sometimes a third color.
Light are photons, and filters let through some of them and prohibit others from passing.
The same principle holds for party lights or colored window sheets: a light source is placed behind a filter sheet which blocks most colors.
On the military flashlight, the "white" setting is general purpose, unfiltered, which will let pass the maximum number of photons you can expect from a given bulb.
Lights are devices which constantly emit photons of a specific variety of wavelengths (colors); we call this variety the "spectrum" (see below).
Put simply, applying a red filter sheet will change the composition of the passing light by blocking all the "non-red" photons.
Because red photons pass the filter, the filtered spectrum will be predominantly red, and appear red to our perceptive system.

Most plants have evolved to be green; their cells hold organelles with the green pigment chlorophyl, which is optimized to absorb some non-green (e.g. red) wavelengths of light very well (Fig. \ref{fig:spectrum}, green curve).
The ensemble of non-absorbed photons appears green to us, which is why leaves appear green to our receptor system.
But leaves only appear green if there is a green content in the incident light!
Green leaves will look red under red light.
Contrary to internet myth, the military use case of red flashlight would be an operation which requires as inconspicuous light as possible in a vegetated environment.
Red light will hardly reflect from gras or bush, and can therefore reduce the chance of being spotted at night by enemy surveillance.
If you need to look for something in a dark forest, and you would like to avoid being seen, use a red flashlight.


#+CAPTION: Spectra. The x-axis shows all wavelengths \(\lambda\) (\(nm\)) of relevance (in this case the range of visible light, for illustration). Related to wavelength and therefore viable axis label alternatives are frequency (\(Hz\)) and photon energy (\(keV\)). The y-axis shows photon occurrence probability, or normalized intensity \(I\), or the intensity difference \(\Delta I\) for the absorption spectrum. Black curve: emission spectrum of a white LED \citep{Tanabe2005}. Green curve: the approximate absorption spectrum of Chlorophyl A \citep{Zscheile1934}. The chlorophyl will hardly get excited by the LED.
#+LABEL: fig:spectrum
#+ATTR_LATEX: :width 13cm
[[./figures/spectrum.pdf]]


To characterize light which is emitted, reflected, or absorbed, one can use a spectrum (Fig. \ref{fig:spectrum}).
Red LED's are an alternative to red filters: they immediately produce a spectrum which is biased towards low frequencies.
We can assess that red LEDs have a different *source spectrum or emission spectrum* than white LEDS or "vintage" (tungsten) light bulbs.
If the light from a white source is filtered (e.g. by a red sheet of thin plastic), the spectrum is altered.
A red LED viewed through a green-pass filter (e.g. a leaf) might appear to be "off", when really power is "on", because the majority of photons are absorbed by the filter.
Light hitting an object will also change its spectral composition, depending on the material's *absorption, transmission, and reflection spectrum*.
This is also a filtering process: the outgoing light will depend on the incoming spectrum and the material properties of the object.
Plant leaves will almost entirely absorb a narrow band of red light.
All that is happening here are interactions of photons and matter.
Those interactions crucially depend on the energy/frequency/wavelength of the photons, and the energetic/vibrational/resonant molecular properties of the matter.
A (differential) spectrum is a way to depict this wavelength dependence.


#+CAPTION: X-Ray emission spectrum. An x-ray source will emit photons with a variety of energies ("colors"). Bremsstrahlung will cover a wide range of photon energies, whereas discrete peaks are caused by specific emission processes in the target material. \citep[taken from ][, creative commons license]{Berger2018fig8}.
#+LABEL: fig:xray_emission
#+ATTR_LATEX: :width 10cm
[[./figures/Berger2018.png]]

The situation is exactly analogous for x-rays citep:Berger2018,Buzug2008.
X-rays are also photons, "elementary particles which are the quantum of the electromagnetic field" ([[https://en.wikipedia.org/wiki/Photon][wikipedia: photon]]), just at a different wavelength (range \(10pm - 10nm\)).
X-ray sources are "targets" of an electron beam, i.e. anodes made of certain metals (Tungsten, Molybdenum, ...).
When hit by electrons which are evoked by applying voltage (e.g. \(60 kV\)) to the anode and a warmed-up kathode, the target will emit x-ray photons of a specific composition of energies (spectrum, Fig. \ref{fig:xray_emission}).
The source emission is generally *polychromatic*, i.e. consisting of multiple colors/energies (just as the spectra in Figs. \ref{fig:spectrum} and \ref{fig:xray_emission}).
Most commercial CT scanners have a polychromatic source; the common exception are synchrotrons.
On the other hand, x-ray detectors are usually monochromatic, integrating intensities over a wide range of wavelengths (in a specific way, described by a detection sensitivity spectrum, which adds another layer of nuisance).
There is ongoing development on the frontier of "spectral CT" citep:Liu2023, yet resolution (spectral and spatial) are currently still below par.


Once set on their path from within the x-ray source, x-ray photons interact stochastically with matter they encounter on their trajectory.
Much simplified, they are either absorbed or scattered (Rayleigh scattering, Compton scattering); "attenuation" is the term to describe that not all photons reach the detector.
Absorption is favourable, scattering is not, there can be secondary effects, and the probability of either of these interactions depends on (i) the wavelength (photon energy), (ii) the elementary composition of the material (absorption spectrum; characteristic bands), and (iii) the trajectory of the photon (thickness, angle).

The varying fraction of attenuated photons, measured from multiple incident angles for 3D view, is what enables the extraction of structural information (Lambert-Beer's Law).
And attenuation is precisely the property which seemingly correlates with physical density: the higher the density, the higher the attenuation.
Or so it seems.
Yet think of a case in which the specific emission of the source does not match the absorption peaks of the material - remember the example of a white LED not exciting chlorophyl of a green leaf.
Or the opposite case, a substance with absorption which is congruent to the emission spectrum.
Examples of substances problematic for x-ray are water and formol, because they absorb a broad range of photon energies within the x-ray range.


To summarize: both in the visual and x-ray range of electromagnetic radiation, emission and absorption are determined by stochastic interactions of elementary particles.
Spectra summarize ensemble properties of a given light source or material; differential spectra can capture absorption.
The filtering properties of matter can be used to acquire images and reconstruct 3D structure, even in the absence of precise spectral information.


** Scan Artifacts
X-ray images do not always look as we would want them to look.
We call the unfavorable image features "artifacts".
In the opinion of the provocative author, there is actually no such thing as CT scanning artifacts.
The term "artifact" implies that there is an unavoidable error in the measurement, yet instead it can be ascertained that correctly obtained x-ray images are usually accurate.
Any tomographic reconstruction just shows exactly what is measured, convoluted with ideally negligible reconstruction algorithm characteristics.

Some aspects of the measurement might be unfavorable to the observer.
For example, we speak of a "beam hardening artifact" if absorption in the superficial layers of an objects alter the spectrum of the beam on its trajectory, which will affect the virtual representation of the underlying regions citep:VanGompel2011.
However, that is just a normal manifestation of the actual physical process (the stochastic interaction of electromagnetic radiation and matter).
Curiously enough, beam hardening can be minimized by pre-hardening the beam with the use of metal filter plates.
Ring artifacts stem from sensitivity variations on the image detector, which are technically inevitable (due to constraints of the physical detection process), but can be rectified reliably citep:Sijbers2004.
Partial volume effects are caused by finite scan resolution and voxel volume.
Streak artifacts are caused by limited dynamic range.
All these should be considered properties of the scan, rather than interpreting them as an annoyance.


Another group of so-called artifacts might stem from the choice and limitations of the reconstruction algorithm.
There are iterative/algebraic and analytical reconstruction methods citep:Gilbert1972,Andersen1984,Feldkamp1984,Geyer2015,Hansen2021, all of which have their specific limitations.
These algorithms are constantly refined and improved by capable scientists, and specific algorithm variants can already overcome specific limitations @@latex:\citep[e.g.][]{Six2019,Frenkel2022}@@.
In the future, the question of reconstruction artifacts will rather be one of algorithm choice.
The most common reconstruction algorithm, used in 99% of the CT service facilities with cone-beam setups, is "filtered backprojection" (FBP, or Feldkamp/Davis/Kress = FDK algorithm).


To summarize: scan artifacts, if we want to use that label, are perfectly normal.
Some are to a certain degree avoidable, others show intrinsic features of the technical and computational tomography procedure.
Artifacts are interpreted as "something is not as it is supposed to be", despite attenuation-based images being close to technical perfection.
I suspect that the major reason we still perceive artifacts as problematic is that we actually think of matter and physical objects as a distribution of density, i.e. a mass distribution, whereas x-ray scanning really yields a distribution of x-ray attenuation.

Conversely, the only appropriate way to measure an exact mass distribution of an object would be to slice it into little voxel cubes and weigh each of them.
In that sense, computational tomography is certainly a time-saving alternative.
#+begin_center
Yet it must be kept in mind that x-ray images do not quantify density, they quantify attenuation, most often lumped over a spectrum.
#+end_center


** Density Approximations: Two Case Studies
The fact that two physical properties (attenuation and density) are fundamentally different things does not imply that researchers cannot use one to measure the other.
Scientists have repeatedly suggested and attempted to convert CT scan gray values to approximate density citep:DuPlessis2013,Durston2022.


For example, citet:DuPlessis2013 acknowledge difficulties of accuracy and repeatability in extracting density from CT data.
They then average gray values of putatively homogeneous blocks of polymer plastic material, apply linear regression which, as they point out themselves, does not appropriately cover two of the measured data points.
The latter problem is attributed to differences in chemical composition (without discussing the known composition of the objects).
The authors then argue that chemical composition can be assessed by performing a dual energy CT scan (DECT), i.e. scanning at two different tube voltages and taking the ratio of gray values.
Note that this version of DECT is not really "dual energy": the spectrum of energies elicited in a \(60\ kV\) scan is included in the \(230\ kV\) scan; the photons below \(60\ kV\) might even contribute the majority of light in the other scan.
A better differential would have been a \(230\ kV\) scan with metal filter beam hardening.
Nevertheless, comparing the calibration line and the DECT ratio results, the putative outliers do not stand out more than other regression elements (especially PTFE puts the original regression in doubt: it is perfectly fit by the calibration regression, is a modest outlier on the DECT ratio, and clearly does have a special chemical composition).
For a toy pig of unknown plastic material, the authors get higher than actuall mass estimates; they identify chlorine and calcium content as the cause.
On another unknown sample which is assessed similar enough in chemical composition, they retrieve an accurate prediction.
The authors do not quantify or report measurement uncertainty which manifests in gray value distributions, suboptimal regression goodness of fit and potentially high regression sensitivity (PTFE), and other sources of variability citep:Macaulay2017.
Finally, they destroyed a toy pig for the study, which cannot be excused.

To summarize, citet:DuPlessis2013 achieve density prediction in a particular use case (homogeneous, chemically identical objects) and suggest a DECT ratio to assess chemical composition.


citet:Durston2022 attempt a huge leap from there and measure inertial properties from frozen cadaver parts, both conventionally and digitally.
Emphasis: they use whole birds, and their considerable amount of work must be appreciated!
As the authors above, Durston et al. acknowledge the critical assumption of a linear relation between attenuation and density, and consequentially use a linear relation as a conversion from CT scan in Hounsfield Units to actual density.
They supplement the calibration regressions, which show systematic errors at close look (the regression line lies tilted compared to the majority of relevant calibration objects, because it is biased by the "air" sample point).
Still, that the linear fit works at all is surprising, given that this study uses tissue phantoms provided for medical CT, all of which will putatively have a slightly different chemical composition.

To validate their results from CT density estimates, the authors apply two approaches.
The first is a comparison of virtual and physical dissection, with regard to segment mass measurements.
The second is a trifilar pendulum "ground truth" for one axis of the mass moment of inertia.
There is also a validation of the pendulum method, by applying it to manufactured nylon blocks, yet quantitative error estimates remain vague.

Overall, results of the citet:Durston2022 study remain superficial considering the author's valuable efforts on this project.
They juxtapose pie charts of segment masses to verify mass distribution.
They compare the virtually and physically derived dorsoventral moment of inertia, and present what must be considered a clear mismatch, given the lack of meaningful error margins.
They briefly discuss the influence of partial volume effects on density (which, agreeably, could be a problem with feathers), however that is irrelevant for mass and moment of inertia because volume and density both change if a voxel contains air and tissue.
They present "moment of inertia distributions" in various ways, i.e. the contribution of each voxel to a COM-centered \(I\), which is of no practical use for an articulated skeletal system (which they confirm themselves, by comparing extended and retracted wing configuration).
It is a good reproducibility control that their data confirms previous findings of segment masses of some bird species; yet whether the moment of inertia is of any relevance for flying birds of prey who are presumably operating in an air drag regime (light bones and feathers, large wingspans) remains questionable.



The critique of the studies above is harsh.
Yet there is a unifying feature and a reason for the highlighted flaws in theses and other studies: they are /output driven/, and fall short of discussing the mechanics of CT imaging.
As argued above, practitioners often simply assume that structural CT data represents physical density, instead of failing to falsify this claim.
The result are studies which yield approximate density distributions, yet fail to quantify the inaccuracy and uncertainty of their quantitative data.

The author of this thesis is no exception.
As the authors of the studies reviewed above, I lacked insight and was driven by good hope when starting the work presented below.
In consequence, this whole study is one that proves its own irrelevance by falsifying the hypothesis that CT gray values can be converted to physical density.
/Mea culpa./
By documenting and discussing these failed attempts in this chapter, I hope to save future researchers from the same fault.


** Reductionist Approach
This study follows up on the idea of using a calibrated CT scan citep:DuPlessis2013.
Calibration is attempted with cheap, leftover plastic pieces of known material and density, as well as commercial bone mineral calibration phantoms.
We chose a dissected porcine femur as the object of interest of which we seek to estimate the density distribution, and thereby COM and moment of inertia.


#+CAPTION: *Experimental Setup.* A piglet femur was excised an marked with metal bead markers. Together with various calibration objects, the sample was mounted in a PET bottle to fit into the cylindrical scan volume of the FleXCT scanner of the University of Antwerp. The image on the left shows the sample mount, inset is magnified. On the right is one CT projection of the sample, with the femur with markers clearly visible on top.
#+LABEL: fig:femur_scan
#+ATTR_LATEX: :width 18cm
[[./figures/femur_scan.pdf]]


The hypothesis that CT images are a valid approximation of physical density is already falsified by the theoretical considerations above.
The following relevant questions remain:
+ Are the cheap plastic parts appropriate calibration options for organic tissue?
+ How far off the true value is the calculated mass moment of inertia, i.e. what is the measurement error?
+ How much do known artifacts contribute to the measurement error?


It should be pointed out that preliminary (naïve) results of this study were first presented at the conference of the [[http://mielke-bio.info/falk/posts/26.seb2021][Society of Experimental Biology (SEB) in 2021]], which was one year prior to the citet:Durston2022 study.




* Materials and Methods
** The Flying Femur

# p.68 in PhD notes 2
As discussed in the previous chapter, the goal of inverse dynamics is to calculate the segment-wise balance of wrenches, thereby elucidating which forces and moments each joint has to handle in a motor task.
The unit of calculation is therefore a segment.
In a reductionist approach, the purpose of this experiment is to perform all experiments and calculations on an extracted, single segment.

For this purpose, one femur was excised from a piglet specimen which had been used previously in XROMM\footnote{X-ray Reconstruction Of Moving Morphology citep:Brainerd2010} experiments (see below) and euthanized after succesful completion of the experiment (approved by the Ethical Committee of Animal Experimentation, University of Antwerp, Belgium, approval number 2017–25).
The femur was extracted by carefully disarticulating the right upper hindlimb of a piglet, and removing all meat.

#+CAPTION: The "flying femur" experiment: an excised piglet femur used for a reduced XROMM experiment. Left: the femur oscillating on a pendulum. Right: a motor moving the femur in a realistic way.
#+LABEL: fig:flying_femur_fotos
#+ATTR_LATEX: :width 18cm
[[./figures/flying_femur_fotos.png]]


The extracted bone underwent the full XROMM procedure (Fig. \ref{fig:flying_femur_fotos}).
Metal bead markers, \(0.5 mm\) standard soldering balls made out of a lead-tin alloy (\(Sn_{63}Pb_{37}\)), were glued to the extracted bone to simulate the typical XROMM necessity of marked bones.
Biplanar x-ray video recordings were performed on the University of Antwerp's 3D²YMOX system citep:Nguyen2021,Sanctorum2020, with two recording modes: the femur hung on a long, thin wire pendulum (appearing on camera to be "flying"), and rotated by a motor.
After the experiment, the femur was subjected to a calibrated micro-CT scan at a local micro-CT facility.
Plastic parts for calipration were donated by the mechanical workshop of the university, covering a range of physical density from polypropylene (PP, \(916 \frac{kg}{m^3}\)) to Polytetrafluoroethylene (PP, \(2210 \frac{kg}{m^3}\); see overview table in the Results section).
In addition to the plastic debris, two professional calibration phantoms were included in the scan.
Those are hydroxyapathite cylinders, immersed in water over night, with a diameter of about half a centimeter and a length of a centimeter.
They calibrate bone /mineral/ density of \(0.25\ \frac{kg}{m^3}\) and \(0.75\ \frac{kg}{m^3}\), and they have a /physical/ density of \(1254\ \frac{kg}{m^3}\) and \(1485\ \frac{kg}{m^3}\), measured by dividing the weight (measured with a fine scale) and the volume (from CT scan).
Air and tap water volumes in the scan have known densities and complete the calibration series.


Outcomes of the "flying femur" experiment are twofold.
Firstly, this provides a test case as a reference for actual XROMM, just with simpler calculations, but including an "order of magnitude" estimate of the moments of forces required to move the bone (motor experiment).
Secondly, the validity of the calibrated CT method for extracting inertial properties is to be evaluated.


** Piglet Data
The femur was part of a bigger whole set of experiments.
That project involved newborn piglets reared temporarily at the veterinary facilities of the university, and subjected to XROMM recording sessions.
Experiments were approved by the Ethical Committee of Animal Experimentation, University of Antwerp, Belgium, approval number 2017–25.

The part of these experiment relevant for this chapter are the CT scans.
Those were not calibrated, as described above, with the plastic debris; they contained only air, water, and the bone mineral density phantoms.
The scans serve the falsification of the density acquisition method by comparing known segment- and total weight to the outcome of the CT method.


** Scan Parameters
The scan was performed on a customized Tescan Unitom XL, with the following settings:

#+begin_center
|------------------+-------------------|
| voltage          | \(150 kV       \) |
| power            | \(55 W         \) |
| current          | \(\approx 360 mA     \) |
| filter           | \(1.0 mm\ Al   \) |
| detector field   | \(1920\times 1896 px\) |
| pixel size       | \(0.15 mm      \) |
| exposure time    | \(50 ms        \) |
| averages         | \(3            \) |
| projections      | \(2879         \) |
| source-detector  | \(800 mm       \) |
| source-object    | \(267 mm       \) |
| binning          | \(none         \) |
| resolution       | \(50 \mu m       \) |
| scan duration    | \(10 min       \) |
| reco value range | \([-0.2, 1.0]  \) |
|------------------+-------------------|
#+end_center

The \(1.0 mm\) Aluminium filter plate and the relatively high voltage were chosen to reduce beam hardening and metal bead artifacts (see below).
Three averages indicate that every projection is the average of three scan images from the same angle, which is a trick to reduce pixel noise.
Scan geometry was set to give reasonable scan duration and sufficient resolution.
The reconstruction value range was chosen to cover the entire histogram, excluding the metal beads, which gives best dynamic range on the plastic and organic tissue.


** Inertial Properties

All code used on this project, including python implementations of the mathematical formula's below, can be [[https://git.sr.ht/~falk/flying_femur][found online]] (\nolinkurl{https://git.sr.ht/~falk/flying_femur} and \nolinkurl{http://mielke-bio.info/falk/posts/23.ct_density}).

#+CAPTION: Calculation of inertial properties of a limb segment (femur) from CT scans. CT scans are 3D images, consisting of voxels (cubes) each of which is associated with a gray value. If these could be associated with physical density, it would be possible to calculate the center of mass (COM) and other inertial properties. In this procedure, voxels are treated as little mass elements \(m_{i}\), which are at a given vector position \(r_{i}\) from an arbitrary CT origin. The procedure might involve segmentation of the segment of interest.
#+LABEL: fig:inertials
#+ATTR_LATEX: :width 8cm
[[./figures/inertial_properties.pdf]]

*** CT Segmentation
A preliminary step to calculate inertial properties from CT scans is the segmentation of the scan.
Segmentation is the separation of the "relevant" and "irrelevant" sub-volumes of the scan, in this case the bone and the surrounding air or background.
More generally, limb segments which are treated as a unit have are labeled in dedicated software (e.g. 3D Slicer) with a kind of "color brush" or "magic wand" tool; thresholding of grey values and other tricks may simplify the procedure in certain situations.
The outcome of this procedure is a 3D boolean mask which can be used to identify the voxels in the scan which are associated with the bone of interest.

This step might seem trivial, and indeed it is.
Of course, if e.g. the mass of a bone is to be calculated, one intends to sum up the mass of only the bone, excluding the mass of the surrounding air or support material.


*** Mass
The mass of a volume element of a rigid body is calculated as the density of that element, multiplied with its volume.
Summing up all volume elements will give the total mass of the object.
@@latex:\label{eqn:mass}@@
#+begin_center
\[ \sum_{i} m_{i} = \sum\limits_{i \in V} \rho_{i} V_{i} \]
#+end_center

The crucial part here is to get \(\rho_{i}\), the density per voxel (see below).


*** Center of Mass
The center of mass is the mass-weighted average position vector of all volume elements of an object.
Mass \(m_{i}\)is a scalar, the position vector \(r_{i}\) is a three-by-one vector, and their product is summed up for all voxels of the segmented bone.
The result is normalized by the total mass.
The outcome is the three-by-one position vector of the center of mass (COM).
@@latex:\label{eqn:com}@@
#+begin_center
\[ COM = \frac{1}{\sum_i m_{i}} \sum\limits_{i \in V} m_{i} r_{i} \]
#+end_center


*** Mass Moment of Inertia
As stated before, mass moment of inertia is the resistance of an object to angular acceleration.
It can be calculated for any rigid body (see Fig. \ref{fig:inertials}) via an integral formula over all volume elements citep:WikipediaMOI:
@@latex:\label{eqn:mmoi}@@
#+begin_center
\[ I = \sum\limits_{i \in V} m_{i} \left( \lVert r_{i} \rVert ^2 E_3 - r_{i} \otimes r_{i} \right) \]
#+end_center
with the rigid body's volume \(V\) split up into voxels \(i\) which have mass \(m_i\) and position vector \(r_{i}\); \(E_{3}\) is the \(3\times 3\) identity matrix and \(\otimes\) the outer product.

Ideally, this is calculated with respect to the COM as reference point.
Otherwise, the reference point can be changed by the generalized parallel axis / Steiner's theorem @@latex:\citep[][, p. 245]{Lynch2017}@@.
@@latex:\label{eqn:steiner}@@
#+begin_center
\[ I_{p} = I_{0} + m \cdot \left( s^{T} s E_{3} - s s^{T} \right)  \]
#+end_center
with \(s\) being the shift vector.


It is difficult to get an intuition about Mass Moment of Inertia, but classroom demos can illustrate that this measure depends exclusively on the geometric distribution of mass of an object citep:Lewin801L19,LewinMOI.
It is independent of the total mass.
Under controlled experimental conditions, a homogeneous aluminium cylinder will roll down a slope in exactly the same time as a homogeneous lead cylinder of identical form.
This has implications for interpreting the "mass scaling" results below.


** Density Regression
The preliminary step in the procedures above is the relation of gray values \(\gamma\) and physical densities \(\rho\).
This is the search for an (idealized) function \(\gamma = f(\rho )\), which can predict the CT gray value for any given density.
The inverse, \(\rho = f^{-1}(\gamma )\), can then be used to assign densities to gray values from the scan.
Several regression functions were attempted, based on a guessed relation of the gray values of the calibration objects.

The regression was performed in Python, namely [[https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html][using the =scipy.optimize.minimize= function]] to minimize the Euclidean difference between observed and fit values with the Nelder-Mead algorithm, tolerance set to \(10^{-16}\) citep:Gao2012.
Convergence was supported by setting meaningful parameter start values close to the expected outcome (Tab. \ref{tab:regressions}).

#+NAME: tab:regressions
#+ATTR_LATEX: :environment tabular :align |l|l|l|
#+CAPTION: Density Regression Functions and regression start values. The "constant" option refers to assigning each voxel the average, known density, which might be a good approximation for the calculation of mass moment of inertia.
#+begin_table
|-------------+---------------+------------------------------|
|             | function      | start values                 |
|-------------+---------------+------------------------------|
|-------------+---------------+------------------------------|
| linear      | \(a + b \cdot x\)  | \(a=0.175, b=10^{-4}\)          |
| exponential | \(a+b\cdot e^{c\cdot x}\) | \(a=0.12, b=0.05, c=0.0015\) |
| constant    | no regression | /actual density/               |
|-------------+---------------+------------------------------|
|-------------+---------------+------------------------------|
#+end_table

Ideally, all measured points would lie on either of these functions.
Yet that turns out not to be the case in the actual data.
Subsets of the calibration objects were selected for the regression to be plausible: one group were air and the plastic parts, which approximate a linear relation; the other group were air, water, and the two bone mineral density phantoms, which seem to follow an exponential relation.


One of the options for converting gray values to densities is the "constant" option (Tab. \ref{tab:regressions}).
This refers to the idea of setting a constant, or uniform, density value for the whole sub-volume of a segment.
This method requires the weighting of each object; by dividing mass by volume one gets the true (average) density of the whole object.
Though tautologous for mass calculation, the constant density is used for comparison in the calculation of mass moment of inertia.


** Scan Artifacts
To estimate the effect of beam hardening artifacts, one of the scanned calibration objects was selected by segmentation and virtually modified.
I selected PTFE, because it has the highest density in the data set and is therefore most prone to suffering from beam hardening.
The PTFE cylinder has almost ideal cylindrical shape, and was aligned with the scan rotation axis.
The object was segmented and cropped out of the whole scan so that the center of the cylinder aligns with the center of the cropped volume.

To quantify the amount of cupping, the cylinder was transformed to cylinder coordinates, and then flattened by averaging along its vertical (long) axis.
# https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.warp_polar

@@latex:\label{eqn:expfit}@@
#+begin_center
\[ I = a+b\cdot e^{k\cdot r} \]
#+end_center
By using an exponential regression \eqref{eqn:expfit} to the exponential part of that cylinder profile, one can extract a parameter \(k\) which quantifies the amount of cupping.
With that \(k\) known, one can rectify the gray values of the scan by applying a correction factor which would push up the exponential line to a flat constant.

Similarly, one can multiply the intensity values of each voxel in the original volume with an exponential of its distance to the center point.
Depending on the chosen value for \(k\) in that exponential, one can virtually control the amount of beam hardening (Fig. \ref{fig:cupping_methods}).


#+CAPTION: Beam hardening artifact simulation. The top view (A) and side view (B) of a PTFE cylinder with beam hardening strength \(k\) virtually set to \(k=0.5\). (C) Line profile of scan gray values along the blue line indicated in panel A shows the typical "cupping". (D) cylinder coordinate transformation of the slice marked by a blue line in panel B gives the gray values along the radial lines \(r\) at angles \(\phi\) as indicated in panel A. (E) Top and side view for different simulated beam hardening strengths \(k\).
#+LABEL: fig:cupping_methods
#+ATTR_LATEX: :width 18cm
[[./figures/cupping_methods.pdf]]

** Error Propagation
How large a problem are miscalculations of the moment of inertia for calculations of joint moment?
To evaluate this, one has to consider error propagation with the balance equations \eqref{eqn:moment}.
The variable \(I\) only enters the balance equations through the dynamic wrench, \(M = I \ddot\theta\).
This function is linear, so error propagation is quite simple citep:Hughes2010,Normann2016:
@@latex:\label{eqn:moment}@@
#+begin_center
\[\Delta M = \sqrt{\left(\frac{\partial M}{\partial I}\Delta I\right)^2} = \sqrt{\left(\Delta I \ddot\theta\right)^2}\]
#+end_center

Sensitivity is linear at this level: any percentage of error in \(I\) will directly propagate to the moment calculation.


Yet the situation is more involved: calculating \(I\) via equation \eqref{eqn:mmoi} is itself subject to errors, first by inaccuracy in the mass itself (see "regression" above), and second by unceretainty in the COM position and therefore the position vectors \(r_{i}\) of each mass element.
#+begin_center
\[ \Delta I = \left \Delta I \right\mid_{m_i} + \left \Delta I \right\mid_{r_i} = \sqrt{ \sum_{i} \left[ \left(\frac{\partial I}{\partial m_{i}} \Delta m_{i} \right)^2 + \left(\frac{\partial I}{\partial r_{i}} \Delta r_{i}\right)^2 \right] }\]
#+end_center

The direct dependence on mass is visible in equation \eqref{eqn:mmoi}, uncertainty of the mass elements contribute linearly but are added up; errors in the mass of further away mass elements contribute more to the total error.
#+begin_center
\[ \Delta I \mid_{m_i} = \sqrt{\sum\limits_{i}\left(\left( \lVert r_{i} \rVert ^2 E_3 - r_{i} \otimes r_{i} \right)\right)^2 \cdot \Delta m_{i} }\]
#+end_center


The partial derivative with respect to \(r_{i}\) must be added, because \(I\) is usually taken relative to the COM (hence, \(\Delta r_i = \Delta COM\)).
We know that the choice of reference point for moment of inertia can be adjusted by using generalized Steiner, and so the error in the COM propagates as a Steiner component, equation \eqref{eqn:steiner}, with \(s=\Delta COM\).
Yet \(\Delta COM\) also depends non-trivially on the relative mass of volume elements, equation \eqref{eqn:com}.
#+begin_center
\[ \Delta COM = \sqrt{ \frac{1}{\sum_i m_{i}} \sum\limits_{i} \left( r_{i} \cdot \Delta m_{i} \right)^2  + \left(-\left(\Delta \sum_i m_{i} \right)^{-2} \sum\limits_{i} r_{i} \cdot m_{i} \right)^2\]
#+end_center
This now lines out how the target parameter, \(I\), depends on mass elements \(m_{i}\) in different ways.


In practical terms, the expected error can be readily computed by iteratively changing the variables of interest by a percent, to infer how "a percent change" in a parameter effects the result of the calculation.
This is called *"sensitivity analysis"*.
By the analytical considerations above, even without exact analytical solutions, we can see that the variables to change are the regression parameters (\(\pm 5\%\) of their value), the COM position \(\pm 5\%\) of femur length, \(0.25 mm\) in each direction), the total mass (\(\pm 5\%\), which are \(0.26 g\)).



* Results
** Density Calibration Regression

# /data/04_dynamics/21_flying_femur_revival/02_inertials/02_Regression.py

#+CAPTION: Density calibration of a CT scan.
#+LABEL: fig:density_calibration
#+ATTR_LATEX: :width 12cm
[[./figures/regression.pdf]]


** Issue 0: Mass Mismatch and Total Mass Normalization


** Issue 1: Beam Hardening

# /data/04_dynamics/21_flying_femur_revival/11_cupping/05_PlotPTFEInertia.py
#+CAPTION: Effect of beam hardening on mass moment of inertia. (A) Repeat of radial profiles (as in Fig. \ref{fig:cupping_methods}C) for different beam hardening strengths. (B) Calculated mass moments of inertia, unscaled (\(\times\)) and scaled \(\circ\). In this cylinder, \(I_z\) is always larger than \(I_x, I_y\) which are approximately identical. The solid, dark red line indicates the theoretical (true) \(I_z\) of the PTFE cylinder, the dashed red line marks the true value of the other inertial axes. The more beam hardening \(k\), the lower the (unscaled) mass moment of inertia. Noteworthy, at \(k=0\) the inertia values match the true values. However, this is only true for the unscaled curves; when scaling to make the calculated mass of the cylinder match the actual mass (i.e. normalizing mass, see text) the correct inertia is reached at an arbitrary, non-zero \(k\), and the calculated inertia increases with beam hardening due to the normalization.
#+LABEL: fig:cupping_results
#+ATTR_LATEX: :width 18cm
[[./figures/cupping_results.pdf]]

To evaluate what effect beam hardening will have on the calculated mass moment of inertia, we simulated beam hardening on a well described PTFE cylinder within the scan volume.

The only reliable recovery of the true mass moment of inertia (Fig. \ref{fig:cupping_results}B, horizontal lines) is found to be if there is exactly zero cupping.
This generally holds for homogeneous objects: moment of inertia is determined by the geometric distribution of mass elements around the COM; iff the relative mass of all mass elements are well approximated by the density regression (which is only and exclusively the case in homogeneous objects), and iff cupping is negligible, then we can calculate appropriate \(I\) values.
However, if the object is non-homogeneous (as a femur), then for example the relative density of marrow and calcified bone are not appropriately covered, and \(I\) will be incorrect.
Also, if there are *any beam hardening or streak artifacts*, which is non-trivial to remove from FBP reconstructed scans, *the moment of inertia will be incorrect*.
Attention should also be put on the units of the calculated mass moments of inertia: it is in the order of \(10^{-7} kg m^2\).
This is small, justifying extra attention to numeric accuracy of computational methods as well as sources of physical inaccuracy (e.g. COM miscalculation).
Three corollaries:
(1) mass scaling, which above I suspected to retain density distribution, will produce erroneous moments of inertia.
(2) Using "constant" regression (i.e. modelling uniform mass distribution) will only produce accurate inertia for homogeneous objects.
(3) iterative reconstruction methods might partially overcome this issue citep:Six2019, but their application requires prior information and extra work.

With conventional methods, we must conclude that the chance of getting an accurate measurement for mass moment of inertia from conventional CT scans is low, and the potential influence of typical error sources is fatal.



** Issue 2: Metal Bead Artifacts and Chemical Composition

#+CAPTION: Metal Bead Artifacts, marked with orange arrows. Despite the use of an aluminium filter to harden the x-ray beam, metal beads produce conspicuous, star-shaped streaks on the scan reconstructions. The reason that the center of the metal beads appears black is a clipping setting during image preprocessing.
#+LABEL: fig:metal_artifacts
#+ATTR_LATEX: :width 12cm
[[./figures/metal_artifacts.png]]

Another typical artifact in CT scans are metal bead artifacts (Fig. \ref{metal_artifacts}).
Metals are chemical elements with overproportionally higher x-ray attenuation than carbohydrate compounds.
They absorb a large fraction of the incoming radiation, demanding the use of hight energy to avoid shadows arising from missing information in the projections, which can be detrimental to contrast on softer tissue.
The shadows appear as "streaks" or "starbursts" on CT scans, they complicate segmentation, and are unwanted in XROMM visualizations citep:Brainerd2010.
As with other artifacts, metal bead artifacts have their source in limitations of the tomographic method (limited dynamic range, rotationally symmetric scan geometry), and might be corrected by appropriate counter-measures.
Beam hardening reduction by using metal filter plates can improve dynamic range and contrast (at the cost of exposure).
The use of a helical scan geometry in a cone-beam CT should reduce the length and contrast of streaks, because projections from above or below the bead elevation level will project through the tissue behind the bead.

Though pronounced on metal beads due to their spatial confinement, th problem is not restricted to metal.
Streak artifacts also appear between multiple regions of dense bone or strongly absorbant solute (i.e. water), especially if two such regions can be behind each other in the projection geometry.

To re-iterate, there are two reasons for these effects.
The first is a kind of "beam hardening", taken to the extreme: the spectrum of the photon ensemble changes along the projection trajectory, and much more so if x-ray interactions with matter are more numerous.
The second factor is that they are more numerous in some materials than others (irrespective of density): chemical composition is key.


** Sensitivity Analysis


#+NAME: tab:sensitivity
#+ATTR_LATEX: :environment tabular :align |l|l|c|c|c|c|
#+CAPTION: Sensitivity Analysis of the Mass Moment of Inertia calculations. For reference, the actual femur weighed \(5.271 g\) and had a length of \(46 mm\).
#+begin_table
|----------------------+--------------+----------+---------+---------+---------|
| *parameter*            | *change*       | \(\sum_{i}m_{i}\) | \(I_x\) | \(I_y\) | \(I_z\) |
|----------------------+--------------+----------+---------+---------+---------|
|----------------------+--------------+----------+---------+---------+---------|
| *(reference)*          | none         |          |         |         |         |
|----------------------+--------------+----------+---------+---------+---------|
| *regression \(a\)*     | \(+5\%\)     |          |         |         |         |
| *regression \(b\)*     | \(+5\%\)     |          |         |         |         |
|----------------------+--------------+----------+---------+---------+---------|
| *COM \(x\)*            | \(+0.25 mm\) |          |         |         |         |
| *COM \(y\)*            | \(+0.25 mm\) |          |         |         |         |
| *COM \(z\)*            | \(+0.25 mm\) |          |         |         |         |
|----------------------+--------------+----------+---------+---------+---------|
| *mass \(\sum_{i} m_{i}\)* | \(+0.26 g\)  |          |         |         |         |
|----------------------+--------------+----------+---------+---------+---------|
|----------------------+--------------+----------+---------+---------+---------|



* Discussion
** Miscalculated Mass

** Intuitive Inertia

** Which Inertia Component is Relevant?
movement in vivo
sensitivity analysis

** Dynamic Images

** Lack of Alternatives
+ pendulum
+ dissection
+ CAD models

* Summary
At the end of this chapter, it should be clear that the only people using CT images to calculate inertial properties would be Biologists who are agnostic to the basic principles of physics.
This includes the author.
Tomographic images depict attenuation, not physical density, and though these are occasionally correlated, they remain fundamentally different properties of matter.
Above, I discussed potential flaws in the calculation of mass, center of mass, and mass moment of inertia, as well as corner cases in which the calculation might co-incidentally yield appropriate results.
In all other cases, the calculation will certainly yield wrong results.
The magnitude of the error is most likely non-negligible, since some axes of inertia in balance equations have very small base magnitude and are therefore susceptible to faults.


However, with all that objection put to paper, it must be stated that there is no effective alternative to the use of CT scans.
There is no "density tomography", and common alternative methods (pendulum, dissection, CAD models) suffer from equally large error margins for other reasons (e.g. measurement inaccuracy, non-static configuration during movements).
Using attenuation values to calculate densities is about as accurate as setting \(\pi \equiv 3\) in physics classes (a totally valid thing to do, if at the same time setting \(g \equiv 10\)).
Yet when knowing and avoiding typical pitfalls (beam hardening, metal beads, symmetries), and when keeping track of error magnitudes (e.g. by sensitivity analysis, or Gaussian error propagation), the so-calculated inertial properties might be a just sufficiently accurate approximation of the true values.


* Acknowledgements
# Joaquim & VisionLab
tbd.

# \pagebreak
# References
# \bibliographystyle{apalike}
# \bibliography{literature.bib}


#+begin_comment
% https://doi.org/10.1117/12.2595473
% https://doi.org/10.2214/ajr.143.5.1101
% https://doi.org/10.1016/S0963-8695(97)00020-0
% https://doi.org/10.1093/iob/obad005
scattering types of xray beams
poly-SIRT
Liu2023 spectral CT https://www.nature.com/articles/s41598-023-33264-2#citeas
% AI density estimation https://doi.org/10.1016/j.media.2021.102061
#+end_comment
