#+TITLE: Extracting Inertial Properties from X-Ray Computed Tomography: A Failed Attempt
#+AUTHOR: Falk Mielke
#+DATE: <2023-07-05 Thu>

#+SETUPFILE: latex_header.org
#+EXPORT_FILE_NAME: pt3ch7_inertials

#+BIBLIOGRAPHY: literature.bib apalike
#+BEGIN_SRC elisp :results none :exports none :tangle no
(setq bibtex-completion-bibliography
      '("literature.bib"))
#+END_SRC

#+OPTIONS: toc:t

#+STARTUP: noinlineimges showeverything entitiespretty
@@latex:\clearpage@@
#+ODT: <text:p text:style-name="PageBreak"/>


* Abstract

* Introduction
** Computed Tomography and Density
Since the advent of x-ray imaging, people are intrigued by the ability to see the inner structure of objects and living creatures (such as the famous hand of Röntgen's wife, "Über eine neue Art von Strahlen", 1895).
This desire even increased by the development of computed tomography citep:Beckmann2006,Hounsfield1973, a set of techniques which enable the reconstruction and visualization of three-dimensional structural images.
The transmission images obtained via high energy electromagnetic radiation often serve to answer qualitative questions (e.g. whether a bone is fractured, whether there are porosities in asphalt drill cores).
Quantitative questions are obvious with regard to the shape of a scanned structure (e.g. the size of porosities, the length of a fracture, the shape of a bone).
However, researchers have been struggling with the quantitative extraction of material properties from Computed Tomography (CT) data.
The material property of primary interest is physical density; from a given density distribution, the other relevant inertial properties can be calculated.


Reseachers suggested early on to relate the gray value of CT images to density citep:Mull1984,Phelps1975, yet it was immediately noted that the relation is nothing more than a correlation which only holds under specific circumstances.
Even these pioneer works acknowledge that there must be discrepancies between real and x-ray-derived densities, which can be explained by (i) the polychromatic character (source spectrum) of the used radiation, (ii) chemical composition (absorption spectrum), and (iii) scan artifacts.
# scattering types,
These issues demand a detailed explanation, below.
Notwithstanding this list of known problems, people have repeatedly attempted to extract density and inertial propertes from CT scans @@latex: \citep[][, as well as the present study]{Phillips1997,DuPlessis2013,Durston2022}@@.
The purpose of this chapter is to explore whether or not (or under which circumstances) CT gray values can be used to estimate density distributions, and thereby mass and other derived inertial properties.
I will start by giving a brief intro to crucial aspects of CT scanning technology, reviewing similar attempts by others, then introducing a simple experimental setup to measure dynamics of an excised piglet femur, and with that re-attempting the extraction of inertial properties.


** Emission and Absorption
Visible light and x-ray radiation are, to a large degree, analogous.
The reason for this is that both are just electromagnetic radiation; they differ in wavelength and thereby energy.
To illustrate what is happening with x-ray light during a CT experiment, I will use the analogy of visible light.


On some military signal flashlights, one can set the light to be white (i.e. bulb spectrum, unfiltered) or filtered either red or green, sometimes a third color.
Light are photons, "elementary particles which are the quantum of the electromagnetic field" ([[https://en.wikipedia.org/wiki/Photon][wikipedia: photon]]).
Filters let through some of them and prohibit others from passing.
The same principle holds for party lights or colored window sheets: a light source is placed behind a filter sheet which blocks most colors.
On the military flashlight, the "white" setting is general purpose, unfiltered, which will let pass the maximum number of photons you can expect from a given bulb.
"Lights" are devices which constantly emit photons of a specific variety of wavelengths (colors); we call this variety the "spectrum" (see below).
Put simply, applying a red filter sheet will change the composition of the passing light by blocking all the "non-red" photons.
Because red photons pass the filter, the filtered spectrum will be predominantly red, and appear red to our visual perceptive system.

Most plants have evolved to be green; their cells hold organelles with the green pigment chlorophyll, which is optimized to absorb some non-green (e.g. red) wavelengths of light very well (Fig. \ref{fig:spectrum}, green curve).
The ensemble of non-absorbed photons appears green to us, which is why leaves generally appear green to our view.
But leaves only appear green if there is a green content in the incident light!
Green leaves will look red under red light.
Contrary to internet myth, the military use case of red flashlight would be an operation which requires as inconspicuous light as possible in a vegetated environment.
Red light will hardly reflect from gras or bush, and can therefore reduce the chance of being spotted at night by enemy surveillance.
If you need to look for something in a dark forest, and you would like to avoid being seen, use a red flashlight.


#+CAPTION: Spectra. The x-axis shows all wavelengths \(\lambda\) (\(nm\)) of relevance (in this case the range of visible light, for illustration). Related to wavelength and therefore viable axis label alternatives are frequency (\(Hz\)) and photon energy (\(keV\)). The y-axis shows photon occurrence probability, or normalized intensity \(I\), or the intensity difference \(\Delta I\) for the absorption spectrum. Black curve: emission spectrum of a white LED \citep{Tanabe2005}. Green curve: the approximate absorption spectrum of chlorophyll A \citep{Zscheile1934}. The chlorophyll will hardly get excited by the LED.
#+LABEL: fig:spectrum
#+ATTR_LATEX: :width 13cm
[[./figures/spectrum.pdf]]


To characterize light which is emitted, reflected, or absorbed, one can use a spectrum (Fig. \ref{fig:spectrum}).
Red LED's are an alternative to red filters: they immediately produce a spectrum which is biased towards low frequencies.
We can assess that red LEDs have a different *source spectrum or emission spectrum* than white LEDS or "vintage" (tungsten) light bulbs.
If the light from a white source is filtered (e.g. by a red sheet of thin plastic), the spectrum is altered.
A red LED viewed through a green-pass filter (e.g. a leaf) might appear to be "off", when really power is "on", because the majority of photons are absorbed by the filter.

In fact, light hitting /any/ object will change its spectral composition, depending on the material's *absorption, transmission, and reflection spectrum*.
This is also a filtering process: the outgoing light will depend on the incoming spectrum and the material properties of the object.
Plant leaves will almost entirely absorb a narrow band of red light.
All that is happening here are interactions of photons and matter.
Those interactions crucially depend on the energy/frequency/wavelength of the photons, and the energetic/vibrational/resonant molecular properties of the matter.
A (differential) spectrum is a way to depict a wavelength dependence.


#+CAPTION: X-Ray emission spectrum. An x-ray source will emit photons with a variety of energies ("colors"). Bremsstrahlung will cover a wide range of photon energies, whereas discrete peaks are caused by specific emission processes in the target material. \citep[taken from ][, creative commons license]{Berger2018fig8}.
#+LABEL: fig:xray_emission
#+ATTR_LATEX: :width 10cm
[[./figures/Berger2018.png]]

The situation is exactly analogous for x-rays citep:Berger2018,Buzug2008.
X-rays are also photons, just at a different wavelength (range \(10pm - 10nm\)).
X-ray sources are "targets", i.e. anodes made of certain metals (Tungsten, Molybdenum, ...), shot at with an electron beam which is evoked by applying voltage (e.g. \(60 kV\)) to the anode and a warmed-up kathode.
When hit by electrons, the target will emit x-ray photons of a specific composition of energies (spectrum, Fig. \ref{fig:xray_emission}).
The source emission is generally *polychromatic*, i.e. consisting of multiple colors/energies (just as the spectra in Figs. \ref{fig:spectrum} and \ref{fig:xray_emission}).
Most household CT scanners (in contrast to synchrotrons) have a polychromatic source.
On the other hand, x-ray detectors usually produce monochrome images, but are not monochromatic!
They integrate intensities over a wide range of wavelengths (in a specific way that could be described by a detection sensitivity spectrum, which adds another layer of nuisance).
There is ongoing development on the frontier of "spectral CT" citep:Liu2023, yet resolution (spectral and spatial) are currently still below par (whereas price is not).


Once set on their path from within the x-ray source, x-ray photons interact stochastically with matter they encounter on their trajectory.
Much simplified, they are either absorbed or scattered (Rayleigh scattering, Compton scattering); "attenuation" is the term to describe that not all photons reach the detector.
Absorption is favourable, scattering is not, there can be secondary effects, and the probability of either of these interactions depends on (i) the wavelength (photon energy), (ii) the elementary composition of the material (absorption spectrum; characteristic bands), and (iii) the trajectory of the photon (thickness, angle).

The varying fraction of attenuated photons, measured from multiple incident angles for 3D view, is what enables the extraction of structural information (Lambert-Beer's Law).
And attenuation is precisely the property which is thought to correlate with physical density: the higher the density, the higher the attenuation.
Or so it seems.
Yet think of a case in which the specific emission of the source does not match the absorption peaks of the material - remember the example of a white LED not exciting chlorophyll of a green leaf.
Or the opposite case, a substance with an absorption spectrum which is mostly congruent to the emission spectrum of the source.
Examples of substances problematic for x-ray are water and formol, because they absorb a broad range of photon energies within the x-ray range.


To summarize: both in the visual and x-ray range of electromagnetic radiation, emission and absorption are determined by stochastic interactions of elementary particles.
Spectra summarize ensemble properties of a given light source or material; differential spectra measure relative absorption.
The filtering properties of matter can be used to acquire images and reconstruct 3D structure, even in the absence of precise spectral information.


** Scan Artifacts
X-ray images do not always look as we would want them to look.
The unfavorable image features are commonly called "artifacts".
In the opinion of the provocative author, there is actually no such thing as CT scanning artifacts.
The term "artifact" implies that there is an unavoidable "error" in the measurement, yet instead it can be ascertained that correctly obtained x-ray images are highly accurate.
Any tomographic reconstruction just shows exactly what is measured, convoluted with ideally negligible reconstruction algorithm characteristics.

Acknowledged, some aspects of the measurement might be unfavorable to the observer.
For example, we speak of a "beam hardening artifact" if absorption in the superficial layers of an objects alter the spectrum of the beam on its trajectory, which will affect the virtual representation of the deeper regions citep:VanGompel2011.
However, that is just a normal manifestation of the actual physical process (the stochastic interaction of electromagnetic radiation and matter, see above).
Curiously, beam hardening can be minimized by pre-hardening the beam with the use of metal filter plates.
Ring artifacts stem from sensitivity variations on the image detector, which are technically inevitable (due to constraints of the physical detection process), but can be rectified reliably citep:Sijbers2004.
Partial volume effects are caused by finite scan resolution and voxel volume.
Streak artifacts are caused by limited dynamic range and "photon starvation" (i.e. beam hardening, again).
All these could be considered properties of the scan, rather than interpreting them as an annoyance.


Another group of so-called artifacts might stem from the choice and limitations of the reconstruction algorithm.
There are iterative/algebraic and analytical reconstruction methods citep:Gilbert1972,Andersen1984,Feldkamp1984,Geyer2015,Hansen2021, all of which have their specific limitations.
These algorithms are constantly refined and improved by capable scientists, and specific algorithm variants can already overcome specific scan limitations @@latex:\citep[e.g.][]{Six2019,Frenkel2022}@@.
In the future, the question of reconstruction artifacts will rather be one of algorithm choice.
The most common reconstruction algorithm, used in a vast majority of the CT service facilities with cone-beam setups, is "filtered backprojection" (FBP, or Feldkamp/Davis/Kress = FDK algorithm).


To summarize: scan artifacts, if we want to use that label, are perfectly normal.
Some are to a certain degree avoidable, others show intrinsic features of the technical and computational tomography procedure.
Artifacts are interpreted as "something is not as it is supposed to be", despite attenuation-based images being close to technical perfection.
I suspect that the major reason we still perceive artifacts as problematic is that we actually think of matter and physical objects as a distribution of density, i.e. a mass distribution, whereas x-ray scanning really yields a distribution of x-ray attenuation.

Conversely, the only appropriate way to measure an exact mass distribution of an object would be to slice it into little voxel cubes and weigh each of them.
In that sense, computational tomography is certainly a time-saving alternative.
#+begin_center
Yet it must be kept in mind that x-ray images do not quantify density, they quantify attenuation, most often lumped over a spectrum.
#+end_center


** Density Approximations: Two Case Studies
The fact that two physical properties (attenuation and density) are fundamentally different things does not imply that researchers cannot use one to measure the other.
Scientists have repeatedly suggested and attempted to convert CT scan gray values to approximate density citep:DuPlessis2013,Durston2022.


For example, citet:DuPlessis2013 acknowledge difficulties of accuracy and repeatability in extracting density from CT data.

They then average gray values of putatively homogeneous blocks of polymer plastic material, apply linear regression which, as they point out themselves, does not appropriately cover two of the measured data points.
The latter problem is attributed to differences in chemical composition (without discussing the known composition of the objects).
The authors then argue that chemical composition can be assessed by performing a dual energy CT scan (DECT), i.e. scanning at two different tube voltages and taking the ratio of gray values.
Note that this version of DECT is not really "dual" energy: the spectrum of energies elicited in a \(60\ kV\) scan is included in the \(230\ kV\) scan; the photons below \(60\ kV\) might even contribute the majority of light in the high energy scan.
A better differential would have been achieved by incorporating metal filters in the \(230\ kV\) scan.
Nevertheless, comparing the calibration line and the DECT ratio results, the putative outliers do not stand out more than other regression elements (especially PTFE puts the original regression in doubt: it is perfectly fit by the calibration regression, is a modest outlier on the DECT ratio, and clearly does have a special chemical composition containing fluor).

For a toy pig of unknown plastic material, the authors get higher than actuall mass estimates; they identify chlorine and calcium content as the cause.
On another unknown sample which is assessed similar enough in chemical composition, they retrieve an accurate prediction.
The authors do not quantify or report measurement uncertainty which manifests in gray value distributions, suboptimal regression goodness of fit and potentially high regression sensitivity (PTFE), or other sources of variability citep:Macaulay2017.
Finally, they destroyed a toy pig for the study, which cannot be excused.

In a nutshell, citet:DuPlessis2013 attempt density prediction in a particular use case (homogeneous, chemically identical objects) and suggest a DECT ratio to assess chemical composition.


citet:Durston2022 attempt a huge leap from there and measure inertial properties from frozen cadaver parts, both conventionally and digitally.
Emphasis: they use whole birds, and their considerable amount of work must be appreciated!

As the authors above, Durston et al. acknowledge the critical assumption of a linear relation between attenuation and density, and consequentially use a linear relation as a conversion from CT scan in Hounsfield Units to actual density.
They supplement the calibration regressions, which show systematic errors at close look (the regression line lies tilted compared to the majority of relevant calibration objects, because it is biased by the "air" sample point; the authors do not discuss this).
Still, that the linear fit works at all is surprising, given that this study uses tissue phantoms provided for medical CT, all of which will putatively have a slightly different chemical composition (linearity assumption violated).

To validate their results from CT density estimates, the authors apply two approaches.
The first is a comparison of virtual and physical dissection, with regard to segment mass measurements.
The second is a trifilar pendulum "ground truth" for one axis of the mass moment of inertia.
There is also a validation of the pendulum method, by applying it to manufactured nylon blocks, yet quantitative error estimates remain vague.

Overall, results of the citet:Durston2022 study remain superficial considering the author's valuable efforts on this project.
They juxtapose pie charts of segment masses to verify mass distribution, which is far too inaccurate.
They compare the virtually and physically derived dorsoventral moment of inertia, and present what must be a clear mismatch, considering the lack of meaningful error margins.
They briefly discuss the influence of partial volume effects on density (which, agreeably, could be a problem with feathers), however that is irrelevant for mass and moment of inertia because volume and density both change if a voxel contains air and tissue.
They present "moment of inertia distributions" in various ways, i.e. the contribution of each voxel to a COM-centered \(I\), which is of no practical use for an articulated skeletal system (which they confirm themselves, by comparing extended and retracted wing configuration).
It is a good reproducibility control that their data confirms previous findings of segment masses of some bird species; yet whether the moment of inertia is of any relevance for flying birds of prey who are presumably operating in an air drag regime (light bones and feathers, large wingspans) remains questionable.



This critique of the studies above is harsh, and I apologize for pointing a finger.
Yet there is a unifying feature and a reason for the highlighted flaws in theses and other studies: they are /output driven/, and fall short of discussing the mechanistics of CT imaging.
As argued above, practitioners often simply assume that structural CT data represents physical density, instead of failing to falsify this claim.
The results are studies which yield approximate density distributions, yet fail to quantify the inaccuracy and uncertainty of their quantitative data.

The author of this thesis is no exception.
As the authors of the studies reviewed here, I lacked insight and was driven by good hope when starting the work on the present project.
In consequence, this whole study is one that proves its own irrelevance by falsifying the hypothesis that CT gray values can be converted to physical density.
/Mea culpa./
By documenting and discussing these failed attempts in this chapter, I hope to save future researchers from the same fault.


** Reductionist Approach
This study follows up on the idea of using a calibrated CT scan citep:DuPlessis2013.
Calibration is attempted with cheap, leftover plastic pieces of known material and density, as well as commercial bone mineral calibration phantoms.
We chose a dissected porcine femur as the object of interest of which we seek to estimate the density distribution, and thereby COM and moment of inertia (Fig. \ref{fig:femur_scan}).
We also attempted to validate the method on dissected animal specimens @@latex:\citep[as][]{Durston2022}@@.

#+CAPTION: *Experimental Setup.* A piglet femur was excised an marked with metal bead markers. Together with various calibration objects, the sample was mounted in a PET bottle to fit into the cylindrical scan volume of the FleXCT scanner of the University of Antwerp. The image on the left shows the sample mount, magnified on the inset. On the right is one CT projection of the sample, with the femur with markers clearly visible on top.
#+LABEL: fig:femur_scan
#+ATTR_LATEX: :width 18cm
[[./figures/femur_scan.pdf]]


The hypothesis that CT images are a valid approximation of physical density is already falsified by the theoretical considerations above.
The following relevant questions remain:
+ Are the cheap plastic parts appropriate calibration options for organic tissue?
+ How far off the true value is the calculated mass moment of inertia, i.e. what is the measurement error?
+ How much do known artifacts contribute to the measurement error?


It should be pointed out that preliminary (naïve) results of this study were first presented at the conference of the [[http://mielke-bio.info/falk/posts/26.seb2021][Society of Experimental Biology (SEB) in 2021]], which was one year prior to the citet:Durston2022 study.




* Materials and Methods
** The Flying Femur

# p.68 in PhD notes 2
As discussed in the previous chapter, the goal of inverse dynamics is to calculate the segment-wise balance of wrenches, thereby elucidating which forces and moments each joint has to handle in a motor task.
The unit of calculation is therefore a segment.
In a reductionist approach, the purpose of this experiment is to perform all procedures and calculations on an extracted, single segment.

For this purpose, one femur was excised from a piglet specimen which had been used previously in XROMM\footnote{X-ray Reconstruction Of Moving Morphology citep:Brainerd2010} experiments (see below).
The animal was euthanized after succesful completion of the experiment.
All this was approved by the Ethical Committee of Animal Experimentation, University of Antwerp, Belgium (approval number 2017–25).
The femur was extracted by carefully disarticulating the parts of the right hindlimb of the piglet, isolating the femur, and removing all meat.

#+CAPTION: The "flying femur" experiment: an excised piglet femur XROMM experiments as an allegory of reductionism. Left: the femur oscillating on a pendulum. Right: installation with a motor capable of moving the femur in a realistic way.
#+LABEL: fig:flying_femur_fotos
#+ATTR_LATEX: :width 18cm
[[./figures/flying_femur_fotos.png]]


The extracted bone underwent the full XROMM procedure (Fig. \ref{fig:flying_femur_fotos}).
Metal bead markers, \(0.5 mm\) standard soldering balls made out of a lead-tin alloy (\(Sn_{63}Pb_{37}\)), were glued to the extracted bone to simulate the typical XROMM necessity of marked bones and facilitate video digitization.
Biplanar x-ray video recordings were performed on the University of Antwerp's 3D²YMOX system citep:Nguyen2021,Sanctorum2020, with two recording modes.
In one mode, the femur hung on a long, thin wire pendulum (appearing on camera to be "flying").
In a second mode, the bone was rotated realistically by a motor to which it was attached with an ingenious, radiotranslucent, custom-made plastic clamp.

After the XROMM experiment, the femur was subjected to a calibrated micro-CT scan at a local micro-CT facility.
Plastic parts for calibration were donated by the mechanical workshop of the university (who thought it was worthless waste), covering a range of physical density from polypropylene (PP, \(916 \frac{kg}{m^3}\)) to Polytetrafluoroethylene (PP, \(2210 \frac{kg}{m^3}\)).
# ; see overview table in the Results section).
In addition to the plastic debris, two professional calibration phantoms (Bruker) were included in the scan.
Those are hydroxyapathite cylinders, immersed in water over night, with a diameter of about half a centimeter and a length of a centimeter.
They calibrate bone /mineral/ density of \(0.25\ \frac{kg}{m^3}\) and \(0.75\ \frac{kg}{m^3}\), and they have a /physical/ density of \(1254\ \frac{kg}{m^3}\) and \(1485\ \frac{kg}{m^3}\).
The latter was measured by dividing the weight (measured with a fine scale) and the volume (from CT scan), after the author had found out that those are different quantities.
Air and tap water volumes in the scan have known densities and complete the calibration series.


Outcomes of the "flying femur" experiment are twofold.
Firstly, this provides a test case as a reference for actual XROMM, just with simpler calculations, but including an "order of magnitude" estimate of the moments and forces required to move the bone (motor experiment).
Secondly, the validity of the calibrated CT method for extracting inertial properties is to be evaluated.


** Piglet Data
The femur was part of an animal, and thus also part of a bigger whole set of experiments.
That project involved newborn piglets reared temporarily at the veterinary facilities of the University of Antwerp, and subjected to XROMM recording sessions.
Experiments were approved by the Ethical Committee of Animal Experimentation, University of Antwerp, Belgium (approval number 2017–25) and performed in June and July 2019.

The part of these experiment relevant for this chapter are the CT scans.
Those were not calibrated with the full array plastic debris; they contained only air, water, and the bone mineral density phantoms.
One of the piglet scans was chosen for the validation of the density acquisition method by comparing known segment- and total weight to the outcome of the CT method.
For this purpose, the animal was dissected both physically and virtually (segmentation, Fig. \ref{fig:piglet_segmentation}) and the results compared.
Segments were weighted individually on a precision scale.
Virtual segments were processed with the density regression procedure (see below) to compute segment-wise masses.

#+CAPTION: Virtual dissection (segmentation) of a piglet CT scan. Example slice.
#+LABEL: fig:piglet_segmentation
#+ATTR_LATEX: :width 12cm
[[./figures/virtual_dissection.png]]


** Scan Parameters

#+NAME: tab:ct_settings
#+ATTR_LATEX: :environment tabular :align |l|c|
#+CAPTION: CT scan settings for the calibrated femur scan.
#+begin_table
|------------------+-------------------|
| voltage          | \(150 kV       \) |
| power            | \(55 W         \) |
| current          | \(\approx 360 mA     \) |
| filter           | \(1.0 mm\ Al   \) |
| detector field   | \(1920\times 1896 px\) |
| pixel size       | \(0.15 mm      \) |
| exposure time    | \(50 ms        \) |
| averages         | \(3            \) |
| projections      | \(2879         \) |
| source-detector  | \(800 mm       \) |
| source-object    | \(267 mm       \) |
| binning          | \(none         \) |
| resolution       | \(50 \mu m       \) |
| scan duration    | \(10 min       \) |
| reco value range | \([-0.2, 1.0]  \) |
|------------------+-------------------|
#+end_table

The scan was performed on a customized Tescan Unitom XL, with appropriate settings (Tab. \ref{tab:ct_settings}).
The \(1.0 mm\) Aluminium filter plate and the relatively high voltage were chosen to reduce beam hardening and metal bead artifacts (see below).
Three averages indicate that every projection is the average of three scan images from the same angle, which is a common trick to reduce pixel noise.
Scan geometry was set to give reasonable scan duration and sufficient resolution.
The reconstruction value range was chosen to cover the entire histogram, excluding the metal beads, which gives best dynamic range on the plastic and organic tissue.


The piglet scans for the second experiment were performed at a different facility and with slightly different settings.
Piglets were scanned in frozen state and in bags of two individuals at a time, to save time and cost.
Air, water, and the bone mineral density phantoms were available for calibration in these scans.
Resolution was lower, but exposure settings were comparable to the ones on the femur experiment.


** Inertial Properties

All code used on this project, including python implementations of the mathematical formula's below, can be [[https://git.sr.ht/~falk/flying_femur][found online]] (\nolinkurl{https://git.sr.ht/~falk/flying_femur} and \nolinkurl{http://mielke-bio.info/falk/posts/23.ct_density}).

#+CAPTION: Calculation of inertial properties of a limb segment (femur) from CT scans. CT scans are 3D images, consisting of voxels (cubes) each of which is associated with a gray value. If these could be associated with physical density, it would be possible to calculate the mass, center of mass (COM) and mass moment of inertia. In this procedure, voxels are treated as little mass elements \(m_{i}\), which are at a given vector position \(r_{i}\) from an arbitrary CT origin. The procedure might involve segmentation of the scan to isolate the volume of interest.
#+LABEL: fig:inertials
#+ATTR_LATEX: :width 8cm
[[./figures/inertial_properties.pdf]]

*** CT Segmentation
A preliminary step to calculate inertial properties from CT scans is the segmentation of the scan.
Segmentation is the separation of the "relevant" and "irrelevant" sub-volumes within the image stack, in this case the bone and the surrounding air or background.
More generally, limb segments which are treated as a unit have are labeled in dedicated software (e.g. [[https://www.slicer.org][3D Slicer]]) with a kind of "color brush" or "magic wand" tool; thresholding of grey values and other tricks may simplify the procedure in certain situations.
The outcome of this procedure is a 3D boolean mask which can be used to identify the voxels in the scan which are associated with the bone of interest.

This step might seem trivial, time consuming, yet necessary, and indeed it is.
Of course, if e.g. the mass of a bone is to be calculated, one intends to sum up the mass of only the bone, excluding the mass of the surrounding air or support material.


*** Mass
The mass of a volume element of a rigid body is calculated as the density of that element, multiplied with its volume.
Summing up all volume elements will give the total mass of the object.
@@latex:\label{eqn:mass}@@
#+begin_center
\[ \sum_{i} m_{i} = \sum\limits_{i \in V} \rho_{i} V_{i} \]
#+end_center

The crucial part here is to get \(\rho_{i}\), the density per voxel, which we attempt via a regression (see below).


*** Center of Mass
The center of mass is the mass-weighted average position vector of all volume elements of an object.
For each volume element \(i\), mass \(m_{i}\) is a scalar, the position vector \(r_{i}\) is a three-by-one vector, and their product is summed up for all voxels of the segmented bone.
The result is normalized by the total mass.
The outcome is the three-by-one position vector of the center of mass (COM).
@@latex:\label{eqn:com}@@
#+begin_center
\[ COM = \frac{1}{\sum_i m_{i}} \sum\limits_{i \in V} m_{i} r_{i} \]
#+end_center


*** Mass Moment of Inertia
As stated before, mass moment of inertia is the resistance of an object to angular acceleration.
It can be calculated for any rigid body (see Fig. \ref{fig:inertials}) via an integral formula over all volume elements citep:WikipediaMOI:
@@latex:\label{eqn:mmoi}@@
#+begin_center
\[ I = \sum\limits_{i \in V} m_{i} \left( \lVert r_{i} \rVert ^2 E_3 - r_{i} \otimes r_{i} \right) \]
#+end_center
with the rigid body's volume \(V\) split up into voxels \(i\) which have mass \(m_i\) and position vector \(r_{i}\); \(E_{3}\) is the \(3\times 3\) identity matrix and \(\otimes\) the outer product.

Initially, this is always calculated with respect to the COM as reference point.
Otherwise, the reference point can be changed by the generalized parallel axis / Steiner's theorem @@latex:\citep[][, p. 245]{Lynch2017}@@.
@@latex:\label{eqn:steiner}@@
#+begin_center
\[ I_{p} = I_{0} + m \cdot \left( s^{T} s E_{3} - s s^{T} \right)  \]
#+end_center
with \(s\) being the shift vector connecting the original and target points.


It is difficult to get an intuition about Mass Moment of Inertia, but classroom demos can illustrate that this measure depends exclusively on the geometric distribution of mass of an object citep:Lewin801L19,LewinMOI.
For symmetrical objects, it is independent of the total mass.
Under controlled experimental conditions, a homogeneous aluminium cylinder will roll down a slope in exactly the same time as a homogeneous lead cylinder of identical form.
This has implications for interpreting the "mass scaling" results below.


** Density Regression
The critical step in the procedures above is the relation of gray values \(\gamma\) and physical densities \(\rho\).
This is the search for an (idealized) function \(\gamma = f(\rho )\), which can predict the CT gray value for any given density.
The inverse, \(\rho = f^{-1}(\gamma )\), can then be used to assign densities to gray values from the scan.
Several regression functions were attempted, based on a guessed relation of the observed gray values of the calibration objects.

The regression was performed in Python, namely [[https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html][using the =scipy.optimize.minimize= function]] to minimize the Euclidean difference between observed and fit values with the Nelder-Mead algorithm, tolerance set to \(10^{-16}\) citep:Gao2012.
Convergence was supported by setting meaningful parameter start values close to the expected outcome (Tab. \ref{tab:regressions}).

#+NAME: tab:regressions
#+ATTR_LATEX: :environment tabular :align |l|l|l|
#+CAPTION: Density Regression Functions and regression start values.
#+begin_table
|-------------+---------------+------------------------------|
|             | function      | start values                 |
|-------------+---------------+------------------------------|
|-------------+---------------+------------------------------|
| linear      | \(a + b \cdot x\)  | \(a=0.175, b=10^{-4}\)          |
| exponential | \(a+b\cdot e^{c\cdot x}\) | \(a=0.12, b=0.05, c=0.0015\) |
|-------------+---------------+------------------------------|
|-------------+---------------+------------------------------|
#+end_table

Ideally, all measured points would lie on either of these functions.
Yet that turns out not to be the case in the actual data.
Subsets of the calibration objects were selected for the regression to be plausible: one group were air and the plastic parts, which approximate a linear relation; the other group were air, water, and the two bone mineral density phantoms, which seem to follow an exponential relation.


#+begin_comment
# The "constant" option refers to assigning each voxel the average, known density, which might be a good approximation for the calculation of mass moment of inertia.
One of the options for converting gray values to densities is the "constant" option (Tab. \ref{tab:regressions}).
This refers to the idea of setting a constant, or uniform, density value for the whole sub-volume of a segment.
This method requires the weighting of each object; by dividing mass by volume one gets the true (average) density of the whole object.
Though tautologous for mass calculation, the constant density is used for comparison in the calculation of mass moment of inertia.
#+end_comment


** Scan Artifacts
To estimate the effect of beam hardening artifacts, one of the scanned calibration objects was selected by segmentation and virtually modified.
I selected PTFE, because it has the highest density in the data set and is therefore most prone to suffering from beam hardening.
The PTFE cylinder has almost ideal cylindrical shape, and was aligned with the scan rotation axis.
The object was segmented and cropped out of the whole scan so that the center of the cylinder aligns with the center of the cropped volume.

To quantify the amount of cupping, the cylinder was transformed to cylinder coordinates (scikit image/transform/warp polar, \nolinkurl{https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.warp_polar}), and then flattened by averaging along its vertical (long) axis.
# https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.warp_polar

@@latex:\label{eqn:expfit}@@
#+begin_center
\[ I = a+b\cdot e^{k\cdot r} \]
#+end_center
By using an exponential regression \eqref{eqn:expfit} to the exponential part of that cylinder profile, one can extract a parameter \(k\) which quantifies the amount of cupping (\(k\) as in the Dutch word "kopje").
With that \(k\) known, one can rectify the gray values of the scan by applying a correction factor which would push up the exponential line to a flat constant.

Similarly, one can multiply the intensity values of each voxel in the original volume with an exponential of its distance to the center point.
Depending on the chosen value for \(k\) in that exponential, one can virtually control the amount of beam hardening (Fig. \ref{fig:cupping_methods}).


#+CAPTION: Beam hardening artifact simulation. The top view (A) and side view (B) of a PTFE cylinder with beam hardening strength \(k\) virtually set to \(k=0.5\). (C) Line profile of scan gray values along the blue line indicated in panel A shows the typical "cupping". (D) cylinder coordinate transformation of the slice marked by a blue line in panel B gives the gray values along the radial lines \(r\) at angles \(\phi\) as indicated in panel A. (E) Top and side view for different simulated beam hardening strengths \(k\).
#+LABEL: fig:cupping_methods
#+ATTR_LATEX: :width 18cm
[[./figures/cupping_methods.pdf]]


** Error Propagation
How large a problem are miscalculations of the moment of inertia for calculations of joint moment?
To evaluate this, one has to consider error propagation with the balance equations \eqref{eqn:moment}.
The variable \(I\) only enters the balance equations through the dynamic wrench, \(M = I \ddot\theta\).
This function is linear, so error propagation is quite simple citep:Hughes2010,Normann2016:
@@latex:\label{eqn:moment}@@
#+begin_center
\[\Delta M = \sqrt{\left(\frac{\partial M}{\partial I}\Delta I\right)^2} = \sqrt{\left(\Delta I \ddot\theta\right)^2}\]
#+end_center

Sensitivity is linear at this level: any percentage of measurement inaccuracy in \(I\) will directly propagate to the joint moment calculation.


Yet the situation is more involved: calculating \(I\) via equation \eqref{eqn:mmoi} is itself subject to errors, by inaccuracy in the mass itself (regression), and by unceretainty in the COM position and therefore the position vectors \(r_{i}\) of each mass element.
#+begin_center
\[ \Delta I = \left \Delta I \right\mid_{m_i} + \left \Delta I \right\mid_{r_i} = \sqrt{ \sum_{i} \left[ \left(\frac{\partial I}{\partial m_{i}} \Delta m_{i} \right)^2 + \left(\frac{\partial I}{\partial r_{i}} \Delta r_{i}\right)^2 \right] }\]
#+end_center

The direct dependence on mass is visible in equation \eqref{eqn:mmoi}, uncertainty of the mass elements contribute linearly but are added up; errors in the mass of further away mass elements contribute more to the total error of the moment of inertia.
#+begin_center
\[ \Delta I \mid_{m_i} = \sqrt{\sum\limits_{i}\left(\left( \lVert r_{i} \rVert ^2 E_3 - r_{i} \otimes r_{i} \right)\right)^2 \cdot \Delta m_{i} }\]
#+end_center


The partial derivative with respect to \(r_{i}\) must be added, because \(I\) is taken relative to the COM (hence, \(\Delta r_i = \Delta COM\)).
We know that the choice of reference point for moment of inertia can be adjusted by using generalized Steiner, and so the error in the COM propagates as a Steiner component, equation \eqref{eqn:steiner}, with \(s=\Delta COM\).
Yet \(\Delta COM\) also depends non-trivially on the relative mass of volume elements, equation \eqref{eqn:com}.
#+begin_center
\[ \Delta COM = \sqrt{ \frac{1}{\sum_i m_{i}} \sum\limits_{i} \left( r_{i} \cdot \Delta m_{i} \right)^2  + \left(-\left(\Delta \sum_i m_{i} \right)^{-2} \sum\limits_{i} r_{i} \cdot m_{i} \right)^2\]
#+end_center
This last equation now lines out how the target parameter, \(I\), depends on mass elements \(m_{i}\) in different ways.


In practical terms, the expected error can be readily computed by iteratively changing the variables of interest by a percent, to infer how "a percent change" in a parameter effects the result of the calculation.
This is called *"sensitivity analysis"*.
By the analytical considerations above, even without exact analytical solutions, we can see that the variables to change are the regression parameters (\(\pm 5\%\) of their value), the COM position \(\pm 5\%\) of femur length, \(0.25 mm\) in each direction), and the total mass (\(\pm 5\%\), which are \(0.26 g\)).



* Results
** Density Calibration Regression
# /data/04_dynamics/21_flying_femur_revival/02_inertials/02_Regression.py

#+CAPTION: Density calibration of a CT scan. The polymer materials show a linear relation between density \(\rho\) and CT gray value \(\gamma\) (exception: PVC, excluded from regression), whereas the positions of BMD phantoms (ld: low density; hd: high density) implies an exponential relation. Violins illustrate the distribution of gray values, yet each object in the scan is associated with exactly one true (average) density.
#+LABEL: fig:density_calibration
#+ATTR_LATEX: :width 16cm
[[./figures/regression.pdf]]

To establish a transform function which can convert CT gray values \(\gamma\) to physical density \(\rho\) and back, we compared different regression functions which fit the observed gray values of different polymer materials of known densities (Fig. \ref{fig:density_calibration}).

The random plastic parts obtained from the workshop have known densities, and plotting \(\gamma\) against \(\rho\) most of them show a linear relation.
The exception is PVC, which was therefore excluded from the regression (whether it was truly PVC, or a mislabeled different polymer, cannot be assessed retrospectively).
Bone mineral density (BMD) phantoms and water do not fall on that line.
Their gray values imply an exponential relation of \(\gamma\) and \(\rho\).
Regression was performed by minimizing least square difference of observations and the target function.
Both the linear and exponential function can be inverted.
The femur of unknown density distribution lies right between the two regression lines, but spans a large range of gray values and densities because of its heterogeneous composition (marrow, cavities, muscle tissue, calcified bone, metal markers and glue).

With the regression outcome, it is technically possible to convert any voxel gray value to putative density values, which applies for example to the femur.


** Issue 0: Mass Mismatch and Total Mass Normalization

To confirm the outcome of the regressions above, we compared the actual mass of the femur (which is \(5.271 g\)) to the outcome of the digital approximation.

As seen in the regression (Fig. \ref{fig:density_calibration}), the majority of femur voxels have a gray value which falls right in between the two regression lines.
This also reflects in the calculated outcomes.
With the linear regression, the femur mass is calculated to be \(6.38 g\) (\(+21 \%\)).
The exponential regression yields a lower than actual mass (\(4.96 g\), \(-29 \%\)).
Though it appears that the correct regression would lie somewhere between the exponential and linear attempt, there is no data, nor theoretical justification supporting any intermediate hypothesis.
Neither is there any reason to think that all biological tissues generally fall in between the presented cases.

We conclude that, at least for a femur, the regression method is not accurate.


To exclude that problems arose from the special composition of this isolated bone, we applied a similar regression method to more complex data.

In a second experiment, a piglet body was CT scanned, virtually segmented, and analogously dissected to see whether the total mass of the virtual segments matches their actual masses.
The corresponding scan was performed at a different facility and long before the density calibration experiments, and thus the only available calibration points were air, water, and two density calibration phantoms.
Consequently, an exponential regression was used to convert gray values to density.
Although an exponential regression was used (prone to under-estimation in case of the femur), this virtual density conversion leads to a considerable over-estimation of the mass of most of the segments, and the specimen total.

This result highlights how erratic the digital density approximation is.



#+NAME: tab:pigletdissection
#+ATTR_LATEX: :environment tabular :align |l|c|c|c|
#+CAPTION: Segment mass verification on an actual piglet specimen. On the lighter segments, measurement accuracy and rounding are limiting. Note that the total mass at euthanasia was measured \(1.125 kg\), a slight loss is expected due to condensation and preservation.
#+begin_table
|-----------------+-----------------+------------+------------|
| *segment*         | *CT segmentation* | *dissection* | *difference* |
|-----------------+-----------------+------------+------------|
|-----------------+-----------------+------------+------------|
| *masses \([kg]\)* |                 |            |            |
| head            |           0.247 |      0.230 |        +7% |
| torso+trunk     |           0.666 |      0.580 |       +15% |
| LF humerus      |           0.033 |      0.027 |       +22% |
| LF radioulna    |           0.016 |      0.014 |       +14% |
| LF metacarpal   |           0.009 |      0.006 |       +50% |
| LF hoof         |           0.006 |      0.005 |       +20% |
| LH femur        |           0.052 |      0.050 |        +4% |
| LH tibiafibula  |           0.027 |      0.020 |       +35% |
| LH metatarsal   |           0.012 |      0.010 |       +20% |
| LH hoof         |           0.004 |      0.004 |        +0% |
| RF humerus      |           0.031 |      0.031 |        +0% |
| RF radioulna    |           0.019 |      0.015 |       +27% |
| RF metacarpal   |           0.008 |      0.006 |       +33% |
| RF hoof         |           0.005 |      0.005 |        +0% |
| RH femur        |           0.050 |      0.053 |        -6% |
| RH tibiafibula  |           0.023 |      0.021 |       +10% |
| RH metatarsal   |           0.013 |      0.011 |       +18% |
| RH hoof         |           0.005 |      0.003 |       +67% |
|-----------------+-----------------+------------+------------|
| *TOTAL*           |           *1.226* |      *1.091* |            |
|-----------------+-----------------+------------+------------|
|-----------------+-----------------+------------+------------|
#+TBLFM: @3$4..@-2$4=100*($2-$3)/$3;%+.0f%%
#+end_table


** Issue 1: Beam Hardening

# /data/04_dynamics/21_flying_femur_revival/11_cupping/05_PlotPTFEInertia.py
#+CAPTION: Effect of beam hardening on calculated mass moment of inertia of a PTFE cylinder. (A) Repeat of radial profiles (as in Fig. \ref{fig:cupping_methods}C) for different beam hardening strengths. (B) Calculated mass moments of inertia, unscaled (\(\times\)) and scaled \(\circ\). In this cylinder, \(I_z\) is always larger than \(I_x, I_y\) which are approximately identical. The solid, dark red line indicates the theoretical (true) \(I_z\) of the PTFE cylinder, the dashed red line marks the true value of the other inertial axes. The more beam hardening \(k\), the lower the (unscaled) mass moment of inertia. Noteworthy, at \(k=0\) the inertia values match the true values. However, this is only true for the unscaled curves; when scaling to make the calculated mass of the cylinder match the actual mass (i.e. normalizing mass, see text) the correct inertia is reached at an arbitrary, non-zero \(k\), and the calculated inertia increases with beam hardening due to the normalization.
#+LABEL: fig:cupping_results
#+ATTR_LATEX: :width 18cm
[[./figures/cupping_results.pdf]]

To evaluate what effect beam hardening will have on the calculated mass moment of inertia, we simulated beam hardening on a well described PTFE cylinder within the scan volume.

The only reliable recovery of the true mass moment of inertia (Fig. \ref{fig:cupping_results}B, horizontal lines) is found to be if there is exactly zero cupping.
This generally holds for homogeneous objects: moment of inertia is determined by the geometric distribution of mass elements around the COM; iff the relative mass of all mass elements are well approximated by the density regression (which is only and exclusively the case in homogeneous objects), and iff cupping is negligible, then we can calculate appropriate \(I\) values.
However, if the object is non-homogeneous (as a femur), then for example the relative density of marrow and calcified bone are not appropriately covered, and \(I\) will be incorrect.
Also, if there are *any beam hardening or streak artifacts*, which is non-trivial to remove from FBP reconstructed scans, *the moment of inertia will be incorrect*.
Attention should also be put on the units of the calculated mass moments of inertia: it is in the order of \(10^{-7} kg m^2\) for this cylinder.
This is small, justifying extra attention to numeric accuracy of computational methods as well as sources of physical inaccuracy (e.g. COM miscalculation).
# Three corollaries:
# (1) Mass scaling, which above I suspected to retain density distribution, will produce erroneous moments of inertia if artifacts are present.
# (2) Using "constant" regression (i.e. modelling uniform mass distribution) will only produce accurate inertia for homogeneous objects.
# (3) Iterative reconstruction methods might partially overcome this issue citep:Six2019, but their application requires prior information and extra work.

We conclude that the chance of getting an accurate measurement for mass moment of inertia from conventional CT scans is low under the influence of common error sources.



** Issue 2: Metal Bead Artifacts and Chemical Composition

#+CAPTION: Metal Bead Artifacts, marked with orange arrows. Despite the use of an aluminium filter to harden the x-ray beam, metal beads produce conspicuous, star-shaped streaks on the scan reconstructions. The reason that the center of the metal beads appears black is a clipping setting during image preprocessing (intentional, do remove their mass).
#+LABEL: fig:metal_artifacts
#+ATTR_LATEX: :width 12cm
[[./figures/metal_artifacts.png]]

Another typical kind of artifacts in CT scans appear around metal beads (Fig. \ref{metal_artifacts}).
Metals are chemical elements with overproportionally higher x-ray attenuation than carbohydrate compounds.
They absorb a large fraction of the incoming radiation, demanding the use of hight energy to avoid shadows arising from missing information in the projections, which can be detrimental to contrast on softer tissue.
The shadows appear as "streaks" or "starbursts" on CT scans, they complicate segmentation, and are unwanted in XROMM visualizations citep:Brainerd2010.
As with other artifacts, metal bead artifacts have their source in limitations of the tomographic method (limited dynamic range, rotationally symmetric scan geometry), and might be corrected by appropriate counter-measures.
Beam hardening reduction by using metal filter plates can improve dynamic range and contrast (at the cost of exposure).
The use of a helical scan geometry in a cone-beam CT should reduce the length and contrast of streaks, because projections from above or below the bead elevation level will project through the tissue immediately behind the bead.

Though it is pronounced on metal beads due to their spatial confinement, the problem is not restricted to metal.
Streak artifacts also appear between multiple regions of dense bone or strongly absorbant solute (i.e. water), especially if two such regions can be behind each other in the projection geometry.


To re-iterate, there are two reasons for these effects.
The first is a kind of "beam hardening", taken to the extreme: the spectrum of the photon ensemble changes along the projection trajectory, and much more so if x-ray interactions with matter are more numerous.
The second factor is that they are more numerous in some materials than others (irrespective of density): chemical composition is key.


** Sensitivity Analysis

#+NAME: tab:sensitivity
#+ATTR_LATEX: :environment tabular :align |l|l|c|c|c|c|c|
#+CAPTION: Sensitivity Analysis of the Mass Moment of Inertia calculations. For reference, the actual femur weighed \(5.271 g\), had a length of \(46 mm\), volume of \(4.637\times 10^{-6} m^{3}\) and an average density of \(\approx 1140 kg m^{-3}\).
#+begin_table
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
| *parameter*            | *change*      | *\(\sum_{i}m_{i}\)* | *\(\Delta COM\)* |          *\(I_{xx}\)* |          *\(I_{yy}\)* |          *\(I_{zz}\)* |
|                      |             |        \([g]\) |  \([px]\) | \([\times 10^{-6} kg m^2]\) | \([\times 10^{-6} kg m^2]\) | \([\times 10^{-6} kg m^2]\) |
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
| *(reference)*          | none        |           6.38 |         0 |                0.52 |                1.36 |                1.67 |
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
| *regression \(a\)*     | \(+5\%\)    |           6.12 |        <1 |                0.50 |                1.31 |                1.60 |
| *regression \(b\)*     | \(+5\%\)    |           6.07 |         0 |                0.49 |                1.30 |                1.59 |
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
| *mass \(\sum_{i} m_{i}\)* | \(+0.26 g\) |           6.70 |         0 |                0.55 |                1.43 |                1.75 |
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
| *COM \(x\)*            | \(+2.5 mm\) |           6.38 |        50 |                0.52 |                1.40 |                1.71 |
| *COM \(y\)*            | \(+2.5 mm\) |           6.38 |        50 |                0.56 |                1.36 |                1.71 |
| *COM \(z\)*            | \(+2.5 mm\) |           6.38 |        50 |                0.56 |                1.40 |                1.67 |
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
| *regression type*      | expon.      |           4.96 |         5 |                0.42 |                1.09 |                1.34 |
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|
|----------------------+-------------+----------------+-----------+---------------------+---------------------+---------------------|


To put all the aforementioned issues into perspective, we calculated how a change in one parameter affects the outcome of the calculation of inertial properties (Tab. \ref{tab:sensitivity}).

Moderate changes in the density calibration regression directly influence the mass, and thereby the moment of inertia; even the COM is mildly affected.
The effect on \(I\) is in the order of \(7-8\%\).
Adjusting the mass has a similar effect as a change in regression parameters, and a \(5\%\) mass increase causes a \(\Delta I\) of more than \(8\%\).
Shifting the COM alone does affect inertial parameters depending on the shift direction, which is expected (Steiner theorem).
The effect of the notable shift (\(5\%\) of the femur length) is a change in \(I\) of about \(4\%\), yet mass changes seem to affect all inertia axes alike, whereas the error due to COM shift affects the axes differently.
This is an artificial adjustment, changing the COM without a change in mass, but it does help to estimate errors in an inverse dynamics workflow, where a COM misplacement will also affect a joint wrench according to the Steiner theorem.
Finally, the exponential regression leads to a moderate shift in COM (\(0.25 mm\)), but a considerable underestimation of mass (\(-29 \%\)) and moment of inertia (\(-32 \%\)).

These simulations confirm that moment of inertia crucially depends on the mass that is assigned to each voxel in the CT data set, because the relative error in the outcome can exceed the input inaccuracy.


* Discussion
** Density and Attenuation
In this chapter, I challenge the common misperception that structural information from CT images can be easily converted to a density distribution.
We think of objects in terms of their mass because that is what humans are confronted with in their everyday experience of the physical world.
And the structures which we see in CT visualizations resemble that experience.
However, they quantify attenuation, which is a different phenomenon.


Reasons for the mismatch are numerous.
X-ray radiation used in commercial CT scanners is often polychromatic.
Absorption is wavelength-dependent in a non-trivial way.
The whole process contains stochastic aspects (e.g. scattering).
Scientists tend to introduce the constraint that chemical composition must be homogeneous within samples, yet that constraint is neither realistic, nor practical.
Finally, the effects some qualify as scan artifacts seem to be an issue, but as argued above they might just be the manifestation of the inappropriate modeling of a normal physical process.


** Miscalculated Mass
The thorough measurements reported above confirm that the outcome of a CT scan cannot be directly related to physical density.
We followed the strategy of others, using a kind of calibration regression to convert CT values to density citep:Mull1984,Phillips1997,DuPlessis2013,Durston2022,Fath2023.
Our measurements show severe differences between the actual density and the calculated values, with errors of more than \(20\%\) of the actual mass.


Neither plastic parts, nor the calibration cylinders we used provided an accurate reference for the density of the test object.
The bone mineral density phantoms arguably serve a different purpose (calibrating /mineral/ density), but resemble the compact parts of the bone in their chemical composition.
Yet it is not only the chemical composition of the scanned object, but also the spatial arrangement of its components, because the trajectory of the x-ray beam affects attenuation.
It is insufficient to just assume "comparable chemical composition".
The calibration object must also have the same shape and spatial arrangement as the object of interest.
The ideal object to calibrate an unknown femur would thus be an identical femur of known mass distribution.

The reason, as illustrated in the introduction, is that the spectrum of the beam changes at each instance in the tissue, because photons of different wavelengths have specific absorption probabilities.
The most obvious example of this is beam hardening, and I showed by a simple virtual simulation that beam hardening leads to a systematic under-estimation of mass and moment of inertia (Fig. \ref{fig:cupping_results}).
In a more extreme case of this, radio-opaque metal beads will absorb almost all passing photons, leading to problems with conventional reconstruction algorithms which appear as starburst artifacts.


Recent developments attempt to improve the reconstruction algorithm citep:Six2019,Frenkel2022,Yang2021, but their application requires prior information and extra work.
Others might eagerly await "spectral CT" citep:Liu2023, yet technical and economic challenges are still limiting the capability and availability of such machines.


** Non-Intuitive Inertia
It is perfectly normal that physical measurements are subject to measurement inaccuracy.
However, the error range must be reported.

Above, we demonstrated an analytical assessment of what errors should be expected, as well as a numerical sensitivity analysis.
The results enable an evaluation of the relative importance of different parameters for the accuracy of the outcome.
For example, changes in the mass or in the regression outcome directly influence the moment of inertia, at a rate higher than the input error.
A COM miscalculation might cause errors of less magnitude, but errors are not necessarily isotropic.


Yet by far the greatest effect was due to a change in the regression type, switching from linear to exponential.
Neither of these is accurate, yet in the absence of a model which covers the nature of attenuation, there is no other reasonable option.
The exponential fit seemed plausible from the BMD phantoms.
The majority of observed femur gray values were not far off the exponential regression line.
Nevertheless, the calculated moment of inertia was about \(30\%\) off the reference.
Note that this error subsumes both an apparent over-estimation in the linear reference regression, and an under-estimation of \(I\) in the exponential attempt.
Also, the considerable percentage is explained by the fact that moment of inertia values are relatively small in baseline magnitude.
A shortcoming of the present study is that we are unable to determine a "ground truth" inertia for the test object, lacking sufficiently accurate physical measurement apperature and expertise.


Nevertheless, our findings have practical application.
Any regression should be as accurate as possible (the more/diverse calibration objects, and the more resemblance of the test object, the better).
A probabilistic regression would be favorable, since it yields error margins for the regression parameters.
With those, a sensitivity analysis can and should be performed.
We also showed that scaling voxel-wise density so that the mass matches the known total mass is not an option: it can amplify issues from beam hardening (Fig. \ref{fig:cupping_results}) and marker streaks and make the outcome more unpredictable.


** Which Inertia Component is Relevant?
movement in vivo
sensitivity analysis
Dynamic Images

** Lack of Alternatives
+ pendulum
+ dissection
+ CAD models

* Summary
At the end of this chapter, it should be clear that the only people using CT images to calculate inertial properties would be Biologists who are agnostic to the basic principles of physics.
This includes the author.
Tomographic images depict attenuation, not physical density, and though these are occasionally correlated, they remain fundamentally different properties of matter.
Above, I discussed potential flaws in the CT-based approximation of mass, center of mass, and mass moment of inertia, as well as corner cases in which the calculation might co-incidentally yield appropriate results.
In all other cases, the calculation will certainly yield wrong results.
The magnitude of the error is non-negligible, since some axes of inertia in balance equations have very small base magnitude and are therefore susceptible to faults.


However, with all that objection put to paper, it must be stated that there is no effective alternative to the use of CT scans.
There is no "density tomography", and common alternative methods (pendulum, dissection, CAD models) suffer from equally large error margins for other reasons (e.g. measurement inaccuracy, non-static configuration during movements).
Using attenuation values to calculate densities is about as accurate as setting \(\pi \equiv 3\) in physics classes (a totally valid thing to do, if at the same time setting \(g \equiv 10\)).
Yet when knowing and avoiding typical pitfalls (beam hardening, metal beads, symmetries), and when keeping track of error magnitudes (e.g. by sensitivity analysis, or Gaussian error propagation), the so-calculated inertial properties might be a just sufficiently accurate approximation of the true values.


* Acknowledgements
If I interchanged "we" and "I" in the text above, this indicates that a certain part of the project was supported by the following fabulous people.
# Joaquim & VisionLab
# Jonathan Brecko / naturalscience and Björn De Samber / FleXCT for scans
# CVG for the most accurate piglet dissection possible
# JS for motor and clamp construction and general support
tbd.

# \pagebreak
# References
# \bibliographystyle{apalike}
# \bibliography{literature.bib}


#+begin_comment
scattering types of xray beams
poly-SIRT
Liu2023 spectral CT https://www.nature.com/articles/s41598-023-33264-2#citeas
% AI density estimation https://doi.org/10.1016/j.media.2021.102061
#+end_comment
